{"channel":{"0":"H2020 2019 call topic n1 - Strengthening Internet Trustworthiness","1":"H2020 2019 call topic n1 - Strengthening Internet Trustworthiness","2":"H2020 2019 call topic n1 - Strengthening Internet Trustworthiness","3":"H2020 2019 call topic n1 - Strengthening Internet Trustworthiness","4":"H2020 2019 call topic n1 - Strengthening Internet Trustworthiness","5":"H2020 2019 call topic n1 - Strengthening Internet Trustworthiness","6":"H2020 2019 call topic n1 - Strengthening Internet Trustworthiness","7":"H2020 2019 call topic n2 - Service and Data Portability","8":"H2020 2019 call topic n2 - Service and Data Portability","9":"H2020 2019 call topic n2 - Service and Data Portability","10":"H2020 2019 call topic n3 - Open Internet Architecture Renovation","11":"H2020 2019 call topic n3 - Open Internet Architecture Renovation","12":"H2020 2019 call topic n3 - Open Internet Architecture Renovation","13":"H2020 2019 call topic n3 - Open Internet Architecture Renovation","14":"H2020 2019 call topic n3 - Open Internet Architecture Renovation","15":"H2020 2019 call topic n3 - Open Internet Architecture Renovation","16":"H2020 2019 call topic n3 - Open Internet Architecture Renovation","17":"H2020 2019 call topic n3 - Open Internet Architecture Renovation","18":"H2020 2019 call topic n3 - Open Internet Architecture Renovation","19":"H2020 2019 call topic n3 - Open Internet Architecture Renovation","20":"H2020 2019 call topic n3 - Open Internet Architecture Renovation","21":"H2020 2019 call topic n3 - Open Internet Architecture Renovation","22":"H2020 2019 call topic n3 - Open Internet Architecture Renovation","23":"H2020 2019 call topic n3 - Open Internet Architecture Renovation","24":"NGI @ICT2018","25":"NGI @ICT2018","26":"NGI @ICT2018","27":"NGI @ICT2018","28":"NGI @ICT2018","29":"NGI @ICT2018","30":"NGI @ICT2018","31":"NGI @ICT2018","32":"NGI @ICT2018","33":"Privacy and Trust Enhancing Technologies","34":"Privacy and Trust Enhancing Technologies","35":"Privacy and Trust Enhancing Technologies","36":"Privacy and Trust Enhancing Technologies","37":"Privacy and Trust Enhancing Technologies","38":"Privacy and Trust Enhancing Technologies","39":"Privacy and Trust Enhancing Technologies","40":"Privacy and Trust Enhancing Technologies","41":"Privacy and Trust Enhancing Technologies","42":"Privacy and Trust Enhancing Technologies","43":"Privacy and Trust Enhancing Technologies","44":"Privacy and Trust Enhancing Technologies","45":"Privacy and Trust Enhancing Technologies","46":"Privacy and Trust Enhancing Technologies","47":"Privacy and Trust Enhancing Technologies","48":"Privacy and Trust Enhancing Technologies","49":"Discovery and Identification Technologies","50":"Discovery and Identification Technologies","51":"Discovery and Identification Technologies","52":"Discovery and Identification Technologies","53":"Discovery and Identification Technologies","54":"Discovery and Identification Technologies","55":"Discovery and Identification Technologies","56":"Discovery and Identification Technologies","57":"Decentralised Data Governance","58":"Decentralised Data Governance","59":"Decentralised Data Governance","60":"Decentralised Data Governance","61":"Decentralised Data Governance","62":"Decentralised Data Governance","63":"Decentralised Data Governance","64":"Decentralised Data Governance","65":"Decentralised Data Governance","66":"Decentralised Data Governance","67":"Responsible AI","68":"Responsible AI","69":"Responsible AI","70":"Responsible AI","71":"Responsible AI","72":"Responsible AI","73":"Responsible AI","74":"Responsible AI","75":"Responsible AI","76":"Responsible AI","77":"Responsible AI","78":"Responsible AI","79":"Responsible AI","80":"Blockchain as an Enabler for NGI","81":"Blockchain as an Enabler for NGI","82":"Blockchain as an Enabler for NGI","83":"Blockchain as an Enabler for NGI","84":"Blockchain as an Enabler for NGI","85":"Blockchain as an Enabler for NGI","86":"Open Internet Initiative","87":"Open Internet Initiative","88":"Open Internet Initiative","89":"Open Internet Initiative","90":"Open Internet Initiative","91":"Open Internet Initiative","92":"Open Internet Initiative","93":"Open Internet Initiative","94":"Open Internet Initiative","95":"Hyper-connected Sociality","96":"Hyper-connected Sociality","97":"Hyper-connected Sociality","98":"Hyper-connected Sociality","99":"The Next Generation Internet: Diversity, Inclusion and Skills","100":"The Next Generation Internet: Diversity, Inclusion and Skills","101":"The Next Generation Internet: Diversity, Inclusion and Skills","102":"The Next Generation Internet: Diversity, Inclusion and Skills","103":"The Next Generation Internet: Diversity, Inclusion and Skills","104":"The Next Generation Internet: Diversity, Inclusion and Skills","105":"The Next Generation Internet: Diversity, Inclusion and Skills","106":"The Next Generation Internet: Diversity, Inclusion and Skills","107":"Socio-economic and Legal Considerations for NGI","108":"Socio-economic and Legal Considerations for NGI","109":"Socio-economic and Legal Considerations for NGI","110":"Socio-economic and Legal Considerations for NGI","111":"Socio-economic and Legal Considerations for NGI","112":"Socio-economic and Legal Considerations for NGI","113":"Socio-economic and Legal Considerations for NGI","114":"Socio-economic and Legal Considerations for NGI","115":"Innovation Networks","116":"Innovation Networks","117":"Innovation Networks","118":"Innovation Networks","119":"Innovation Networks"},"date":{"0":"18 Feb 2019","1":"20 Nov 2018","2":"19 Nov 2018","3":"10 Aug 2018","4":"01 Aug 2018","5":"09 May 2018","6":"12 Feb 2018","7":"21 Nov 2018","8":"20 Nov 2018","9":"08 May 2018","10":"04 Mar 2019","11":"27 Sep 2018","12":"02 Aug 2018","13":"09 May 2018","14":"08 May 2018","15":"07 May 2018","16":"07 May 2018","17":"06 May 2018","18":"12 Mar 2018","19":"12 Mar 2018","20":"19 Feb 2018","21":"18 Jan 2018","22":"18 Jan 2018","23":"30 Oct 2017","24":"11 Dec 2018","25":"07 Dec 2018","26":"05 Dec 2018","27":"05 Dec 2018","28":"05 Dec 2018","29":"05 Dec 2018","30":"05 Dec 2018","31":"29 Nov 2018","32":"19 Nov 2018","33":"07 Feb 2019","34":"13 Nov 2018","35":"09 Nov 2018","36":"05 Jun 2018","37":"08 May 2018","38":"06 May 2018","39":"04 May 2018","40":"16 Mar 2018","41":"12 Mar 2018","42":"21 Feb 2018","43":"21 Feb 2018","44":"19 Jan 2018","45":"17 Jan 2018","46":"16 Jan 2018","47":"15 Jan 2018","48":"15 Nov 2017","49":"14 Nov 2018","50":"26 Sep 2018","51":"26 Sep 2018","52":"25 Sep 2018","53":"25 Sep 2018","54":"04 May 2018","55":"12 Dec 2017","56":"14 Nov 2017","57":"31 Oct 2018","58":"31 Oct 2018","59":"31 Oct 2018","60":"02 Aug 2018","61":"07 Feb 2018","62":"19 Jan 2018","63":"18 Jan 2018","64":"11 Jan 2018","65":"10 Nov 2017","66":"30 Oct 2017","67":"28 May 2019","68":"08 Jan 2019","69":"26 Mar 2018","70":"26 Mar 2018","71":"26 Mar 2018","72":"26 Mar 2018","73":"13 Mar 2018","74":"15 Feb 2018","75":"15 Jan 2018","76":"15 Jan 2018","77":"04 Jan 2018","78":"04 Dec 2017","79":"31 Oct 2017","80":"28 May 2019","81":"18 Dec 2018","82":"25 Mar 2018","83":"01 Jan 2018","84":"24 Nov 2017","85":"24 Nov 2017","86":"18 Mar 2019","87":"09 May 2018","88":"09 May 2018","89":"22 Feb 2018","90":"22 Feb 2018","91":"22 Feb 2018","92":"22 Feb 2018","93":"22 Feb 2018","94":"20 Nov 2017","95":"19 Jan 2018","96":"16 Jan 2018","97":"22 Nov 2017","98":"31 Oct 2017","99":"17 Dec 2018","100":"05 Jun 2018","101":"22 Feb 2018","102":"23 Jan 2018","103":"10 Jan 2018","104":"18 Nov 2017","105":"31 Oct 2017","106":"31 Oct 2017","107":"22 Feb 2018","108":"22 Feb 2018","109":"22 Feb 2018","110":"22 Feb 2018","111":"21 Feb 2018","112":"21 Feb 2018","113":"21 Feb 2018","114":"23 Jan 2018","115":"04 May 2018","116":"23 Jan 2018","117":"21 Jan 2018","118":"21 Jan 2018","119":"21 Jan 2018"},"text":{"0":"Modern news publishers have a big problem.  \nIndustry standard is to publish reports -- even when incomplete -- within minutes of critical events.\nHowever, today's fact-checking processes take up to *13 hours* to correct information in those rushed reports.\nAnd if any mistakes slip through the cracks, as the saying goes, that misinformation travels halfway around the world before the truth can even put on its pants.\nIn our polarized world, misinformation has shown significant power to shape public opinion and influence the direction of our societies.  If we want to share a *trustworthy* digital landscape, which empowers us to better understand our world and make better decisions because of it, we must create new tools to validate our online information -- and fact-checking is a pillar of that effort.\nMy name is Sam Butler, and I'm working on a project called CrowdFact.  Our objectives are to (a) reduce the current response time on misinformation from 13 hours to a matter of minutes, and (b) provide a model for stabilizing and protecting the digital information landscape in advance of the worldwide 2020 election cycles.\nOur tool solves the aforementioned problems by bringing fact-checking power *outside* the newsroom.  With our browser overlay technology, anyone can publicly fact-check claims -- on *any* piece of online content -- and \"bridge\" them to supporting\/refuting evidence, which will be visible to all other users looking at that content.\nHere's a video of our tool in action:\nhttps:\/\/www.youtube.com\/watch?v=FphXsJS7wtA#t=02m05s\nPresuming users have fact-checking competence and good intentions, this solution is robust.\n-- But when they *don't?*\nAs a digital community, that is a question we must address.\nIn our tool, when users cite (or \"bridge\") evidence to *contradict* an existing claim, that claim is highlighted in *red* to alert other readers of potential misinformation.  When users bridge evidence to *support* an existing claim, that claim is highlighted in *green*, to signal validity to other readers.  When users have bridged both *contradicting and supporting* evidence for a given claim, that claim is highlighted in *yellow* to alert other readers that it is questionable and up-for-debate.  \nSee this image for a visual representation:  \nhttps:\/\/imgur.com\/a\/hCVaBIw \nThe biggest problem here is that we don't have an objective way to *evaluate* the quality of bridged evidence -- including the sensibility of the citation and the trustworthiness of the referenced source.    \nIn short, someone can make a random \"contradicting\" bridge on a completely valid claim, and make that claim be highlighted in red to appear untrustworthy.  Someone can likewise make a random \"supporting\" bridge on a completely false claim, and make that claim be highlighted in green to appear trustworthy.  \nIf other users fail to explore these bridges and simply take the color of the highlighted text at face-value, they can come away with the impression that misinformation is true and real information is false, which is a dangerous outcome.  \nSo the question becomes: how *can* we objectively evaluate the quality of bridges?\nSeveral solutions to come to mind, but each of them have their own flaws.  \n1. Internal platform moderation\nWhenever a user bridges a claim to supporting\/contradicting evidence, that bridge is evaluated by internal staff to determine its validity.  Only after passing this moderation will a bridge be publicly displayed.  \nHowever, what if a user make a legitimate bridge to contradict a disreputable claim in an article -- and while that bridge awaited moderation, other users read the article's misinformation and accepted it as true?  \nThis demonstrates the tradeoff of speed and reliability in any fact-checking effort.\nFlaws: Slows down the tool's fact-checking capabilities, doesn't scale with user activity, potential for platform + moderator biases\n2. Crowdsourced moderation \nWhen users bridge claims to supporting\/contradicting evidence, that bridge is immediately visible to (at least some portion of) the existing user base.  Any time a user comes across a supporting\/contradicting bridge, they will soon have an incentive (based on a cryptocurrency rewards protocol) to explore that bridge, and flag it if it appears unsubstantiated.\nWith a trusted crowd of user-moderators -- who could potentially view supporting\/contradicting bridges prior to the rest of the community -- this could be an effective and scalable solution.  \nLikewise, if the broader userbase positively responds to the incentive and takes it upon themselves to evaluate any encountered bridges, this could also be an effective and scalable solution.\nFlaws: Allows unmoderated bridges to become publicly visible, risking that others may erroneously internalize them.  If relying on user-moderators, you are susceptible to their biases while slowing down the tool's fact-checking capabilities.\n3. Tangible disincentives\nAs described in the preceding paragraph, our technology will include a platform-specific cryptocurrency which can reward users for their fact-checking efforts.  \nSimilarly, we can also create opportunity costs for publishing misinformation and disreputable bridges.  \nThrough their activity on our platform, users will have an opportunity to earn a share of daily token rewards.  If users have been found to post misinformation\/disreputable bridges, they could lose a portion of their projected rewards tokens to disincentivize that foul play.\nThe biggest strengths of this solution are that it (a) preemptively disincentives bad actors, and (b) incentives bad actors to personally correct their own disreputable activity.\nFlaws: If users are willing to accept this disincentive in exchange for publishing misinformation, this solution is ineffective\n4. Machine-learning verification\nUse algorithms to (a) analyze all available information about a given bridge and the evidence that it cites to support\/refute a claim, (b) calculate the projected validity of the bridge, and (c) determine whether or not to make this bridge publicly available.  \nML verification can be a near-instantaneous and reliable source of moderation.  Furthermore, the exact process of its moderation can be tweaked to include effective human collaboration and improved reliability.  \nFor example, if the algorithm calculates a low trust score for a given bridge, that bridge can be instantly flagged and sent to a human moderator to determine proper action.  \nFlaws: The algorithm itself is a source of bias.  Is CNN a reputable source?  Is Fox News?  Breitbart?  Is the data from which the algorithm learns which sources are reputable and disreputable are a reliable source itself?  Are the biases of the humans creating this algorithm diminishing its objectivity?  What *is* the objective truth that this algorithm is based on?\nConclusion:  \nWe have the technology to build new fact-checking protocols for the Internet and meet the instantaneous supply of new online information.\nHowever, as those solutions involves more crowdsourced participation and machine learning (and a higher volume of fact-checking activity in general), a new challenge comes to mind.  \n*How can we fact-check the fact checks?*\nThis is a complex problem facing all technologies in the anti-misinformation space, with the consequences affecting all of us who rely on digital information.\nWe've shared some of our ideas for solutions -- and now, we'd love to hear yours.  \nShare feedback on our proposals, and propose any ideas you have to improve the speed and reliability of next-gen fact-checking tools.\n","1":"This discussion is open for your questions, comments and ideas that you want to propose during the webinar organized on November 20th starting at 14.00 CET.\nAll comments will also be shared with the NGI community at large to allow networking and interactions around the upcoming funding opportunities.\n","2":"Hi All,\nMy team at Weizmann is engaged on basic research on the foundations of e-democracy.\nFor a foundational discussion see: https:\/\/cacm.acm.org\/magazines\/2018\/8\/229759-point\/pdf For some of our work, see: https:\/\/arxiv.org\/search\/?query=Shapiro%2C+Ehud&searchtype=author&order=...\nHere is a relevant abstract of a work-in-progress: A Global Web of Trust of Global Identities: Supporting an Open and Sybil-Resilient e-Democracy\n\u00a0\nA key threat to any open electronic community in general, and to an open e-democracy in particular, is fake identities, aka sybils: They undermine the integrity of the community, hamper equality, subvert accountability and are a potent source of manipulation and disinformation, thus promoting distrust. Critically, a swarm of sybils may attack an e-democracy in concert and overtake it. Genuine global identities are needed in a broad range of contexts, to increase credibility and accountability on the net \u05bf( https:\/\/www.w3.org\/DesignIssues\/PublicIdentity.html ) in general, and to enable democratic processes +( https:\/\/cacm.acm.org\/magazines\/2018\/8\/229759-point\/pdf ) in particular.\nTo help achieve that, we propose here a notion of a self-sovereign and decentralized global identity that consists of a public key and a profile, which may be cryptographically-hashed for privacy. People can create their own global identities and form a global web of trust among them. We explore the properties of global identities, their profiles and their global web of trust and outline their potential realization in compliance with the emerging standards of Decentralized Identity ( https:\/\/w3c-ccg.github.io\/did-spec\/ ) (DID) and Verifiable Credentials ( https:\/\/www.w3.org\/TR\/verifiable-claims-data-model ) (VC) and with privacy-related regulation, in particular the EU GDPR.\n\u00a0\nAttached file: https:\/\/consultation.ngi.eu\/sites\/default\/files\/attachment\/cacm-e-democr...\n","3":"Better search for trustworthy content and objects discovery is one of the interactive sessions at the NGI Forum 2018 on 13 September in Porto. This highly interactive session organised by TSSG and Trust-IT zoomed in on better search for trustworthy content and objects discovery.\nA short panel discussion with three SMEs Alexandru Stan (In-Two), Ales Cernivec (XLAB), Alessandro Bassi (ABC) led directly to the ConverStations, where participants moved around in groups to openly discuss about \"Improving identification of content, objects and services on the internet\" and \"\nUsing new search methods to improve the relevance and reliability of search results\".\u00a0 The session wrapped up with each ConverStation Chair sharing the main takeaways from the interactive discussions around the common themes of Values, Challenges, Solutions and the Research and Innovation need to fill the gaps.\nThe full report of the session is available here https:\/\/www.ngi.eu\/news\/2018\/09\/21\/report-session-3-better-search-trustw...\n","4":"On March 21st 2018, the Engineroom project ran an expert workshop in London to support the establishment of a research agenda for the Next Generation Internet. One of the activities was to examine challenges for a set of umbrella topics. \"Online Identities and Trust\" was one of those topics and\u00a0four distinct areas of discussion were elicited:\nGeneral thoughts;\nChallenges;\nOpportunities;\nExamples.\nOnline Identities and Trust\nDescribed as: There is a need for secure online identity verification and management system that can replace the trustless system with trust-enhancing solutions which would be alternatives to codifying trust through reputation systems. \nGeneral thoughts\nInstead of various identities for each individual issued by various governments, federated identities will enhance trust, security and reputation.\nNew identity formations are in place which contain characteristics from governments, business world and individuals e.g. World Identity Network, ID2020, YouPort etc.\nE-Estonia is a great example and an important source of inspiration that makes Estonia as the world\u2019s most sophisticated digital government\/economy.\nChallenges\nInstead of choosing good and favourable processes, we used to select what is more convenient. Complexity of convenience is a big challenge against change.\nDecentralised identity systems need some sort of verifiability or legitimacy from a wider community.\nEurope needs to look for an alternative, realistic, and optimistic vision which should revolve around immutable, and trustworthy identity systems.\nOpportunities\nEurope needs to benefit from the world\u2019s most sophisticated identity and e-government system (e-Estonia) of Estonia and scale it on a European level.\nEurope-wide identity management system makes a more frictionless single market and would solve a lot of economic issues.\nExamples\nAlice is a platform that brings transparency to social funding through blockchain technology.\nYoti is a London-based technology company on a mission to become the world\u2019s trusted identity platform.\n\u00a0\n","5":"According to The NGI Study draft final report, the universal \"neutrality principal\" that lies at the heart of the Internet allows everyone to use the Internet to its full potential without holding back. It is essential for democratic ownership of the digital society. It can be achieved only with the use of trustworthy technologies that can be relied upon by all users of the Internet. This can be done by the identification and deprecating existing non-trustworthy elements and creating new trustworthy components. This requires applying severe scrutiny to key 'commodity' protocols and widespread implementations. The core networking components need to be clean without defects or backdoors. The built-in security of core networking components may be the only line of defence for many applications and services on top of the network.\nFor now, especially in case of critical or vulnerable applications, the security and integrity of the network should not be treated as axiomatic and additional measures need to be taken with the costs and additional efforts associated. This way the NGI will help to create security transparency, meaning that users will be able to adequately grasp their overall security situation. The amount of suspect technologies we cannot avoid to rely on\u00a0ultimately needs to be reduced to zero. This is a very significant but unavoidable task if future contamination is to be prevented. It requires a structured long-term approach where step by step core technologies are either proven to be secure (possibly after improvements) and can remain in use, or are replaced with better solutions. The urgency of this effort cannot be overestimated, given the high economic and social stakes. The end result should be a growing set of essential internet technologies which can be fully trusted as building blocks for any purpose.\nThe list of reliable (best practise) technologies should be actively maintained during the NGI. This is considered a pivotal aspect of the NGI initiative. This will help NGI to significantly improve security transparency, which means that users will have better understanding of their overall security situation on the Internet.\n","6":"I am working for a non profit organisation in France. We manage the \".fr\" namespace. We have been working on identification and discovery service for the IoT for the last 8 years with experiences in working with the supply chain and LoRa (Long Range narrow band spectrum). I have also been a part of the IoT expert group constituted in 2013 by the EC.\nI would like to propose a subject on this R&I and am looking on how to submit a proposal and possible partners. Thanks for redirecting me to the appropriate place.\u00a0\n","7":"This discussion is open for your questions, comments and ideas that you want to propose during the webinar organised on November 21st\u00a0starting at 14.00 CET.\nAll comments will also be shared with the NGI community at large to allow networking and interactions around the upcoming funding opportunities.\n","8":"There are upcoming calls ICT-24, also with the topic of \"service and data portability\" (RIA). We are interested in hearing your thoughts and experiences regarding the data portability (personal, non-personal). The call is not so oriented towards \"moving services from provider to provider\" as one should conclude from the title of a call, but more towards \"moving data from a services provider to a service from other provider\", personal, non-personal, mixture of both types of data.\nThe solution developed within these calls (ICT-24) should support \"values of openness, cooperation across borders, decentralisation, inclusiveness and protection of privacy\". As soon we will get these kinds of solutions on a plate, only time will tell about the \"trust\" part. As we all know, trust is built through time.\nQuestions that can arise while reading the call: is it in APIs or pure data? Should solutions also offer some kind of toolkits that would help to understand the data and mechanisms within the solutions? What are the most probably use cases of such data portability? What standards should be considered? What is our major concern about end-user contracts and services' Terms of Uses? Is there a solution where we can thing about different approaches that just putting a banner on a web page with opt-in options for the cookies?\nPlease, share your thoughts.\nSlides from my presentation:\u00a0NGI for webinar RIA 2018 - service and data portability.pdf\n","9":"The NGI Study draft final report recognizes the need for service portability and data decoupling as essential to achieving the vision of next generation Internet.\nService portability and data decoupling outlines the need for empowering users to separate their content and data from internet software and services. This ability will transform market-dominant \u2018black box\u2019 internet services into universally available alternatives available to all as generic \u2018white label\u2019 building blocks that can be reused and adopted by anyone. This re-establishes the boundaries between content owner and service provider, allowing alternative and complementary services to be mixed and matched. It will also safeguard openness and diversity by actively steering away from market monopolies. In addition, without the pressure to maximise profit, services can be cleaned from psychological manipulation, be made more efficient and better adhere to the ethical preferences of the user. Following is the motivation and benefits of this approach.\nUser Mobility: Monolithic internet services result in a soft lock-in of the user community with one or a few companies. The overall cost of switching providers becomes too high, which means users can no longer autonomously decide to leave because they are co-dependent on a group of peers they use the service with. At that point users are at the mercy of the supplier, even if that user is facing very unfavourable or even unethical treatment or the service is no longer satisfactory. In the common case where multiple services are combined from a single very large company, these effects are even stronger.\nUsers should be able to choose service providers and\/or host services themselves. Users should be able to use services that have the best match with their needs, ethics and rights at any point. At the very least they should be able to switch providers without friction, and to choose the conditions under which their services are run and where their data is stored. This also makes sense as user needs are not static and universal. Allowing the user data to be decoupled and independent of service providers will boost the availability of commons alternatives for important internet services such as calendar, instant messaging, etc. and hence favouring user mobility.\nIncreased competition and resiliency: Service portability and data decoupling go hand in hand to help achieve openness to new entrants by unlocking clustered service verticals that have strong market positions. This will provide active countermeasures against market dominance and launch a competitive ecosystem of strong solution providers with a level playing field. By favouring the introduction of suitable microscale alternatives as a result of data independency, the monolithic dependency on individual hyperscale service providers can be dissolved, resilience be increased as there will be no single point of failure, and European or localized service providers become more competitive.\nStandardization and reduced friction: The goal herein is to establish suitable mature technology commons for popular end user services as open source, which are not bound to be hosted on any one individual company and have no friction cost for switching. These \u2018commons services\u2019 should contribute to standardization to reduce friction so that data and content is easily portable across instances in different providers. By introducing suitable microscale alternatives and interoperable standards that can be universally deployed, individual service providers are no longer a single point of failure and resilience will be significantly increased.\nDiverse, Inclusive and Localized Services: Service provider\u2019s businesses considerations are not supportive of incorporating broad social and cultural diversity into the nature of services, and the needs of economically marginal user groups are left under-represented. Availability of open-source building blocks will reduce the cost of innovation and foster creation of suitable microscale alternatives that are representative of the needs of economically marginalized and people with disabilities, and also provision services in many local languages, boosting diversity.\nThe report also recognizes that without prioritizing data decoupling and service portability, we face following risks.\nStagnation of overall innovation\nVendor dominance due to Metcalfe\u2019s law creates single points of (significant) failure in each domain\nLack of alternatives makes users vulnerable to targeted profiling and exploitation.\nEuropean businesses are at an unfair competitive disadvantage.\nFailure to reach the overall vision of the NGI.\nIn addition, the report proposes inviting projects proposals that create the generic infrastructure to facilitate data decoupling and frictionless switching such as \u2013\nremote storage and transfer of content separate from software provisioning\nSolutions to reuse non-commercial social and business graphs.\nDelivery methods.\n","10":"ISOC has issued its Global Internet Report. It focusses in particular on the issues around service provider consolidation and flattening of the Internet. \nIn particular consolidation is raising a vital question over the future of innovation over the Internet and of the Internet due to the increasing dependency on a few major industry platforms. \nISOC's CEO Andrew Sullivan postulates that this is putting pressure on the Internet architecturally. \nThe full report can be found online at https:\/\/future.internetsociety.org\/2019\/\n","11":"Renovating the Internet architecture is no easy feat: it not only depends on the technology, but also on complex social, political and economic interactions and interests from the multiple Internet ecosystem stakeholders. However, getting the technology right is crucial towards lying a strong foundation for a secure, decentralized and more performing Next Generation Internet (NGI).\nMy team at i2CAT has been collaborating with a global community of academic and industry researchers that have\u00a0worked\u00a0in research\/development of RINA, the Recursive InterNetwork Architecture,\u00a0for the last 6 years (see http:\/\/pouzinsociety.org). RINA is an Internetwork architecture whose fundamental principle is that networking is only inter-process communication (IPC). RINA reconstructs the overall structure of the Internet, forming a model that comprises a single repeating layer, the DIF (Distributed IPC Facility), which is the minimal set of components required to allow distributed IPC between application processes. RINA supports inherently and without the need of extra mechanisms mobility, multi-homing and Quality of Service, provides a secure and configurable environment, motivates for a more competitive marketplace and allows for a seamless adoption.\nDuring the last years we have been investigating (theoretically and experimentally) the properties of RINA, building open-source implementations, deploying experiments on large-scale testbeds, analysing how to interoperate with existing technologies. The results have been published in a number of journal and conference papers (http:\/\/pouzinsociety.org\/research\/publications). We think it is the right time for more groups to jump in, specially open source communities, to facilitate large-scale validation and assesment of RINA as the simplest yet more powerful possible Internet architecture.\u00a0\n","12":"A topic related to this, \"Cyber Security and Resilience\" was under discussion at the Engineroom project's expert workshop in London, March 2018. Four distinct areas of discussion were elicited:\nGeneral thoughts;\nChallenges;\nOpportunities;\nExamples.\nCyber Security and Resilience\nDescribed as: There is a need for secure internet infrastructure and protocols which are resilient against cyber-physical attacks with future-proof encryption. \nGeneral thoughts\nThe incentives of actors in cyber security need to be realigned.\nThere is a trade-off between resilience and efficiency. Everything is currently optimised for efficiency which is not suitable for cyber security in the long run.\nChallenges\nCheap technologies are not necessarily secure because they cost less. For example webcams and other such kind of devices can be turned into nodes in botnets as happened with the Mirai botnet.\nCybersecurity is seen as very complex, so people tend to disengage. People need to take this issue very seriously.\nLack of accountability and regulation, and insufficient public awareness leads to higher risk of cyber threats.\nNew business models are needed which include incentives to put cyber security and resilience at the core of the products.\nNeed new regulation, for example the EU\u2019s upcoming NIS directive, equivalent to the GDPR but for cyber security and CNI.\nOpportunities\nEuropean tech should be known to the secure-by-design. Europe has a real opportunity and potential in developing secure technology.\nThis will also be an opportunity to bring back hardware production to Europe and to set global standards.\nThere is a good opportunity for European start-ups to fill the gap in the market looking at tamper-proof ledgers, and other emerging solutions.\nExamples\nEquifax (example of what not to do!) was a massive data breach caused by shoddy security standards.\nBitcoin mining in websites (new type of crime!) without consent by the user, who inadvertently give up their computing power (through JavaScript scripts).\nShopify has been working closely with small retailers to collaboratively build safer systems.\n","13":"Growing dependency on a few operators might increase the risk of single point of failure. In order to avoid this risk and to make Internet services more resilient, network can be segmented in such a way that issues in one segment have no side effects in other segments\/parts of the network, which would allow for uninterrupted use outside of any affected areas. Furthermore, the service quality degradation can be avoided by providing multiple independent alternatives access networks (multihoming), and other means of smarter asset distribution as\u00a0presented in this discussion.\u00a0\nMany resources on the web and the wider internet are no longer self-contained, but have hard-coded dependencies on resources delivered by third parties, such as content delivery networks and cloud providers. These are used for critical features such as navigation. An outage somewhere in this chain can ripple an avalanche of unintended outages throughout many different systems. An example is the whois of a registry that needs to be able to be used in case of emergencies to notify the administrators of a certain domain, but turns out to depend on 3rd party Javascript sources.\nResilient Internet services can be achieved by ensuring high availability, openness and disruption tolerance as also detailed here. This will ultimately improve operational efficiency of the Internet, lower the operational cost, increase privacy by removing central vantage points, improve disaster-readiness and ensure business continuity and social connectivity.\n","14":"Creating a future proof Internet infrastructure requires continuous optimisation and integration of best practises at all levels, including at the hardware and system integration level. While the software market has been commodified and democratised through free software (aka open source), the hardware market is still dominated by a small amount of vendors. Commodification of the development of networking hardware, from full-blown optical networking equipment to embedded systems and hardware cryptographic components, can help to ensure higher availability, lower costs, increase transparency and diversity, and create a more open market where anyone may introduce highly complex new services that require strongly optimised and well-integrated hardware and software.\nNGI report recognizes extensible and reliable open hardware as an essential contributor towards achieving NGI vision, with the following identified benefits and risks respectively.\nBenefits\nLower costs for market entrants\nIncreased reusability of efforts. Otherwise there is a risk of vendor specific feature delivery with low reusability.\nReduced market dominance of (mostly non-European) hardware vendors\nIncreased transparency, otherwise in-transparency of hardware can lead to security breaches.\nImproved energy use and resource efficiency mitigating suboptimal development of ecological optimisations.\nRisks of not addressing this topic\nLoss of agency within NGI due to dependency on hardware vendors\nInability to deal with overarching issues without market buy in\nLack of responsiveness and lower efficiency in fixing issues due to wrong market incentives.\nInadequate capacity building and development of expertise leads to diminished competitiveness.\n","15":"The NGI Study draft final report discusses the topic of architecture renovation. At the heart of the NGI is architectural evolution that improves upon legacy core protocols of the internet by investigating alternative or auxiliary core infrastructures. This would include projects that are aimed at changing the underlying fabric of the internet and the web itself. Many fundamental issues with resilience and robustness can only be fixed at a systemic level, but the inertia to integrate new solutions into existing Internet is too huge. The matters have been aggravated by the fact that many practical workarounds have been found meanwhile to cater for explosive demand. These workarounds have raised cost, complexity, and even further worsened the known fragility and inflexibility of Internet. The complexity of designing a successful architecture upgrade is easily illustrated by the fact that over half of the life time of the internet has already been spent on the (arguably not very successful) move away from IPv4. Therefore, research and tools to assist in the practical transition or migration to new evolved technologies should also be investigated. Significant effort will have to go into understanding and mitigating the many practical aspects of potential transition from the current internet.\nArchitecture renovation is widely recognised as critically important for the long term vison of NGI, and can provide structural solutions to problems that can only be partially mitigated within the current architecture. NGI Final report advocates the need for catalysing architectural renovation movement.\nWhy?\u00a0Rewriting the ground rules of Internet has a huge effect on higher levels. New ways of Internet addressing that prevent spoofing, a distinct possibility with IPv4, should make it impossible to subsequently brute force attacks. This would for instance change the whole dynamics of currently persistent threats \u2013 such as distributed denial of service by botnets. Similar changes can be envisioned to address other key issues such as mass surveillance capabilities. Modern usage is completely different from the static setup of those days, and key features such as disruption tolerance should not be an afterthought. Research into infrastructure renovation is essential to facilitate the introduction of exciting new capabilities apart from mitigating existing limitations. The more fundamental the new characteristics, the further we may evolve the internet.\nHow? Projects within this banner should investigate fundamental contributions to solving the internet\u2019s challenges. They may question the whole technology stack, the only condition being that they are feasible in terms of technology roll-out and prove their potential to provide lasting answers in line with the NGI Vision. In some cases it will be possible to retrofit novel principles into today\u2019s internet, or to encapsulate current behaviour as an application of the future architecture. In other cases this will be wholly impossible or extremely inefficient. In that case, creating forward compatibility by for instance providing suitable abstractions and mechanisms at the level of end points could be helpful.\nApart from addressing the existential threats from the NGI threat catalogue, potential higher level design goals for alternative infrastructures should be-\nConfidentiality and privacy\nAuditable integrity\nScope isolation of contingencies\nRedundancy and self-repair\nDisruption tolerance\nSmarter asset distribution\nBetter real-time behaviour\nEnergy efficiency\nWithout the movement for Internet architecture renovation, following risks are identified.\nLoss of innovation capabilities and competiveness due to unnecessary technological dependencies.\nRaising the overall cost of future upgrades to the core technologies of the internet (technical debt).\nLoss of diversity, privacy, autonomy and choice for users.\nGiving way to alternative next generation internet technologies incompatible with European values.\nThe entire Internet threat catalogue.\nImprovements to the system have been proposed and even implemented with various degrees of maturity and success over the course of decades. For the architectural renovation to be effective for NGI, infrastructure innovations should take into account how they should be introduced or retrofitted at internet scale. This means technologies should not just exist in a paper, a technical specification at the IETF, or run on an infrastructure test bed in a lab. Their claims and compatibility should be tested in every possible situation in an automated manner. Investing in maintainability\u00a0is vital to achieve that means \u2013 without a strong global deployment strategy inside operating systems, routers and management software, alternative infrastructures do not stand a chance. In addition to such deployments, providing adequate fallback mechanisms is a priority.\n","16":"NGI Interim Study Report recognizes\u00a0smarter assets distribution as one of the traits for an improved alternative Internet infrastructure. Provisioning distributed alternatives to obtaining digital assets from a single source would make the next generation Internet more robust\u00a0in the event of various threats, outbreaks and downtimes. These measures would prevent complete service failure, and contribute to making Internet less forgetful,\u00a0allowing content that would otherwise have disappeared to remain available. Given the common and transverse nature of this issue critical to and effecting all actors from service-providers, ISPs to clients, alternatives complementary to each other therefore should be developed\u00a0and provisioned in parallel-\n\nServer initiated\n\tThe service that offers the assets\u00a0can itself suggest or provide a suitable means of taking care of distributed delivery in case of failure.\n\n\nP2P\n\tEnd-to-end sharing of assets with known friendly peers works even in the most extreme scenarios.\n\n\nCommunity Caching\n\tP2P sharing is not scalable, collaborative caching and sharing of assets instead should be able to provide similar benefits and in a scalable manner. An important requirement is that the sharing facilities shield of the privacy of the participants in the network through a level of indirectness, i.e. caching should not mean that the participants you connect with have interacted with that resources themselves.\n\n\nNetwork caching\n\tThe operator of the network may prefetch assets likely to be consumed within the network when there is surplus capacity, in order to prevent peak usage\n\n\nService-provider driven\n\tIndependent service providers (such as VPN providers) may provide a fall-back service.\n\n\nClient-side asset identification\n\tEfficient de-duplication so that a generic asset already cached or downloaded can be identified and reused over and over again.\n\nThere are a number of ongoing and relevant smaller and larger initiatives that may contribute to the goal of alternative infrastructure, such as the SCION architecture, ARPA2, DPDK and Open Optical Packet Transport.\n","17":"Alternatives to current legacy\u00a0core infrastructure have to be developed in order\u00a0to structurally increase resilience and robustness of Internet at a systemic level. This would provide an opportunity for fixing Internet's known fundamental architectural weaknesses and applying lessons learned in the lowest possible\u00a0layer, resultantly, the whole dynamics of currently considered undefeatable\u00a0threats such as distributed denial of service by botnets and mass surveillance can be changed as well providing a lasting answer from the catalogue of threats dangerous to Internet resiliency. Another benefit is in the high availability of Internet services, be it network or application related. Therefore, the NGI\u00a0goal should be to ensure high availability, resilience, openness and disruption tolerance by providing a resilient, robust and secure routing and transport layer.\nNGI Study Reports recognize\u00a0alternative core infrastructure with following traits\/components to be a feature of Next Generation Internet. A primary challenge for these innovations would be to evolve from testbed and technical specification form, and be deployed in a realistic manner.\u00a0Improving Maintainability and Deployability\u00a0is therefore vital to achieve that means \u2013 without a strong global deployment strategy inside operating systems, routers and management software, alternative infrastructures do not stand a chance.\nPartitioning\/scope isolation\n\tThe ability to segment parts of the network in such a way that issues in one part have no side effects in other parts, which would allow for uninterrupted use outside of any affected areas.\n\t\u00a0\n\nRedundancy\n\tMultiple independent alternatives should be provided to avoid quality degradation and single points of failure. For instance, ubiquitously\u00a0combining multiple user access networks in parallel, a practice generally referred to as multihoming.\n\t\u00a0\n\n\nAbuse Handling\n\tAn important part of maintaining high availability is streamlining and automating how incidents are detected and handled across the network, especially in strongly connected parts or functions. Such a practice would make the overall system more secure\u00a0because it allows for increased responsiveness to changing operational conditions, particularly in time of emergency.\n\t\u00a0\n\n\nRooting out spoofing and amplification attacks\n\tInternet is not very immune to attacks and with minimum efforts can be weaponised to attack itself, citing an amplification attack example that old Internet protocols are still in common usage which will happily answer every request with a response over 4000 times larger. Spoofing therefore has to be kept out from NGI as it provides attackers a huge advantage over those that have to keep their systems up and running.\n\t\u00a0\n\n\nSmarter asset distribution (less fragile and invasive)\n\tDistributed alternatives to obtaining digital assets from a single source\u00a0should be provided to make the NGI more robust\u00a0in the context of various threats, outbreaks and downtimes. Given the common and transverse nature of this issue critical to and affecting all actors from service-providers and\u00a0ISPs to clients, complementary alternatives therefore should be developed and provisioned in parallel. This could be\u00a0from the server-end through means like geo-distributedness, through network or service-provider\u00a0means such as CDN and VPN, or at client-side through caching and providing alternative native as well as 3rd party software to access web resources as discussed in detail in this discussion.\n\nThere are a number of ongoing and relevant smaller and larger initiatives that may contribute to the goal of alternative infrastructure, such as the SCION architecture, ARPA2, DPDK and Open Optical Packet Transport.\n","18":"Flexibility and responsiveness is essential for Internet as a system. Without proper procedures for maintenance and without auditability, a system cannot be expected to be secure and reliable. Internet should be made responsive to changing conditions, support\u00a0efficient deployment of upgrades, particularly in the event of disastrous system failure, performance degradation, changes in workload, or conditions of crisis etc., as advocated by the\u00a0NGI Interim Study report. The systems should also be equipped with periodic self-test procedures in order to check the system\u2019s integration and immunity against various malicious attacks.\nDeployability means that it should be possible to easily distribute and combine new technologies in order to deploy them. A shared delivery methodology for software produced for and required by the NGI will allow the user to easily and instantly switch back and forth between different versions of both software and dependencies. It would also create a shared workflow across all of the NGI projects where one may consistently apply best practices such as continuous integration, code fuzzing and the creation of integrated test suites. The results and failures, as well as collisions across projects, for instance when two projects are working on incompatible patches to an operating system kernel in exactly the same place, would become immediately visible to anyone. These are but a few starting points, the overall goal is to converge systems and to create the distributed capability to make appropriate near-runtime modifications in the event of catastrophic system failure, degradation of performance, change in workload, and conditions of crisis.\nNGI Interim and final reports recognize the need for R&D efforts to be deployable and maintainable in the context of actual Internet environment. A successful approach for NGI would be to create a universal and reliable path to automatable deployment even during\u00a0development. The aim would be having a coordinated approach to get the needed deployments and upgrades on the Next Generation Internet by using realistic transition mechanisms, solving scalability issues, collecting feedback by real time data gathering, and encouraging the right network equipment upgrade capabilities and emergency response procedures. The goal is to ensure resilience, reliability, trustworthiness and sustainability of the NGI. The benefits of a maintainable Internet and increased deployability of NGI projects are-\nWith a coordinated deployment strategy comes increased reusability of efforts and sharing of knowledge arises and beyond projects. Without that, there is a risk that NGI projects would not benefit from each other\u2019s results, and not able to deal with overarching issues.\nLower costs at the project level by shared infrastructure and setups, otherwise subprojects inside NGI will each invent different quality procedures and delivery.\nProlonged unavailability cannot be prevented due to lack of a shared upgrade mechanism across NGI subproject. Thus a coordinated upgrade strategy will increase the efficiency of the overall infrastructure.\nIncrease responsiveness and availability of the Internet\nLower cost of deployment for users\n","19":"The internet needs to be extremely resilient and should be able to cope with many parts of the modern threat landscape. The IETF believes\u00a0\u201cWhenever a new protocol is developed or existing protocols are modified, threats to their security should be evaluated\u201d, (https:\/\/www.rfc-editor.org\/rfc\/rfc4081.txt).\u00a0\u00a0\nDifferent threat categories were identified by the\u00a0NGI Interim Study report\u00a0which need to be considered in order to achieve the vision of NGI, grouped together as 'Force majeure'\u00a0(Natural disaster, Man-made disasters, Adversary AI), 'Technological\u2019 (Cascade of system failure, Spillover from inadequate isolation\/segmentation), and \u2018Human intent\u2019 (Cyber warfare and cyber conflicts, Industrial espionage, Industrial sabotage, Pervasive surveillance and Malicious big data). Here is a brief overview of different\u00a0threat categories:\u200b\u200b\u200b\u200b\u200b\u200b\u200b\n\nNatural disaster:\u00a0Damage to critical parts of the infrastructure (earthquakes, floods).\n\n\nMan-made disasters:\u00a0Intentional and unintentional sabotage, the result of human action, (nuclear explosions, acts of terrorism, vandalism).\n\n\nAdversary AI:\u00a0AI does not understand mutually assured destruction. The risk of non-benevolent or adversary AI to impact the larger system becomes more realistic as AI is handed larger responsibilities, such as handling some of the largest data centres on the planet, (https:\/\/deepmind.com\/blog\/deepmind-ai-reduces-google-data-centre-cooling-bill-40\/).\n\n\nCascade of system failure:\u00a0Many resources on the web and the wider internet are no longer self-contained, but have hard-coded dependencies on resources delivered by third parties, such as content delivery networks and cloud providers. These are used for critical features such as navigation. An outage somewhere in this chain can ripple an avalanche of unintended outages throughout many different systems.\u00a0\n\n\nSpillover from inadequate isolation\/segmentation:\u00a0The combination of different applications and user domains in a single infrastructure mean that the risks of that combined system may end up as the sum of all risks. One submission pointed out a quote by a security manager: \u201cIn a relatively short time we've taken a system built to resist destruction by nuclear weapons and made it vulnerable to toasters.\u201d (Jeff Jarmoc, head of security Salesforce, quoted in a summary article at http:\/\/www.bbc.com\/news\/technology-37738823).\n\n\nCyber warfare and cyber conflicts:\u00a0The Fifth Domain,\u00a0disruption of the internet infrastructure of a region for military and political purposes.\u00a0\u00a0\n\n\nIndustrial espionage:\u00a0Theft of advanced technology from industry, academia and military through exploiting internet infrastructure weaknesses.\n\n\nIndustrial sabotage:\u00a0Disruption and exploitation of internet weaknesses aimed at competing global regions and economic actors, aimed at giving the attacker a competitive edge.\n\n\nPervasive surveillance:\u00a0Mass scale monitoring and long term programmes for pervasive surveillance dating back to the earliest days of the internet have been exposed and\u00a0not all capabilities have been revealed.\n\n\nMalicious big data:\u00a0Passive observation of users by companies without their explicit knowledge and consent is another type of threat.\u00a0\n\u00a0\n\n","20":"In human history, we always tried to reach for the sky. In construction, the foundation is the most important part of the building. Because of its unstable foundation, the leaning tower of Pisa started to sink at the second floor and it took three phases over 199 years to complete. It has had numerous very costly structural renovations during its lifetime, and the straightening of the tower from 5.5 to 3.9 degrees completed in 2013 costed $30m dollars.\nThe ancient Egyptians used their knowledge and past experiences to build the great pyramid in less than 20 years. It was the tallest building in the world for over 3800 years until 1311 and it structural integrity is still intact today\n\nThe same applies to computer networks. Nearly half a century old, 4 layered TCP\/IP design was sufficient enough to fulfil the needs of that time.\n\nThe internet nowadays is built upon the same TCP\/IP stack which has proved to have an inadequate core architectural design for the scale it has grown into. To solve the emerging problems, more and more building blocks were added and a very complex solution is the current result. Today\u2019s Internet is it has bad performances, bad security, hard to build and maintain, and configuration and operational costs are through the roof. In this respect, TCP\/IP is not unlike our leaning tower of Pisa.\n\nMost of the\u00a0services which we are using today e.g. security, QoS etc. are not built-in. It is obvious that the NGI initiative for a human centric network will insert many more services in already overweight layered stack. Thus creating new vulnerabilities and the game will go on. For example, in order to overcome the address depletion problem and to facilitate the ever increasing number of Internet users, IPv6 is brought into network however IPv6 has it's own issues such as exploding routing table size.\nThere is a need for such an architecture that is more scalable, robust and has built-in services like security and QoS. Users and service providers should have the freedom to opt-in or opt-out any service at any time without disturbing the any other user or underlying protocols.\n","21":"HUB4NGI D2.1 identifies some key application areas which are expected to be greatly impacted by the emerging NGI technologies.\nIndustry 4.0\nIndustry 4.0 is a big change as agreed by the experts in \"The Next Generation Internet Workshop\" on \"Widen the European Space of Life and Work\" held on 8th June 2017. It is considered to be the next phase in the digitization of the manufacturing sector. It relies on Internet services and knowledge is largely shared across the network in order to exploit this available knowledge for faster and better robotic learning.\nImmersive Environment\nWith the advancement in AI and learning algorithms, the immersive environments such as Virtual Reality (VR), Augmented Reality (AR) are also expected to be leveraged. However, these new forms of interactions and immersive environments might also face the challenges of data privacy, diversity and the concentration of data into proprietary platforms. Understanding the psychological & biological effects and threats and opportunities for industry and citizens is necessary in the VR world.\nCollective User Experience\nDecentralised, heterogeneous and distributed architectures are important in the next generation digital society. For an enhanced user experience, human-centric technologies need to be identified, propagated and managed. \u00a0\nLifelong Learning\nICT lifelong learning is important in order to raise people's awareness of the significance of acquiring ICT skills throughout their lives.\nInclusiveness\nEach citizen has the right to benefit from modern ICT services and technologies. And the services should be designed in simple and easy to use way so that everyone including persons with disabilities could get benefit. Ubiquitous access to Internet and other ICT services is the right of each citizen just like access to clean water or energy infrastructure. Inclusiveness and ubiquitous connection are the key themes for civil society.\nThe important risk factor is the potential isolation of those behind general levels of connectivity. There is a need to take immediate actions in order to bridge the digital divides and to cope with the digital literacy challenges.\nProtection from the dangers of the Internet\nOrdinary Internet users are not fully aware how deep they are in the Internet. They sometimes disclose very personal information against social engineering attacks. This poses not only data protection problem but also people themselves protection. It is important for emerging NGI technologies to protect people from dangers of the Internet.\n","22":"Next generation ICT technologies are seen as having major impact on our society. The convergence among these technologies such as 5G, SDN, AI, and NFV is highly important. The NGI infrastructure and architecture will have significant challenges of low latency, higher throughput and secure communication, therefore the development of new network protocols should be the core of future R&D efforts. Because of the new networking approaches, and higher demand of interoperability, security may be built within the networking protocol.\nHUB4NGI D2.1 identifies following technologies as important for NGI and gathers the citations for each of these.\nInternet of Things (IOT):\nIoT is marked as the top technology driver by the number of sources. From the results of a large scale survey of European citizens, IoT, Big Data and machine learning are considered to be the most promising technologies which may have larger impact not only on peoples' personal lives but also in the labour market.\nAt the Digital Innovation Networks (DIN) Forum held on 27 June 2017, from the opinions expressed by experts, almost 80% of participants expressed IoT as the key technology driver for NGI.\nBlockchain & Distributed Ledgers\nAlthough still not very familiar to most people, however, blockchain and distributed ledgers are widely being considered as revolutionary technologies. At the Next Generation Internet workshop - \"Widen the European space of life and work\" held on 8 June 2017, it was highly recommended that we have to adapt and understand blockchain technology and for this purpose training is very important. A research on better compression algorithms is also very important to make this technology more efficient.\nThe participants in a large scale survey expressed the potential for a financial revolution from these technologies. At the Digital Innovation Networks (DIN) Forum held on 27 June 2017, the experts agreed that a pan European blockchain should be included in the new areas of research and experimentation such as IoT programmability, robotic devices, large scale streams etc.\nBig Data\nBig Data is also seen by the European citizens as the most promising next generation technology.\nEdge Computing\nEdge Computing is considered as top-priority technology area by 30% experts at the Digital Innovation Networks Forum held on 27 June 2017.\nAI and Autonomous Machines\nAutonomous machines, as defined in the Digital Innovation Networks (DIN) Forum in 2017, are intelligent self-driven machines (robots) that are capable to sense their surrounding environment, reason intelligently about it, and take actions to perform tasks in cooperation with humans and other machines in a wide variety of situations on land, sea and air.\nWith the development and proliferation of autonomous machines, a paradigm shift will occur within the Industrial IoT domains towards Edge Computing, in which programmable, autonomous IoT end-devices can communicate with one another and continue to operate without connectivity.\nArtificial Intelligence and autonomous machines are expected to have major impact on our society. With the advancement of machine learning, AI will play an increased role in our daily life (e.g. self-driven cars, semi-automated justice systems etc.).\nOpen Data\nDiscoverable and easy to process data is important from the perspective of start-ups. There is a need to develop and \"open link\" in order to overcome the challenges of format interoperability among data representation and data sources.\nCloud Computing\nAlthough cloud computing pose some security and privacy threats however it is important because of many reasons. For both education and business, cloud solutions are seen as a great opportunity. In order to overcome the challenges of security, privacy and surveillance, new security built protocols could be designed to support new business and social domains.\n\u00a0\n","23":"An inclusive digital single market means an internet\u00a0that breaks down language barriers, that connects and empowers every citizen and business across Europe.\nAn internet where services are available in multiple languages, accessible to all. A\u00a0public, open and interoperable European language grid that connects resources and tools, combining and sharing them across a network of people.\u00a0\nThe sheer volume of content, diversity of content types and languages spoken in Europe makes the roll-out of multilingual solutions challenging.\u00a0\nYet, herein lies an unprecedented opportunity for Europe.\nThe work programme 2018-2020 of the European Commission's next generation internet initiative includes an Innovation Action for a European language grid.\nExperts are called upon to develop the architecture and components for an open and interoperable language grid by developing and deploying language technlogies - software and services - across Europe.\nThis Innovation Action will, among other things, encompass easy access to basic natural language processing tools and services for European languages with end-users of the grid closely involved in the process.\u00a0\nWork Programme 2018-2020: ICT-29-2018\n\u00a0\n","24":"It\u2019s Saturday night and you\u2019re just getting home after a great night out. To get your keys you turn on your Apple flash light. Nothing could be simpler, after all you're just opening your front door, right? \nWrong! Your movements can be followed through tracking tools but do the app developers really need to track your location? Absolutely not. This is just one of many examples of design by deception as Kai Rannenberg, Chair of Mobile Business and Multilateral Security at Goethe University, pointed out at ICT2018. \nIn a nutshell, today\u2019s app markets are not informing us of what they track or when. Users have no way to check this behaviour. To turn things around, we need improvements on several levels:\n1. Trustworthy hardware.\n2. Robust mobile operating systems.\n3. Privacy-friendly apps giving users control.\n4. Better app markets informing users better about the apps and the consequences of using them.\n5. Neutral evaluation of relevant system properties so the average person can understand and make informed choices. \nWe need to create a world where every citizen can understand privacy settings and their implications. A \"trustworthy communicator\", including an app market that informs the citizen-consumer is informed about data flows and security levels.\nConsent forms are very long lists and hardly anybody reads the terms and conditions. These conditions are expected to change for apps with the GDPR and ePrivacy laws in Europe, but we need much more debate on how technologies are developed and related business cases. \nDo you have other examples of \"deception by design\"? How concerned are you about data flows and user control? \nJoin the debate by adding your comments below.\n","25":"\"The dramatic changes, which came with the technology like IoT, AI and Blockchain often focus on \u201cthings\u201d and not on people and therefore leaves Citizens out of the City. \nOur solution integrates smart buildings with a modular and scalable platform (Smart Buildings\/SB platform) to proactively engage with citizens. \nOur solution is complete: from IoT devices in homes and buildings (Home Energy Management, Smart home, Building energy management) through user interface (with building, city, service providers) and includes also a \u201cdigital wallet\u201d in the form of a mobile application, which is seamlessly connected to the platform and enables users the execution of payments and secure storage of the platform utility tokens (tokens are not stored on the application but on wallets in the cloud, whereas the mobile application is the interface to the actual token usage). \nThis approach by using engagement tokens would allow to manage City by managers of the platform to incentivise users to active platform usage to contribute. \nMatevz Baskovs, ETOS solutions, https:\/\/www.etos-solutions.com\/en\/sb-platform\/\n","26":"Silvana Muscella: Opportunities & challenges of NGI in the words of the public (consultation)\nNGI is a cross-disciplinary effort, for a human-centric approach to the future internet.\nNGI funding is  a wonderful opportunity for start-ups, SMEs and centres of excellence across Europe that are active in the various domains encompassed by NGI and the increasing convergence of technologies such as blockchain, AI, immersive media, cyber security.\nWhere are we with SMEs?\n\u201cWe have been active in European Research and Innovation for over 10 years and have witnessed first-hand how the areas of artificial intelligence, content interaction and access developed towards the human centric vision of NGI. Future Internet initiatives like FIRE, and more specifically Experimedia, BonFIRE and Fed4Fire, have provided our SME with unparalleled opportunities to experiment with new technologies, explore new business ideas and turn them into successful product innovations. We are excited to be part of the NGI Community as we believe this to be a key enabler and growth catalyst for European businesses.\u201c -- George Ioannidis, Director of IN2.\nWhere are we with technology developers=\n\u201cAs facility control and automation players we tangibly see the strong impact of 5G, from design to business modelling & go-to-market strategy - that is the strategic reason we strive to keep being part of the 5G PPP\u201d - Nicola Ciulli, Head of R&D @Nextworks\nWhere are we with citizens?\n\u201cImagine you have a heart attack and you need people to access your medical history, where would you like them to go?\u201d \u2013 Alessandro Bassi President IoT Italy \nInteractive discussions: need for multi-stakeholder dialogue\nCecilia Bonefeld-Dahl, DIGITALEUROPE: the technology policy process needs to embrace the views of different stakeholders, exchange different views and reduce the gap with citizens so they have a better understanding of what the technologies can actually deliver and how we will benefit. A lot of knowledge is in the hands of the private sector and can play a key role in conveying the benefits.\nSilvana Muscella, Trust-IT: with the Waterford Institute of Technology, we have been working with civil society to make sure their voice is heard. One example of this is the participation of the International Civil Society Centre in the NGI Champions Panel, with an NGI Salon at Global Perspectives 2018. We are also working with Mission Pubbliques to bring in the views of civil society.\n","27":"Internet is key to most of our lives, changing the way we interact with each other, transforming all sectors of the economy. It will continue to drive all elements of society and the economy, including improved living, safer mobility, better health while enabling new business opportunities. \nWith a solid legal and regulatory framework in place, Europe is well positioned to play a leading role in shaping the internet and ensure it embeds European values like democracy and inclusiveness. \nEuropean investments in technologies like 5G as the underlying infrastructure, blockchain, interactive and immersive technologies and cyber security will help Europe stay at the forefront of game changing developments. Alongside this, we need to ensure protection of user privacy and security, control over data, privacy and security by design.\nInvestments in NGI is creating an environment where Europe can shape the next generation internet. These investments will give opportunities for new entrants to funding and the chance to work alongside with industry and specialised research institutes in areas like\n- decentralised data technologies\n- privacy-enhancing technologies\n- trustworthiness of electronic identities\nThe next generation internet will also need to tackle online abuse so we're all safer on line.\nKey to all this is mastering the complex value chain, including connectivity assets, IoT, new service approaches of butt and edge computing, ensuring digital inclusion, accessibility to content and devices so we deliver more to people.\nPearse O'Donahue, European Commission\nDiscover the funding opportunities here:\nICT2019: H2020 2019 call topic n1 - Strengthening Internet Trustworthiness\nhttps:\/\/consultation.ngi.eu\/taxonomy\/term\/140\nH2020 2019 call topic n2 - Service and Data Portability\nhttps:\/\/consultation.ngi.eu\/taxonomy\/term\/141\nH2020 2019 call topic n3 - Open Internet Architecture Renovation\nhttps:\/\/consultation.ngi.eu\/taxonomy\/term\/142\n","28":"#ICT2018 Networking Session: Let's create the next generation internet - it's ours to shape!\nNGI in Austria: focusing funding on societal and legal developments in sync with technology developments\nOliver Hoffman, Austrian Ministry for Infrastructure, presented the recent national calls in relation to NGI topics. It is recognised that the projects not only address technology developments, but must also focus on societal and legal developments. It is well known that the latter lags behind technology\u2019 developments, so the motivation in our calls is to better synchronise those developments from the very start. Thus, the funding on national level in Austria focuses on the inter-disciplinary nature of NGI challenges. If you have a technology innovation, the legal and social motivation might not be there and need ramping up and included from the start. Austria had a first call on this in 2017, entitled ICT of the Future with a funding of \u20ac500, 000 - these are the projects presented during the ICT2018 Networking Session. In 2018,  funding has increased to \u20ac700,000. \nNGI in EU: Driving NGI with new research and innovation actions\nAndres Sanchez Sandaza, presented LEDGER, one of the RIAs funded in the last NGI call addressing Decentralised Data Governance. Subtitle of LEDGER is \u201cThe Venture Builder for Human centric solutions\u201d. More info will soon be available at http:\/\/www.ledgerproject.eu. Some information is already available at http:\/\/ngi.eu\/opencalls\/. The concept is to have 32 projects covering topics like privacy by Design, Open software, as well as decentralised technologies such as blockchain, peer to peer, and distributed ledger technologies. The winners of the cascading funding (open calls) will also receive mentoring and support from senior experts along the road to market and MVP. It is expected that the best 16 projects will get to the final phase and receive more funding, up to a maximum of \u20ac200,000.\n","29":"#2018 Networking Session: Let's create the next generation internet - it's ours to shape!\nKatrin Mathmann \u2013 Foodnetlab project: using NGI approaches for the food industry, which is quite conservative and needs to be brought into NGI systematically so it can benefit from NGI technologies in the future. The project only started 8 weeks ago and 2 weeks ago held its first focus group meeting with 50 industry partners, mainly from Austria and from producers, feeders, breeders, retail, and network. The next stage is to include government players, policy makers, plants. A survey will ask people in companies to rate the impact factors of NGI from their perspective. In the next step colleagues will make a \u201cgame\u201d to show society and get feedback on how citizens see see it, telling us acceptance levels and how much it is liked. This concept will then be turned into an innovation laboratory in Austria, where people from the network can co-create new projects for the food industry. NGI plays a key role in giving the big picture and on how co-creation can be effective. \nMario Drobics, COMPASS \u2013 Cooperative Design Spaces for Next Generation IoT Solutions, which has received funding from the ICT of the Future program of the FFG and the BMVIT. The project wants to see if the societal values can be translated into the business values. http:\/\/compass-project.at\/. The project wants to see if they can make new products based on these values, and ensure a transparent process. They also want to bring it to the policy makers so they can use the knowledge as part of the decision making process for future funding. \nExpedite project: Exploring Opportunities and challenges for Emerging personal Data Ecosystems: Empowering humans in the age of the GDPR \u2013 a roadmap for Austria.  We need a paradigm shift to get the data out of the silos and figure out how to better use data to benefit society. Small companies face challenges with the GDPR. Expedite is a roadmap that will lead to further projects later on. The project is multi-dimensional and will work with social scientists, technologists, lawyers, etc. to determine the new opportunities on how to use data in a way that benefits humans and understand what kind of support is needed to fully realise these benefits.\nChristoher Frauenberger, TU Vienna Winner of the NGI Research & Education Award. Christoher is part of the COMPASS project, motivating his application to the NGI award.  His work is looking at the deep connectivity between the data economy situation and how it needs to be re-thought of at all different levels. Research will tap into the many resources of Aarhus University, where they have many experts in the necessary mullti-disciplinary fields and he is very grateful for the opportunity being offered by winning the NGI award.\nMirko Presser described the next round of the NGI Awards. Aarhus University is very much looking forward to hosting the winners and bringing NGI technologies and social elements to real life. It will be very cross cutting at Aarhus University, involving technologies, sociologists, legal experts, etc. This dimension is very much reflected in the winners of the last round of the awards. This is expected to continue with the next round of NGI Awards being run again by NGI Forward project in 2019. You are welcome to apply for this!\n","30":"#ICT2018 Networking Session: Let's create the next generation internet - it's ours to shape!\nMarina Mortara, Researcher, InterIoT project (Interoperability of Heterogeneous IoT platforms):  working on the decentralised and mobile monitoring of assisted livings lifestyles. InterIoT is using advanced technologies dealing with overweight and obese issues for citizens. It is looking at innovative ways of evaluating the risk of cardio illness via data collections using everyday smart phones,. These technologies could be extended in the future other citizens. \nEduard Grasa, RINA, Recursive InterNetwork Architecture: working on an environment where users can roam through wireless networks in an internet that is secure by design, powerful but simple enough without needing artificial intelligence (AI) and machine learning (ML) to manage it. RINA seamlessly integrates networks in a powerful way. RINA is the outcome of collaborative work between the EU and National Science Foundation in the US, with i2Cat playing an instrumental role. \u201cPerfection is not achieved when there is nothing left to add, it is achieved when there is nothing else to remove\u201d. \nJohannes Klingmayr, Linz Center of Mechatronics GMBH: making money from data. Today's approach is not the right one. Compare it with napster, where they were taking music and just giving it away. A better idea is to use spotify\u2019s approach, which can only be done when knowledge is captured through knowledge engines. It's not just for big companies as everyone can create knowledge engines. We are suggesting to move from the Internet of Data capture to the Internet of Knowledge Engines. This moves away from the approach of Internet monopolies. This is a better match with EU values: more heterogeneous and strengthening networks of knowledge engines.\n","31":"Public and consortium blockchains are widely considered to be disruptive innovations by enabling new market and low-end market footholds.\nConsortium networks can be the preferred blockchain architecture for businesses because they enable partners to retain control of certain rights while reaping the benefits of a decentralised network. \nBut what kind of business model can support blockchain innovations? Well, the decentralised focus of blockchains means that traditional centralised business model canvases are not really fit for purpose. Blockchain will also have multi-dimensional impacts on the four dimensions of business models to unleash new opportunities. \nOut with the old - in with the new. Some key aspects to consider:\n1. Blockchain can enable increased operational efficiency, the removal of intermediaries in transactions, micro-economics, crowdfunding, digital ownership and authentication of assets.\n2. Blockchain's democratising effects can empower users and create a shift in power structures between providers and users.\n3. Users can be increasingly engaged in both value creation and the infrastructure needed for value delivery.\n4. Blockchain can change the role of trust. Businesses need to have a greater focus on customer relationships.\n","32":"As CEO of a dynamic ICT intensive SME, I will be talking \"Straight from the NGI's mouth of the people\"  providing some key concepts around our discussion topics. \nIntroducing the benfits for a savvy SME to get involved in NGI, touching upon multiple business models for the future, how SMEs can play a role in 5G trials & verticals for the future and;\nfinally seeing how NGI will ultimately act as the (very much) needed commodity (enabler) for EOSC to achieve its ambitious goals of new open science cloud. \nFeel free to comment below on the above or if you're an SME tell me about your experience so your voice can be heard during the session.\nJoin me @ICT2018 on Wednesday 5th December @ 14:30. See you there !\n","33":"Though a bit old but very relevant and worth reading article about an enormous multibillion-dollar industry based on the collection and sale of our personal and behavioral data:\nhttp:\/\/content.time.com\/time\/printout\/0,8816,2058205,00.html\n\u00a0\n","34":"In an EU project (http:\/\/www.automat-project.eu) we have developed real-time data marketplace where thousands of car sensors automatically publish real-time data, which is streamed through channels and subscriptions to the interested service providers. During the post project exploitation phase we are facing the issue of consent management. The current mechanisms do not seem practical. Any suggestions or links to recent research for this topic?\n","35":"When 150 people made their way to the NGI Forum 2018 in Porto, they were not expecting to make tricky decisions about weaponised fridges, defensive measures against bots attacking democracy and \u201cgenerous\u201d offers of free educational tech for schools. But this is exactly what they were asked to do in a workshop organized by NGI Engineroom project with an aim of articulating a new vision for the internet. Central to this vision are the values Europeans want to see reflected in the way the internet works.\nThese values include privacy, trust and unlocking the promise of data for the common good. However, realising all of these values is difficult, because some of them are in conflict with each other and because we need to decide where to focus our energy. Engineroom project ran a workshop to get participants in the Forum to think about these issues and gather their insights, which will help inform our own thinking about the future internet, and the values it should champion. Detailed insights from the workshop are available here.\n","36":"Have the courage to use your own reasoning, Immanuel Kant (1724-1804)\nDisinformation, deliberately false and misleading information, causes public harm. We have seen how in recent years malicious intentions to misguide voters in electoral campaigns risk undermining democratic processes. Hate speech is fuelling discrimination and intolerance across the internet and society.\nDisinformation, malinformation and misinformation are eroding trust in internet users and creating fast-emerging risks.\nWe need to level the playing field and protect our European human values.\nEurope is driving discussions on these and similar issues in a debate that is open and evidence-based to ensure diversity of information, freedom of speech and privacy as a fundamental human right. EuroDIG 2018 is offering an important forum for debate.\nMany studies are taking place across Europe and the Council of Europe is setting down recommendations but actions are need to help citizens make more informed decisions about how they how use the internet. Citizens also need to be able to read information critically with digital literacy initiatives in place across all member states.\nTechnology innovations like blockchain, artificial intelligence and cognitive algorithms are important in implementing a pre-emptive approach by enabling faster identification of content verification.\nBut we also need a coordinated international response to these challenges, bringing together civil society, the private sector and the technical community to work towards a framework of voluntary practices, more research to understand the problems and the risks, citizen guidance to help differentiate between fact and fiction.\nKey take-aways from #EuroDIG18 sessions on privacy.\nFollow these discussions at the European Dialogue on Internet Governance online\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n","37":"User-friendly mechanisms to overview transparency of Internet services should be provisioned for end-users, such as - transparency on the security situation of a connection, background processes, data collected and observed or data retention. These mechanisms may also provide tweaking options empowering the user to define custom and desired security levels. This will lead to higher trustworthiness of the Internet with the effect of enabling innovation and creativity.\nBenefits\nSupporting safety of EU citizens and their data\nImproving transparency for consumers\nEnsuring business continuity and social connectiveness\nUser empowerment leading to higher innovation\nAbility to verify adherence to EU laws\nLevel playing field between good actors and malicious actors\nRisks of not addressing this topic\nLack of knowledge leading to vulnerability if businesses and citizens relating to the abuse\/predation of data\nLack of trust regarding how data is handled, lowering the usage of the system and hindering innovation\nHigh cost of law enforcement in Digital single market\n","38":"Typically Internet users do not possess much understanding of security issues and ways to protect oneself as user. There is also lack of trust in technology that hinders economic growth. There is a need to develop standard interaction patterns to allow declarative interaction. By standardising popular interaction patters, users only have to passively declare the desired interaction, and do not have to bother the user with permission to run unverifiable scripts on a web page. The users will have the right to be off-line when using connected devices, as well as using safe content profiles or generic profiles for revealing personal information. This will lead to higher openness and trustworthiness of the Internet with the effect of enabling innovation and creativity.\nSafe Content Profiles\n\tFor the end users, safe content profiles need to be implemented. The original design of the web as a set of documents where one can safely surf from link to link, has been lost over time due to the rise of demanding applications that appropriated the technology to get system agnostic interfaces. As a result, document are now no longer safe. When a user browses an unknown website, he or she typically grants the operator the same technical privileges as a bank or trusted software supplier would need \u2013 browser have not been given the native abilities to distinguish among known and unknown. Browsing the internet, the risk of abuse is very significant. Availability of a safe content profile (e.g.. return of the web document) would provide a subset of features that is known to be secure and passive, which would guarantee the end users are not attacked while they just want to read a document.\n\t\u00a0\nDomain Isolation\n\tDomain isolation, which is another part of the securing the browser environment, should be provided between websites. This will minimize the amount of observational data about a user between their use of different websites\u00a0 unless the user explicitly makes the connection. There is a real need for users to be in control of what the application software inside their device and the sensors are revealing about them to the outside, such as their location or life habits. There is a need to provide generic profiles for revealing personal information. A user should be able to silence or randomise sensors, or to have his GPS module give inaccurate data about his whereabouts to app that do not need such intimate information\n\t\u00a0\nHardware security\n\tHardware should also be protected from abusive monitoring. There should be mandatory hard switches for embedded cameras and other devices. Cameras and microphones are particularly invasive, and a high profile target for abuse. Users should be able to physically switch of cameras and microphones they are not using, so that they can be 100% safe from the emergence of sudden software flaws or security glitches. Furthermore, users should have the right to be IoT off-line including environment. People should not be forced to use invasive technologies by their employer or other persons that have authority over them. Encryption is the single most important technological building block of Internet security. The rigjht to encryption should also be universally established.\n\t\u00a0\n","39":"Everyone has the right to deserve respect for his or her private\u00a0life, home and communications. Trust is the key driver for human interaction. Identity and reputation are characteristics which should be an intrinsic part of the internet infrastructure, yet any such unbiased shared infrastructure is lacking. Market-driven mechanisms in this already are opaque and predatory, and tend to reinforce already problematic market imbalance and unfairness. In addition, these produce undesirable side efects such as passive profiling and exposure to corporate surveillance. In order to secure end-user rights, the NGI needs to create decentralised internet-wide identity mechanisms, distributed reputation options and ensuring viable means of extending end-of-life of software and software-enabled devices. A better protection of users starts with the ability to distinguish users from each other. The goal is to improve the trustworthiness of the Internet and the sustainability of software and devices making use of it, which builds the levels of trust for the Internet to be levered in innovation.\nFurthermore, there is a need to look for the alternatives of naming system.The DNS system is known to leak a lot of detail about the behaviour of users to third parties, including public DNS operators and wifi hotspot operators (and since these are known to be very unsafe, to anyone). DNS is regularly used as a tool of censorship and in some cases surveillance. A dual strategy of hardening at the one end and shifing to fundamentally more secure and private solutions at the other is recommended.\n\u00a0\n","40":"Today cooperation of good guys against the brotherhood of hackers is fragmented rather than a principle. Too often companies and other entities are reluctant (for good reasons) to share security related information. Prevailing principle is: what is inside my walls is my business, the rest of the Internet including my customers, does not concern me. Plus everyone handles security patching themselves, or leaves it until later. No surprise that most security breaches take place using known vulnerabilties for which patches exist. The hackers can keep on using the same resources agaist many potential victims.\nTo change the picture, in www.re2ee.org we are proposing a solution made of several components\n- cooperative firewalling (customer edge switching)\n- realm gateway for interoperation with the legacy Internet\n- ubiquitous policy based admission of all flows\n- homomorphic trust processing in trust domains (correponds to gossipping behind the back of people in society)\nHere communications security policy = desciption of what a host expects. Policy creation should be as automatic as we can make it.\nThe approach has numerous benefits like: no unwanted traffic is sent over the air to wireless hosts, NAT traversal is dynamic (ICE is only a fall back option) leads to fast and easy session setup, all security logic is at the edge leading to better scalability, better use of private addressing improving overall network scaling, limiting the actions it makes sense for hackers to program into exploits, fast traceback of all resources used by attacks, limiting the lifetime of those infected resources, scaling of the firewall itself due to use of SDN principles in the design etc...\n","41":"Internet is the fabric of modern communication. Privacy and confidentiality are essential human rights - at the heart of both the\u00a0UN Universal Declaration of Human Rights\u00a0and the\u00a0European Convention of Human Rights. People entrust their most private and intimate information to travel safely across the internet - to their loved ones, to journalists, politicians and lawmakers. Governments and businesses trust critical parts of their operations to the internet. The shocking revelations from whistle-blowers like Edward Snowden have made it very clear that this shared trust in the internet has been naive and undeserved, and that weak parts of the design of the internet have being systematically abused at a scale beyond comprehension. It has become very clear that the internet was - knowingly - kept incapable of handling the actual threats since the earliest days of the internet, which has put the world at risk. The ground work for pervasive surveillance now serves industrial espionage, cybercrime, and sabotage - and who knows what else. Technologies driven by data hunger rather than user needs have made the web unsafe.\u00a0\nThe NGI initiative wants to create an Internet that deals with this severe crisis in the only way possible: move on and fix it. An internet that is non-partisan, and at its very core serves shared human values. NGI seeks to craft an internet that is resilient, trustworthy and sustainable. Part of that is preventing any systematic leaks of metadata and communication profiling of users. The following aspects related to NGI activities on confidentiality have so far been suggested and brought out by the\u00a0NGI Interim Study report-\n\nRouting Layer Confidentiality:\u00a0The routing layer of TCP\/IP Internet architecture is vulnerable against man-in-the-middle attack and passive observation. The communication pattern can be exposed even when common end-to-end encryption is used. There are known solutions to this vulnerability and need to be further investigated and developed for more confidentiality.\n\n\nNaming System Hardening and Alternatives:\u00a0The current Domain Name System (DNS) system is also vulnerable to leak user activities and behaviours to third parties. DNS is regularly used as a tool of censorship and in some cases surveillance. A dual strategy of hardening at the one end and shifting to fundamentally more secure solutions at the other is recommended.\n\n\nSearch and Discovery:\u00a0One of the most problematic areas for confidentiality is search and discovery. Current search tools have shown that they leak a great deal of private information about users.\n\n\nProvide end-user security transparency:\u00a0Not every connection is the same. Users should be able to grasp the overall security situation of a specific connection.\n\n\nProtecting users from malicious data observation:\u00a0Passive observation of users by companies without their explicit knowledge and consent, which includes storing the complete browsing history of users, location data, media consumption, shopping behaviour, cross-device identification of users, stealth identification of other users in the vicinity, undisclosed audio streaming for off-site analysis, persistent identifiers, etc.\n\n\nDevelop new safe web standards:\u00a0As security attacks like Rowhammer, Meltdown and Spectre prove, allowing to running unverified software on web pages poses a dire risk to the user. By standardising popular interaction patterns, users only have to passively declare the desired interaction, and do not have to bother the user with permission to run unverifiable scripts on a web page.\n\n","42":"Cybersecurity will be the most pressing challenge of the next decade. Inadequate management of cyber threats will put users increasingly at risk, undermine trust in the Internet and jeopardise its ability to act as a driver for economic and social innovation. Disproportionate government responses will threaten freedoms, and contribute to a climate of fear and uncertainty. The ISOC report on \u201cPaths to Our Digital Future\u201d released in 2017 brought attention to the fact that we need new models to increase cybersecurity readiness and reduce vulnerabilities but also to ensure end-user security.\u00a0The complexity and scope of cyberattacks necessitates multi-stake holder and expertise-driven responses for the digital economy to thrive and for trust in the Internet to be rebuilt.\nThe scale of cyberattacks is steadily growing, and many anticipate the likelihood of catastrophic cyberattacks in the future.\nAs the Internet becomes intertwined with national security, cyber offense and defence strategies will shape the future Internet for industry and individual users alike. Acts of cyber conflict will be coupled with disinformation and propaganda to destabilise states and economies. The threat of destructive cyber conflict will only increase over the next decade. Conflicts will be initiated not only by nation states, but also by their surrogates, and by independent political movements and private actors. For the open Internet to continue as a platform for social and economic growth, users must be able to trust that the government agencies and businesses collecting and using their data are resilient and will address cybersecurity threats adequately.\u00a0\nNeither government nor the private sector can deal with the scope and scale of cyber threats alone. Driven\u00a0by the need to be seen to be \u201cdoing something\u201d\u00a0in the face of ever-bolder cyberattacks, we expect that government responses to cybersecurity challenges will be increasingly reactive. Effective action and building network resilience towards cyber threats will only come through information sharing, strategic thinking and collaborative efforts among stakeholders.\u00a0\nThe way stakeholders adapt to future cyberattacks could change the Internet from an open and collaborative Internet to a fragmented, closed\u00a0but \u201csecure\u201d network environment.\u00a0\nThe pressure to put \u201crules of the road\u201d in place will continue, but it is unclear whether governments will prioritise cross-border cooperation over\u00a0national sovereignty and security. Financial markets, elections and health care provision will not be immune to cyberattacks and cybercrime in the future.\nRead full report here \n","43":"The future of AI depends on security and trust. The future AI technology could also help to address security challenges. The ISOC report on \u201cPaths to Our Digital Future\u201d released in 2017 highlighted this issue. As networks and traffic streams become increasingly complex, AI can help network managers to understand traffic patterns and create heuristics that identify security threats. At a basic enterprise level, AI can perform tasks normally carried out by an IT helpdesk, such as troubleshooting employee computer problems. In this way the IT professionals will get more time to implement security best practices and better secure their systems and networks.\nAs the AI needs large amount of computational resources and data, because of that, it is possible that the computing and storage resource need to be redistributed to meet the requirements of the technology which could also impact on the Internet architecture.\n","44":"When considering highly interconnected networks, it is clear that trust, security and privacy are the prominent concerns. The Fire Study DIN 2017 looked at technology drivers and found IoT and 5G to be the key components. The focus was on the need to understand the trust, security and privacy concerns within NGI regarding the interaction of humans and autonomous, manual and remotely operated machines. There is a need to look deeper at the security threats even for liberal governments as cyber security will become impossible to secure because of the ease of connectivity as the internet of Things becomes ever more prevalent. More urgency is needed on this.\u00a0\nWill end-users know the how much privacy, if any they could have when using a service? Should open source software be checked by NGO\u2019s, trusted parties? Should a decentralised trust be set up? The dominance of social networks begs the questions, should they be broke up? Should they pay for content? Are citizens informed, do they understand what social networks do with their content? Who, if anyone will be accountable for machine learning, for data management?\n","45":"The power balances between providers and users created by IoT and Big Data needs to be framed by European values, as discussed at the workshop on Personal Data Spaces and Privacy.\nIoT is an opportunity but also creates a concern regarding privacy. Cloud solutions may well be an opportunity for Education and Business but they are also seen as a potential major threat for Privacy, Security and Surveillance. Could this be a space for designing interventions to support new business? This was explored in the large-scale survey of European citizens, titled Citizen Engagement and Media Campaign on the Next Generation Internet.\n","46":"At the workshop on Personal Data Spaces and Privacy, there was a discussion about how people need to better understand the effects of giving away personal data. There is a belief among citizens that when we're getting free services, we don't have to think about our data.\u00a0\u00a0There is a need to give more attention to the debate about privacy, at the political level, or market forces will prevail.\u00a0\u00a0\nAnother aspect which was debated at the workshop was the issue of transparency and to what extent users were aware of the level of privacy they get when they access service.\u00a0\n","47":"One of the topics raised in the Hub4NGI D2.1 deliverable that is worth discussing further, is a lack of control over Data.\nThere is a considerable fear that citizens\u2019 privacy is being eroded by the exploitation of citizens\u2019 personal data by profiling, and citizens have no control over this.\u00a0At the DIN Forum 2017 there was concern that the dominators of the Internet economy; Facebook, Apple, Amazon, Netflix, Google, are using and selling our personal data.\nAccording to the Lipparini & Romeo \u00a0there are a lot of conversations about preserving net neutrality and equal access to the Internet, or making sure that user privacy, security, and data ownership are preserved, and that data based profiling doesn\u2019t result in manipulation of people or the democratic process. Once you give you're data to a provider, it is out of your control. Exacerbating this problem is the fear around the difficulties encountered when citizens want to manage their privacy. Even when citizens know where their data has been processed, it is not easy to exert any control over how the processing is done, or to prevent processing.\u00a0\nThere is a strong feeling about the right to know who had collected your personal data and who controls it. The need for all EU countries to formalise this through legal channels was discussed in Poznan Supercomputing and Networking Centre, The Next Generation Internet workshop - Widen the European space of life and work. Workshop Report, 8 June 2017\n","48":"What is your opinion on GDPR in context to NGI?\nI see it as a big chance to improve the protection of the users privacy, but on the other hand it is a big burdon for companies with all the new regulations, and especially with the fear to get huge fines. I see little support for SMEs and high personal risks for SME owners due to the potential high fines.\u00a0\nHere are three concrete questions to open the\u00a0discussion:\u00a0\na.) Who\u00a0will get sued first? Big players like FB or Google, oder public bodies or SMEs?\u00a0\nb.) Will citizens value the better protection of their privacy or will they simply don't care and complain about beeing asked more often to agree on use of their data?\nc.) Or is this just a big incident destroying our global competitiveness?\u00a0\nLooking forward to read your opinion.\u00a0\nManfred\n","49":"The story behind the video that was used to prove the \u201cinappropriate behavior\u201d of CNN reporter Jim Acosta towards a White House intern, leading to withdrawal of his press pass, is a sad yet dramatic example of how technology \u2013 and not even IoT in this case (see the debate around the edits that apparently may have been made to the video https:\/\/twitter.com\/PrisonPlanet\/status\/1060521980615634944) is just a means in the hands of the \u201cnet\u201d.\nAs \u201cAt issue here is how video speed and frame rate affects the human ability to perceive force,\" said Britt Paris, a researcher with Data & Society studying audio-visual manipulation. \"Context matters, and time and duration is an oft-overlooked part of context that helps us interpret the content of a video.\"\n\nCan NGI technology help us identify whether a video has been tampered with?\n\u00a0\nSource: https:\/\/www.wired.com\/story\/infowars-video-white-house-cnn-jim-acosta-tw...(1)&utm_medium=email&utm_source=nl\n\n\u00a0\n","50":"At the\u00a0NGIForum 2018,\u00a0Prof.\u00a0Jamal Shahin (VUB and GIPO) led this discussion on tackling online disinformation.\nProf. Shahin represented\u00a0the weight of the disinformation crisis by citing an example of how some kids believed that Titanic was burnt upon watching an Youtube video. In the wake of this, Prof. Shahin\u00a0presented some illuminating statistics, only 2% of children have the critical literacy skills they need to tell if a news story is real or fake, half of teachers (53.5%) believe that the national curriculum does not equip children with the literacy skills they need to identify fake news. Two broad questions to handle this issue were raised -\u00a0What critical skills do we need to have to overcome disinformation?\u00a0and what tools do we need to overcome disinformation in the NGI?.\nA number of challenges related to tackling online disinformation were presented -\u00a0Skills (digital literacy); how to reach out into the Public sphere and the news media ecosystem;\u00a0tools, techniques and algorithms required for overcoming disinformation; and where does\u00a0the liability or responsibilty lies.\nProf. Shahin also involved the audience of NGIForum in an interesting poll about how to face online disinformation. A number of answers were recorded from the participants on the following possible solutions:\n\u2022 Through self-regulation (5.2\u00a0\/10);\n\u2022 Through support to quality journalism (7.7\u00a0\/10);\n\u2022 Through regulation (5.0\u00a0\/10);\n\u2022 Through education (8.7\u00a0\/10);\n\u2022 Non-intervention \u2013 the marketplace of ideas will deal with it (2.8\u00a0\/10).\nHuman Values, Challenges, Solutions, Initiatives, Gaps and R&I needs related to Tackling online disinformation are listed below.\nThe following Human Values were identified in relation to this topic\n\nV1. Authenticity\nV2. Authoritative\nV3. Diversity\nV4. Transparency\nV5. Trustworthiness\n\nThe following Challenges were identified in relation to these Human values\n\nC1. We are living in a world of sensationalism and negativity [V1, V2, V4, V3]\nC2. Advertising does not equal content trustworthiness (e.g. google a product and you may find a review that is a hidden advertisement disguised a review) [V1, V2, V4, V5]\nC3. Creation of needs is still largely based on or driven by large entities [V3, V5]\nC4. Authority of the platform [V1, V2, V5]\nC5. Information overload [V3]\nC6. Open \/ Democratised Algorithms [V3, V4]\n\nThe participants identified a number of Potential Solutions to address the challenges\n\nS1. Reputation meter for ranking information [C1, C4, C6]\nS2. Control (at certain times) [C6]\n\nA number of known initiatives \/ projects were identified addressing the solutions\n\nI1. Global Internet Policy Observatory (GIPO)\nI2. Fact-checking organisations [S1]\n\nIdentified Gaps\n\nG1. Education [C1]\nG2. Integration between technology and human intervention [S1, S2]\nG3. Means of control [S2]\n\nR&I Needs to fill the gaps\n\nR1. Supervisor (AI supported) [I2]\nR2. Who is addressing the human \/ social effect\n\n","51":"At the\u00a0NGIForum 2018, a workshop was organized on\u00a0Better search for trustworthy content and objects discovery.\u00a0Mr.\u00a0Ale\u0161 \u010cernivec, (Project Manager,\u00a0XLAB d.o.o.) led this discussion session on tools and concepts for search and discovery based on the Slovenian Interoperability Framework.\u00a0\nXLAB d.o.o. ( a Slovenian company)\u00a0has gained significant experiences in building knowledge management services and portals. They built the\u00a0Slovenian interoperability portal\u00a0hat allows public authorities (PAs) to publish their solutions and make them discoverable to citizens.\u00a0Legislation and openness of public sectors data allows citizens to look in to PAs operations and better trust them.\u00a0Citizens have the means to develop new solutions based on searchable and existing information at their ready disposal. The institutions producing the data thus also become more aware of their responsibility leading to the improvement in data quality, quantity and management. The portal contributes to\u00a0\u00a0Slovenian open data portal\u00a0which provides a single point of access for easier search, analysis and linking of the data.\nMr. \u010cernivec presented on search and discovery tools from the perspective of the Slovenian interoperability and open data portal, in particular covering security, ID management, authentication and authorisation frameworks, data sharing and safeguarding privacy.\u00a0The presentation focussed on the technologies involved and also highlighted the human values to be considered while developing these technologies. The human values of importance to this topic include openness, trust, security, revision (transparency), and responsibility. In words of Mr.\u00a0\u010cernivec,\nExperiences gained show that the technology allows us to manage the knowledge easier and faster, produce new content faster; and human values can now be powered by the technology and Next Generation Internet should make knowledge management easier, more dynamic, discoverable.\u201d\nHuman Values, Challenges, Solutions, Initiatives, Gaps and R&I needs related to Interoperability framework and open data portals are presented below.\nThe following Human Values were identified in relation to this topic\n\nV1. Openness\nV2. Trust\nV3. Security\nV4. Transparency\nV5. Responsibility\nV6. Inclusiveness\nV7. Awareness\n\nThe following Challenges were identified in relation to these Human values\n\nC1. Legislation on openness of public sector data [V1, V4]\nC2. Increasing trust and revision [V2]\nC3. People engagement [V7]\nC4. Improvement in data quantity and quality and management [V5]\nC5. Education [V5, V7]\nC6. Advantages on the market (for small and big players) [V6]\nC7. Fragmentation (objects) [V1, V2, V3, V4, V5]\n\nThe participants identified a number of Potential Solutions to address the challenges\n\nS1. Distributed Ledger Technologies (DLTs) [C1-C4, C7]\nS2. Certifications [C2, C3, C5]\nS3. Excluding blockchain\nS4. Micro-services oriented solutions [C2, C6]\n\nA number of known initiatives \/ projects were identified addressing the solutions\n\nI1. Public Service Initiative (PSI) [S2]\nI2. NIFO [V4, C2]\nI3. JoinUp\nI4. Open Data Portal\nI5. ISA2\nI6. My Data Hub\n\nIdentified Gaps\n\nG1. Usability, Accessibility [V1, V3]\nG2. Business Models on data [C6]\nG3. Transparency on retaining data [V4, C1, C2]\nG4. Skills (HR) [V1, V5, V7, C3, C5]\nG5. Sources of funding [C6]\n\nR&I Needs to fill the gaps\n\nR&I Needs to fill the gaps ->\nR1. DLTs [V1 \u2013 V4]\nR2. Survey supporting NGI [V1,V4,V6]\nR3. Consultation platforms for citizens [C3]\nR4. Semantic search [V4]\nR5. Specialised Search (IoT, Big Data, AI,\u2026) [G5]\n\n\u00a0\n","52":"At the\u00a0NGIForum 2018, Mr. Alexandru Stan from\u00a0In-Two, Germany provided the viewpoint of SMEs in relation to their participation to the Next Generation Internet initiative (NGI):\u00a0 Are\u00a0SMEs\u00a0important for NGI? Can SMEs create the impact in trustworthiness of content alone?\nSpeaking on the first question, the importance of the role of SMEs in the NGI initiative was especially highlighted\u00a0since they have a critical role to play in the value chain of innovation, in which they are constantly experimenting, and rapidly bringing new innovative things to the market. They are well positioned and have a guided view on how to design solutions that are \u201cPeople centric\u201d and \u201chuman centric\u201d, as to succeed as an SME, it is necessary to come up with real solutions that make sense to solving real world problems.\nIn response to the second\u00a0question, it was felt that SMEs do not play well alone.\u00a0Researchers need the collaboration with SMEs in order to make their innovation an industrial success. Industry can push the innovation process behind research organizations. Mr. Stan highlighted the\u00a0Marconi project\u00a0for an example of excellent collaboration between research and industry, in particular SMEs, within the combined fields of radio & media. IN2 is an SME working on developing content-rich applications with trustworthiness and quality of content, and collaboration with research institutes\u00a0for them provided stimulating results, according to Mr. Stan.\nHuman Values, Challenges, Solutions, Initiatives, Gaps and R&I needs related to Search and Discovery (SME perspective) are presented below.\nThe following Human Values were identified in relation to this topic\n\nV1. Openness;\nV2. Access;\nV3. Inclusiveness;\nV4. Trustworthiness.\n\nThe following Challenges were identified in relation to these Human values\n\nC1. The trend of moving towards echo chambers and walled gardens, and how this differs from the ideas of an open internet [V1, V2, V3, V4];\nC2. Content without the proper context or content with the wrong context [V4];\nC3. The need to raise the profile and reputation of SMEs producing solutions in the larger setting against the large players, who have a dominant role [V3];\nC4. Coming up with a peer review or reputation strategy to make it clear to customers that what SMEs are doing is trustworthy [V3, V4]\nC5. Trustworthiness for the entire value chain in large scale systems \u2013 how to ensure all steps along the way are verifiable in real time (some examples from smart Agriculture, smart pharma were highlighted where if one sensor was giving incorrect readings, the whole system is compromised) [V4].\n\nThe participants identified a number of Potential Solutions to address the challenges\n\nS1. Less is More (e.g. \u201cA-Social networks\u201d);\nS2. Conversation vs. \u201cEngagement\u201d;\nS3. Publish (on your) Own Site, Syndicate Elsewhere (IndieWeb);\nS4. Trade off: Convenience \/ Privacy;\nS5. Selective serendipity (i.e. giving the algorithms an opportunity to step out of the models);\nS6. Developing transparency into peer to peer reputation systems, making them more trustworthy \u2013 connect with experimental platforms such as smart cities initiatives, Fed4Fire, and other experimental facilities would enable raising of profile and reputation of results coming from the NGI programme [C4].\n\nA number of known initiatives \/ projects were identified addressing the solutions\n\nI1.\u00a0Caprice community\nI2. European Trusted Cloud Platform of EIT Digital; e.g.\u00a0My Data Store\u00a0of Telecom Italia. Also see Trusted Cloud Platform with FSecure, experimenting with an offer of Security as a Service (now available commercially\u00a0HERE). In-Two have integrated this in one of their solutions so that our customers could have secure and trustworthy content hubs, building search and discovery on top of the trusted content only. [C5]\nI3. Pharma industry are working on some elements of the E2E verification process but needs more R&I [C5, S6];\nI4. FIWARE context broker, which is a central component of the FIWARE platform, would it address the challenge related to mapping the content and context in relation to the content. [C2]\n\nIdentified Gaps\n\nG1. How to make sure the context for the content is correct and evolving? [C2, I4]\nG2. Lifespan of the content and whether it is evolving according to the correct contex? Some challenges to address are a) Gaining reputation from today\u2019s models could take too long; b) Need to develop new ways to quicken the process e.g. having reputable review trusted authorities and\/ or certification processes. [C2]\nG3. Need to look at the end to end harvesting of data to ensure there is no corruption of data anywhere. [C5, S6]\n\nR&I Needs to fill the gaps\n\nR1. Detailing correctness and authenticity of entire value chain verification mechanisms (some work started in smart pharma and smart agri, but much more is needed for NGI); [G3]\nR2. Could blockchain technologies be used to address these gaps in such a low power based system: is it feasible, either technically or economically? [G1 \u2013 G3]\n\n","53":"At the NGIForum 2018, a workshop was organized on\u00a0Better search for trustworthy content and objects discovery.\u00a0A specfic discussion in the workshop was positioned on\u00a0how we need new ways of storing, understanding and releasing data based on the semantics of the data itself and the context within which the data exists.\n\u201cWe have many options how to store our data (cloud, device, edge, NAS). But is it better to rely on local external devices or buy a cloud space somewhere? Imagine you have a heart attack and you need people to access your medical history,\u00a0where would you like them to go?\u201d\nThis discussion evolved from the idea that our current means of storing and releasing data lack\u00a0any insight into the meaning of that data, the context in which it is in use, and reliable set of rules governing how that data can be used or shared given that context in addition to automated mechanisms to enforce those rules.\nHuman Values, Challenges, Solutions, Initiatives, Gaps and R&I needs related to Semantic Data Organisation are presented below.\nThe following Human Values were identified in relation to this topic\n\nV1. Privacy\nV2. Trustworthiness\n\nThe following Challenges were identified in relation to these Human values\n\nC1. Contextual awareness of data [V1, V2]\nC2. Technology challenge: Organising Data through meaning (Files Systems) [V2]\nC3. Automatic Extraction of Metadata [V2]\nC4. Cloud vs Location assurance [V2]\nC5. Device Data vs Personal Data [V1, V2]\n\nThe participants identified a number of Potential Solutions to address the challenges\n\nS1. AI to understand context [C1, C3]\nS2. Sticky Policies [C4, C5]\nS3. Data Licencing [C1, C5]\nS4. Personal Data Rules [C4]\n\nA number of known initiatives \/ projects were identified addressing the solutions\n\nI1. CocoCloud project [S2]\nI2. Creative Commons licencing [S3]\nI3. Picos [S4]\nI4. Personal Data Vaults [S4]\n\nIdentified Gaps\n\nG1. AI to extract semantic meaning [P1, C2, C3]\nG2. Education of Creative Commons plus extensions to CC type licencing [S3]\nG3. Solutions to contextually manage data release [S1, S4]\n\nR&I Needs to fill the gaps\n\nR1. Remote \/ Automated enforcement of data handling rules [G3, S1]\n\n","54":"Enabling unbiased and privacy-respectful discovery of content, services and metadata on the Web, also in a real-time local context. This will lead to higher trustworthiness of the Internet for the users, more openness of content and enhancement of creativity and human potential through alternative access to various types of content andservices.\nThe internet and especially the web are constantly changing, as billions of people add, shift, modify and remove content and services. To find their way around, internet users heavily depend on a small set of active intermediaries such as search engines, social networks and platforms. This strong dependency carries a number of very signifcant risks:\nan intermediary may (either intentionally or non-intentionally) act as a gatekeeper (block certain things),\nexhibit an unfair (economical, political, social or other) bias and,\nintimately track, analyse and influence user behaviour.\nAt internet scale, looming dominance of a few large intermediaries is fed back into the decision process during creation and promotion decisions of content and services. This leads to a vicious cycle which reinforces dominance and as such has huge implications for the open nature of the Next Generation Internet. Allowing for bottom-up means of fine-grained discovery as well as shared metadata and other forms of enrichment and aggregation of content and services is essential to create alternatives. By making low-level discoverability an essential characteristic of the edges of the system, rather than something controlled by intermediaries.\n","55":"In his blog, the commissioner Ansip is commenting\u00a0that Germany was the first country to pre-notify EC, in February 2017, about its eID scheme, completing its formal notification in late September. More recently he also comments that Italy was the second member state to do this, and that Italy\u00b4s national eID scheme SPID is led by Italy's private sector:\nhttps:\/\/ec.europa.eu\/commission\/commissioners\/2014-2019\/ansip\/blog\/milestone-towards-establishing-eid-and-trust-services-europe_en\nhttps:\/\/ec.europa.eu\/commission\/commissioners\/2014-2019\/ansip\/blog\/online-trust-italy-blazes-trail-eid-scheme-led-private-sector_en\nShould eIDAS compliance be obligatory for all EU projects? How to speed up uptake of eIDAS compliant identification and aiuthentication by private service providers?\n\u00a0\n\u00a0\n","56":"Before embarking on a long discussion about what's needed in relation to D&I Tech, does anyone have recommendations for a good landscape overview? Discovery and Identification has been done in multiple EU (and other) projects to date...\n","57":"At the NGI Forum 2018 in Porto, a session was led by\u00a0Marta Arniani\u00a0(futuribile \/ curating futures) on behalf of the NGI Move project on the topic of \"A secure, decentralised Internet\".\nThe session consisted of 4 sessions debating on different challenges in making of a decentralised Internet. In one the session,\u00a0Pablo Ojanguren, founder and CTO of\u00a0Swell RT\u00a0spoke on the\u00a0unbalance of data relationships in the digital market.\nThe data-based relationships between users (consumers) and companies isn't fair.\u00a0\u2028\nUsers don\u2019t really control how their data are delivered to service providers, which gather\u00a0them through centralized channels (user interface, web or app) and process them.\u00a0\u2028Also, the information returned by the service can be only consumed in one controlled way. It is like buying shoes that you can only wear in the streets allowed by the vendor.\u00a0\u00a0\n\t\u00a0\n\u2028Another case of unbalance is when organizations can handle our information automatically but we cannot handle theirs in the same way.\u2028 Should these commercial relationships of data be\u00a0legally regulated? \u2028Could we legally force service providers to give APIs to allow users to retrieve its data or to decide where its data must be stored?\u00a0\u2028\nWhat would happen if users could get raw data from service providers? Would that be\u00a0helpful?\u2028 Here is where real decentralization apps can help. A\u00a0single user couldn\u2019t extract much more value from its data by itself (or service\u2019s data). But people could aggregate their\u00a0data in a peer-2-peer platform to operate them. In cases like Uber, for example, it would bring opportunity for drivers to be organized in a kind of p2p digital union driven by data that could allow better self regulation.\n\u00a0\n\u00a0\n","58":"At the NGI Forum 2018 in Porto, a session was led by Marta Arniani (futuribile \/ curating futures) on behalf of the NGI Move project on the topic of \"A secure, decentralised Internet\".\nThe following priorities for a decentralised Internet emerged from the session.\nOpenness and security: the infrastructure must ensure fair data handling and trust\n\t\u00a0\nDecentralised business models\u00a0(distributed, not leveraging massively data extraction): for instance, most Initial Coin Offerings, or ICOs, propose in another format the walled garden pattern from which blockchain technology was supposed to take us away from.\n\t\u00a0\nPertinence assessment:\u00a0the appropriateness of decentralised infrastructures has to be proved case by case and where positively evaluated, tailored to the specific needs of entire industry verticals. Blockchain isn\u2019t a one-size-fits-all tool.\n\t\u00a0\nSustainability:\u00a0environmental, economical and political sustainability has to be designed in such systems from day 1.\n\t\u00a0\nCapacity building: more literacy on the topic means more expert people able to maintain the system decentralised and innovate on top of it, as well as better awareness at citizens\u2019 level.\n\t\u00a0\n","59":"At the NGI\u00a0Forum 2018 in Porto,\u00a0a session was led by\u00a0\u00a0Marta Arniani\u00a0(futuribile \/ curating futures) on behalf of the NGI Move project on the topic of \"A secure, decentralised Internet\".\nThe main challenge that echoed out\u00a0from the session is to avoid the concentration of data (and power) in the hands of a few dominant players.\u00a0Big corporates have limited interest in empowering their users, but are undoubtedly more competitive than decentralised solutions in the user experience. The challenges to be tackled in this run are building trust in decentralised systems, as well as creating a strong community around the topic while supporting a larger upskilling and literacy. Moreover, citizens will need to better understand what value they can extract from their personal data and become more responsible in managing them.\nThe session consisted of 4 debates led by experts -\nfair and responsible data management (Pablo Ojanguren,\u00a0Swell RT)\npeer to peer approach for a truly decentralised governance (Antonio Tenorio,\u00a0P2P Models)\na better economic model for our society (Alex D\u2019Elia,\u00a0Mangrovia Solutions)\na more effective and trackable public funding mechanisms (Sanyu Karani,\u00a0Funding Box)\nThe following major challenges were output of each of the debate.\nA decentralized infrastructure is not a sufficient condition for a decentralized world. Indeed, many Blockchain applications are build with the objective of becoming new monopolies, the winners that will take all off the markets to come\u00a0(Antonio Tenorio, P2P Models).\n\t\u00a0\nToday the whole process of getting public funds takes in average 24 months.\u00a0Two years make a brilliant idea obsolete. Blockchain could help shrinking the process to 24 weeks, keeping the procedure transparent, efficient and public. Blockchain-based funding delivery will be tested in the upcoming NGI calls for decentralised technologies and the requirements for it should be decided upon.\n\t\u00a0\nEconomic models for the new Industrial Revolution:\u00a0The Token economy in the new Blockchain industry is promoting a new model of \u201cdecentralized power\u201d for a better wealth redistribution. Is it enough to use decentralized technologies to foster a better economic model for our society? How can these technologies help us step into the new Industrial Revolution and accelerate the transition?\n\t\u00a0\nUsers don\u2019t really control how their data are delivered to service providers, which gather\u00a0it\u00a0through centralized channels (user interface, web or app) and process them. Moreover, the information returned by the service can be only consumed in one controlled way. It is like buying shoes that you can only wear in the streets allowed by the vendor\u201d (Pablo Ojanguren, Swell RT).\nA trending topic at the event was around Blockchain. Blockchain is strongly emerging as an infrastructure appealing to all types of industries.\u00a0Despite the decentralised nature of blockchain, the business models related to decentralised technologies are still extremely centralised and reinforce the revenue and power of a single player. The real bearers of decentralisation though are governance and business models which should be focussed rather than technology.\n","60":"One of the activities of an expert workshop run by the Engineroom project in March 2018, was to examine challenges for a set of umbrella topics. \"Internet and Data Sovereignty\" was one of those topics and\u00a0four distinct areas of discussion were elicited:\nGeneral thoughts;\nChallenges;\nOpportunities;\nExamples.\nInternet and Data Sovereignty\nDescribed as: Currently a lack of control over personal data. Decentralised data governance. New standards around data portability and interoperability.\nGeneral thoughts\nAmbiguity around the term \u201csovereignty\u201d, maybe we should talk about agency.\nNot only focus on empowering individuals but also at a collective and community level.\nBe aware that with control we also bear responsibility.\nRisks and questions about consent and traceability need to be addressed.\nChallenges\nHow to make data understandable and attractive for humans.\nLack of data portability\nLack of plurality due to concentration of data.\nAs privacy becomes a commodity, there emerges a challenge on inequality.\nData boxes giving control back to users are difficult to execute securely and efficiently.\nHow do we build trust in leveraging data sharing for social good?\nOpportunities\nData commons models empower citizens in controlling their own data.\nRequirement for tools providing transparent and accessible interaction.\nData commons models allow for a more pluriform landscape.\nFree and Open Source models should be promoted at a European level.\nExamples\nIndigenous communities in South Africa and Australia\nthe DECODE project\nBBC Databox\nMyData conference.\n","61":"Greetings,\nI've had for 5\/6 years now the feeling that most of the efforts for open, decentralized, privacy-friendly alternativesive to centralized social networks are as cool as unable to make any real difference, in useful time. I feel that such projects are too complex and\/or not \"packaged\" in the right way to make them really usable by ~99.99..% of Facebook users. If they were, Facebook would have not doubled its users in the same 5\/6 years.\nI started proposing my own vision of a \"first aid\" but concrete solution in 2013: percloud, that is \"PERmanent\/PERsonal CLOUD\". Now I have just updated it, and would really like to see it implemented (with or without my own personal involvement is irrelevant, see links below) and in any case get feedback. Therefore, I suggest that Open Internet NGI programmes support development and promotion of perclouds and \"percloud as a service\", as described in these two pages, and the links they contain:\nPercloud proposal, 2018 version\nWhat is the difference between percloud and...\nThank you in advance for any feedback, and help in promoting the proposal.\nBest Regards,\nMarco Fioretti\n\u00a0\n","62":"Fixing asymmetry in data governance was a\u00a0topic mentioned in the Wednesday webinar. Perhaps I misunderstand what this means, but\u00a0in our current economic system large corporations, such as Google, benefit from hoarding the information they are collecting from us and other companies, and only selectively releasing it back to the rest of us. To me it looks like that fixing this problem would require fixing the economic system itself.\nAs discussed by e.g. Juliet Schor [1] and Alex Pazaitis et al [2]\u00a0and indirectly by Jeremy Rifkin [3], our current economic system, including the very structure of money (see e.g.\u00a0[4]), is not up to date in aligning the public societal interests and private interests. In general, information is an anti-rival good while the tangible\u00a0things that our life depends on, like food, are rival goods. That is, if I ate a cake, you cannot eat it too, but if I utilise a piece of information, you can do that as well. As Schor, Pazaitis and the others argue, money \u2014 as we know it \u2014\u00a0evolved to serve the exchange of rival goods, leading to what Adam Smith called the \"invisible hand\" aligning the interests of the society in the large with the interests of private actors.\u00a0 That is the very reason why our capitalistic system works in the first place.\nWhat comes to information, this alignment no longer works. From the societal point of view, the more efficiently we distribute information, the more efficiently the real economy can work. However, we do not have proper structures to motivate companies to share their information.\u00a0 Of course, the original idea of the patent and copyright systems were to incentivise companies to share their information through giving them exclusive rights for a limited time. However, that has been later watered down and shown not to work as originally intended.\nSo, returning to the asymmetry in data governance, could it perhaps make sense to create new incentive structures \u2014 somewhat similar to what money and rival goods exchange is \u2014\u00a0that are specifically designed to incentivise efficient sharing of information.\u00a0 That is, to create structures that make it more beneficial to share all of your information than to keep it as a \"trade secret\"? \u00a0\nThat may come about as completely utopian and impossible, but as Pazaitis et al argue [2], there are already attempts to do this within the community and crypto currencies movement.\nNow, I am wondering\nif such a radical approach to information asymmetries and decentralisation is too far fetched for the ICT-24 call, and if not\nif there are any others here who possibly might want to collaborate with us in this area?\nIn the case someone is interested in more direct discussion, I can be reached at pekka dot nikander at aalto dot fi.\n[1] Juliet Schor, Plenitude, 2010\n[2] Pazaitis, de Filippi, Kostakis,\u00a0Blockchain and value systems in the sharing economy, 2017\n[3]\u00a0Rifkin, The zero marginal cost society, 2014.\n[4]\u00a0McLeay, Radia, and Thomas,\u00a0Money creation in the modern economy,\u00a02014.\n\u00a0\n","63":"Dear all,\nI'm a researcher in Semantic Web technology at Ghent University \u2013 imec, Belgium.\nWe're want to address the ICT-24 call with a Web technology stack, emphasizing:\npersonal data spaces, i.e., a very large number of individual data pods on the Web with relatively few data.\n\tFor example, every single person stores his or her own profile, posts, pictures, health data in a personal data pod with very strict access control.\napps as interchangeable views, i.e., the data exists independently of the Web applications that use it, and data is shared across applications.\n\tFor example, I enter my address book once in my own data pod, and it is used by Contact apps A, B, C, by Meeting Planner apps\u00a0X and Y, and by a Birthday Reminder app Z.\nThe important part in this vision are separate markets for data and apps. I describe that vision in detail here:\u00a0https:\/\/ruben.verborgh.org\/blog\/2017\/12\/20\/paradigm-shifts-for-the-decentralized-web\/\nThe technologies we aim to use are:\nCore Web technologies\u00a0(HTTP \/ HTTPS \/ URI, \u2026) and output from related W3C working groups (micropayments, \u2026)\nLinked Data (RDF \/ SPARQL \/ JSON-LD)\nblockchain \u2013 not as a holy grail \/ hype, but specifically as trust and incentive mechanism between personal data spaces\nOur intention is to use the funding for three aspects:\nlow-level technology \/ infrastructure, focusing on data pods and caching\/replication\nmany different\u00a0decentralized applications on top of that infrastructure\nresearch into economic, legal, privacy aspects\n\u00a0\nWe are looking for collaborators to help turn that vision into a strong consortium and proposal.\nLet me know if you're interested!\nRuben\n","64":"One of the topics raised in the Hub4NGI D2.1 deliverable that needs to be addressed by NGI research topics is that of \"Decentralisation of Control\".\u00a0 A visualisation of the key factors is provided as shown here:\n\nDecentralisation of Control: Key Factors\nThe report provides evidence from multiple sources including the 2017 DIN Forum Report which acknowledges that the GAFA (Google, Apple, Facebook, Amazon) incumbents are in such a dominant position that it is difficult for European start-ups to compete. The NGI should enable alternative business models and infrastructure to support alternative solutions to the current centralised service offerings.\nThe Hub4NGI deliverable also cites input on the subject from the Report of the Policy Workshop on Next Generation Internet,\u00a0Centre for Science and Policy, Cambridge Computer Laboratory from March 2017. Participants in that workshop raised concerns about how the GAFA incumbents were in fact best positioned to exploit emerging AI techniques and \"further entrench their market dominance\". The workshop also discussed how the principles that were the drivers for the TCP\/IP protocols, namely lack of ownership and content agnosticism, no longer reflect the current situation in the Internet. The report\u00a0of the NGI public consultation published in March 2017 echoes this concern noting that 80% of participants agreed that it was important to \"limit the increasing power of dominant platforms aggregating data\" and that 74% saw decentralisation as a means of avoiding monopolies. The consultation report also indicates that participants felt strongly that \"the Internet should ensure diversity, pluralism and a right to choose\".\u00a0\nTo what degree does the current ICT-24-2018 call for proposals address these issues? What could future calls also include in this area?\u00a0\u00a0\n","65":"I recently attended the COST-CONNECT workshop entitled \u201cAn interdisciplinary approach on the Next-Generation Internet\u201d, held on 12-13th September, 2017, in Brussels. The event was jointly organised by the COST programme and DG CONNECT of the European Commission with the purpose to bring together the COST and DG CONNECT projects working in relevant areas to NGI topics.\u00a0\nDuring the world cafe session part of the event, I led a group discussion pondering a question\u00a0on how to adequately balance a \u201ccitizen centric\u201d Next Generation Internet in an environment where the business models are largely based on the data economy, which uses citizens\u2019 data as a replacement for payment fees or subscription charges.\nIf we are truly trying to\u00a0ensure the internet of the future is truly citizen-centric,\u00a0then we need to address the quandaries such as how do you give people power and control over their data in an internet, which today is largely based on the data economy and making money from this data, are adequately balanced and fully addressed. For example, decentralised data governance in the NGI is key to empowering the citizens in terms of knowing fully what their data is being used for and by whom. That is why it is one of the core selected topics in the upcoming WP2018 for NGI.\u00a0\nIf you are interested in this topic, or want to add to the discussions, please do so. We put together a nice team working on this topic at the COST-CONNECT workshop and we would very much like to hear your views on how to address this important challenge for the NGI.\n","66":"Distributed architectures for Decentralised data governance\nMany of the discussions on decentralised data governance focus on regulatory and policy perspectives, but as Fabrizio Sestini pointed out in his blog on the next generation internet, it's time to look into ways to engineer\u00a0new network architectures as a way to re-address\u00a0the balance of power held by a few global aggregators.\u00a0\nDominant data platforms have extremely centralised architectures, especially at the level of data governance. The key question is whether technological solutions enabling an intrinsically decentralised data governance break the \"rules of the game\" that have made current data incumbents successful.\u00a0\nThe shift would come from distributed architectures that enable the fully decentralised storage and management of data. In such a scenario, peer-to-peer technologies and distributed ledgers technologies would enable a fully decentralised certification and security of transactions: monetary exchanges and data exchanges.\nCurrent projects exploring the challenges and opportunities include Decode (among others) but the topic is now also part of the EC's Work Programme 2018-2020 (draft) on the next generation internet, specifically ICT-24-2018-2019: NGI - An Open Internet Initiative. R&I Actions closing in 2018\nDecentralised data governance:\nleveraging on distributed open hardware and software ecosystems based on blockchains, distributed ledger technology, open data and peer-to-peer technologies.\npaying attention to ethical, legal and privacy issues, as well as the concepts of autonomy, data sovereignty and ownership, values and regulations.\u00a0\nOf interest to experts in:\nRelevant technology fields.\nResearchers\/professionals\u00a0working on legal and ethical aspects.\nOpen data communities.\nIf you have the expertise in relevant technology fields, legal and data governance to address this challenge? Then join us in driving the debate on NGI\n","67":"Hi All,\u00a0\nI thought it might be interesting to\u00a0zoom in on what AI means for 5G networks and the challenges that need tackling to realise the benefits, other challenges and on-going work on standardisation. Inspiration for this post comes from\u00a0Yue Wang, Samsung UK.\u00a0\nSmart connectivity will combine AI with IoT and 5G, with potentially significant impacts on the production of future intelligent services and products. The convergence of these technologies is expected to transform how industries innovate and operate, including transport systems, smart cities, health monitoring and entertainment. Many AI applications will rely on 5G in the future, from virtual reality (VR) and augmented reality (AR) to autonomous vehicles and robotics.\nHowever, we are still some way off, as Yue notes in her article, Key Factors Driving the Adoption of AI for 5G and Beyond.\u00a0\nWhen #AI in network becomes large scale, we need to consider not only how to use AI to enhance network efficiency but also how to efficiently use #AI. The reusability of data and AI modules, the synergy among them as well as with the network - scalable and deployable #AI.\nIn summary, the 3 major challenges are:\nThe data challenge - lack of relevant and mature data sets for AI in the network. This challenge requires the industry to adopt a unified approach with a common language as key to the correct interpretation of data sets from the large-scale 5G infrastructure.\nThe reliability challenge - lack of confidence in the reliability of the AI solution. This challenge needs a benchmark for assessing the various AI solutions, as well as validation and integration across the network end-to-end.\nThe deployability challenge - lack of scalability and deployability of existing AI solutions. This challenge needs the validation, integration and network deployment of AI solutions that are scalable and use unified data sets.\nThe key to the market using AI for 5G and beyond network operation and management is the deployability of the AI solutions IN the network. Because existing solutions are designed for specific parts of the network, problems and applications, they work in isolation and lack scalability. The industry, therefore, needs to work towards a strategy for AI solution development and scalability with unified data sets, validated, integrated and deployed in the network. Such an approach is key to improving both network efficiency and efficiently using AI with re-usable data and AI modules, creating a synergy across them and with the network. This takes us back to the need for uniform data use across the network, the use of common tools and the availability of platforms for validation and integration.\nOn the research front, we need to focus on\u00a0AI to develop solutions dealing with safety, privacy, security and trustworthiness. Pressing issues within AI include compliance with privacy regulations, tackling bias in algorithms, mitigating risks and threats with suitable techniques and methods.\nWe also need to tackle the societal challenges that AI poses, including compliance with privacy regulations, bias in AI algorithms, transparency, right of verification, risks and ethical issues, safety, privacy, security and trustworthiness.\nIn this respect, future research and innovation (R&I) actions need to look at societal readiness levels, and not just technology and market readiness levels. This is a key point also raised in SpeakNGI.eu discussions with European stakeholders working on robotics while also noting the fascination of small children (aged 5-10) on robots during the International Robotics Festival (September 2018, Pisa). In our view, more work is needed to understand the societal readiness levels across age groups, class systems and countries.\nBesides this, AI needs industry collaboration across domains for applications in transport, medicine, finance, robotics, manufacturing and others should become a top priority. Other synergies could come from AI technologies in terms of market segments, and benefits from AI, analytics, big data, the Internet of Things (IoT), among others.\nOn the standards front, we are engaging with ETSI and the chair of the\u00a0Experimental Networked Intelligence group (ETSI ISG ENI), which is defining a cognitive network management architecture, using AI techniques and context-aware policies to adjust user offered services based on changes in user needs, environmental conditions, and business goals. ENI ISG is developing standards for a cognitive network management system aimed at delivering a metric for the optimisation and adjustment of the operator experience over time by taking advantage of machine learning and reasoning. Using the \u2018monitor-analyse-plan-execute\u2019 control model will enable the system to adjust the offered services based on changing conditions. The group is also considering a gap analysis of work on context-aware and policy-based standards with other Standards Developing Organisations to re-use existing standardised solutions for legacy and evolving network functions wherever possible. Its work plan also includes adding closed-loop AI mechanisms based on context-aware, metadata-driven policies to more quickly recognise and incorporate new and changed knowledge, and hence, make actionable decisions, in day-to-day-operations, as well as security and a closed loop learning policy-model.\nOne of our Early Adopters, Ray Walshe, is helping drive AI standardisation within ISO, the international standards organisation, and IEC, the International Electrotechnical Commission (IEC). Here, work\u00a0is undertaken in JTC\/SC42, which has set up a systems integration committee offering guidance on AI applications to IEC, ISO and JTC1 committee. It draws on the support of committees looking into horizontal and vertical areas. As AI matures, JTC\/SC42 is adopting a broad approach looking at the full AI ecosystem and beyond traditional interoperability. On top of this, it is running several projects on big data, foundational AI, AI trustworthiness that also encompasses use cases and AI governance applications.\nThanks for reading and commenting!\n","68":"Artificial intelligence, or AI for short, has the potential to revolutionise our lives but we need to understand its real-world benefits and plan its usage carefully in Europe.\nThat\u2019s why the European Commission has published two important reports:\n\nA coordinated plan on artificial intelligence.\n\n\nNew guidelines on how to deal with the ethical issues.\n\nBoth reports put humans at the centre of this key technology as it\u2019s essential to use AI to help humans and not develop it for its own sake but make sure it serves the greater good of society.\u00a0\nHere we take a look at the European coordinated plan and new funding for AI, giving some examples of what is already being developed and testing.\nEuropean Funding and Coordinated Plan for Artificial Intelligence\nThe EU has been supporting Artificial Intelligence (AI) for many years but now plans to boost investments through the next funding programme, Digital Europe (2021-2028). It is expected that \u20ac2.5 billion will be made available to spur development and uptake across Europe and beyond. The funds come on top of the \u20ac1.5 billion being invested between now and 2020 to help drive European leadership on AI. Expected investments from member states and the private sector could bring this figure close to \u20ac20 billion in the same period. It\u2019s essential that member states and the Commission work together to maximise investment impacts and drive Europe\u2019s competitiveness.\nHowever, funding is not for funding\u2019s sake but part of a coordinated plan on artificial intelligence, setting out how the EU plans to target investments and coordinate the development of AI across the EU with a strong focus on human needs.\nHere are some of the ways innovators can benefit from the new plan starting in 2019\n\nMaking \u20ac100 million available by 2020 to support European AI start-ups.\n\n\nBuilding networks of European AI research centres of excellence to improve cooperation between the best teams in Europe.\n\n\nCreating a common European Data Space with a focus on healthcare enabling re-use of data by innovators, businesses and the public sector.\n\n\nDeveloping an AI-on-demand platform pooling knowledge and expertise to expand access to existing body of work on AI in the EU.\n\n\nAttracting and retaining skilled AI professionals in the EU.\n\nSnapshot of AI developments and Testing in Europe\nWith the plan in mind, it\u2019s important that innovators across the public and private sectors have a good idea of what is already being developed and tested on AI, thus avoiding unnecessary overlap. Here\u2019s a snapshot to get you started.\n(Semi-)Autonomous driving \nRoad accidents have huge societal and economic impacts, and are a major concern for public safety. As human error is the main cause of accidents, intelligent driver systems monitoring the driver\u2019s state and behaviour could lead to improved collective safety.\nVI-DAS (vision-inspired driver assistance systems) is an EU project taking forward the design of next-gen 720\u00b0 connected scene analysis and driver status (ADAS).\u00a0\u00a0Advances in sensors, data fusion, machine learning and user feedback give the capability of understanding driver, vehicle and scene context as significant steps towards truly semi-autonomous vehicles. Cars driven by using AI turn the human eyes, ears, feet and hands into sensors and the data collected sends back all the signals a driver would normally process, e.g. how close the car is to other vehicles, what speed is it travelling, the behaviour of other road users such as cyclists or pedestrians, etc. \u00a0VI-DAS is developing a system that will allow cars to switch seamlessly between their human and automated drivers, based on data from real drivers in a variety of conditions and cases.\nHealthcare\nThe European project MURAB stands for MRI and ultrasound robotic assisted biopsy. Current techniques used to diagnose breast cancer can lead to 10-20% of patients being wrongly informed. What\u2019s more , tissue sampling methods are lengthy and often inaccurate. MURAB sets out to change this by \u00a0developing a more accurate technique that overlays MRI scans taken by AI-driven robots with images from ultrasound and pressure sensors to a give a much clearer view of potentially diseased areas and making it easier to target the area for tissue samples.\nSmart cities\nAI will have many potential applications in smart cities, from helping identify people in crowds using face-recognition software - preventing terrorist attacks or finding a lost child in a crowd - to monitoring air quality conditions and taking appropriate actions like limiting traffic flows or sending out automatic alerts to citizens. Diverse applications are already being tested\u00a0in European projects that are part of the IoT Large-scale pilots programme,\u00a0such as ACTIVAGE, Autopilot, IoF, CREATE-IoT, MONICA, Synchronicity and U4IoT.\u00a0\u00a0The projects bring together innovators to facilitate the deployment of IoT solutions in Europe by integrating advanced IoT technologies across the value chain, demonstrating multiple IoT applications at scale and in a usage context as close as possible to operational conditions.\nACTIVAGE (activating innovative IoT smart living environment for ageing well): deploying and operating at large scale Active & Healthy Ageing IoT based solutions and services, supporting and extending the independent living of older adults in their living environments, and responding to real needs of caregivers, service providers and public authorities.\nAutoPilot (automated driving progressed by Internet of Things): increasing safety, providing more comfort and creating many new business opportunities for mobility services.\nIoF (Internet of food and farm 2020): accelerating the adoption of IoT for securing sufficient, safe and healthy food and strengthening the competitiveness of farming and food chains in Europe.\nMONICA (management of networked IoT Wearables - very large-scale demonstration of cultural societal): providing a very large-scale demonstration of multiple existing and new Internet of Things technologies for Smarter Living.\nCREATE-IoT (cross fertilisation through alignment synchronisation and exchanges for IoT): stimulating collaboration between IoT initiatives, fostering the uptake of IoT in Europe and supporting the development and growth of IoT ecosystems based on open technologies and platforms.\u00a0\nSynchronicity\u00a0(delivering an IoT enabled Digital Single Market for Europe and Beyond: working to establish a reference architecture for the envisioned IoT-enabled city market place with identified interoperability points, interfaces and data models for different verticals. Synchronicity is a member of the early adopters Club for\u00a0the next generation internet. \nU4IoT (user engagement for large scale pilots in the Internet of Things): developing a toolkit for large-scale pilot end-user engagement and adoption, including online resources, privacy-compliant crowdsourcing tools, guidelines and an innovative privacy game for personal data protection risk assessment and awareness, online training modules.\nSources: European AI Alliance; Digital Single Market; IoT Large Scape Pilot Programme.\u00a0\n","69":"Current efforts to find answers to the ethical, societal and legal challenges posed by AI and autonomous technologies and to orient them for the common good represent a patchwork of disparate initiatives. This underlines the need for a collective, wide-ranging and inclusive process of reflection and dialogue.\u00a0A statement by the European Group on Ethics calls for the launch of such a process that would pave the way towards a common, internationally recognised ethical and legal framework for the design, production, use and governance of artificial intelligence, robotics, and \u2018autonomous\u2019 systems.\nFollowing is a brief overview of various disparate standalone initiatives on this subject followed by the statement from EGE calling for a collective initiative-\nSome of the most prominent initiatives towards the formulation of ethical principles regarding AI and \u2018autonomous\u2019 systems have stemmed from industry, practitioners and professional associations, such as the IEEE's policy paper on Ethically Aligned Design, ITU's Global Summit AI for Good, and the ACM's Conference on AI, Ethics, and Society. Within the private sector, companies such as IBM, Microsoft and Google's DeepMind have established their own ethic codes on AI and joined forces in creating broad initiatives such as the Partnership on AI or OpenAI, which bring together industry, non-profit and academic organisations.\n\t\u00a0\nOne of the leading initiatives calling for a responsible development of AI has been launched by the Future of Life Institute and has culminated in the creation of the \u2018Asilomar AI Principles\u2019. This list of 23 fundamental principles to guide AI research and application has been signed by hundreds of stakeholders, with signatories representing predominantly scientists, AI researchers and industry. A similar participatory process has been launched though the Forum on the Socially Responsible Development of Artificial Intelligence held by the University of Montreal, in reaction to which a first draft of a potential \u2018Declaration for a Responsible Development of Artificial Intelligence\u2019 has been developed. It is publicly accessible on an online platform where all sectors of society are invited to comment on the text.\n\t\u00a0\nA worldwide debate on the military use of AI has been initiated by the UN and the meetings for the Convention on Certain Conventional Weapons (CCW, Geneva), where a majority of the High Contracting Parties endorsed the so-called principle of \u2018meaningful human control for LAWS\u2019 stating that \u2018Autonomous Weapons Systems that require no meaningful human control should be prohibited\u2019 (General Assembly UN, 2016). The UN has also established a special research institute in The Hague to study the governance of Robotics and AI (UNICRI).\n\t\u00a0\nAt the national level initiatives are uneven, with some countries prioritising the development of rules for robots and artificial intelligence and going so far as to adopt legislation (e.g. to regulate self-driving cars on public roads), whereas other countries are yet to deal with the matter. This lack of a harmonised European approach has prompted the European Parliament to call for a range of measures to prepare for the regulation of advanced robotics including the development of a guiding ethical framework for the design, production and use of robots.\nAgainst this backdrop, the EGE draws attention to the risks inherent to uncoordinated, unbalanced approaches in the regulation of AI and \u2018autonomous\u2019 technologies. Regulatory patchworks may give rise to \u2018ethics shopping\u2019, resulting in the relocation of AI development and exploitation by regions with lower ethical standards. Allowing the debate to be dominated by certain regions, disciplines, demographics or industry actors risks excluding a wider set of societal interests and perspectives. Current discussions sometimes also lack an overview of \u2018autonomous\u2019 technologies that are likely to be studied, developed and implemented in the next decade, leaving a blind spot when it comes to regulatory foresight.\nThe EGE calls for a wide-ranging and systematic public engagement and deliberation on the ethics of AI, robotics and \u2018autonomous\u2019 technology and on the set of values that societies choose to embed in the development and governance of these technologies, proposing a set of ethical principles to start with. It should integrate a wide, inclusive and far-reaching societal debate, drawing upon the input of diverse perspectives, where those with different expertise and values can be heard.\nThe EGE calls upon the European Commission to investigate which existing legal instruments are available to effectively deal with the problems discussed in this statement and whether new governance and regulatory instruments are required.\nThe EGE calls for the launch of a process that paves the way towards a common, internationally recognised ethical and legal framework for the design, production, use and governance of artificial intelligence, robotics, and \u2018autonomous\u2019 systems. This process, in which the EGE stands ready to play its part, should provide a platform for joining together the diverse global initiatives outlined above.\nThe EGE in its statement urges the European Union to place itself at the vanguard of such a process and calls upon the European Commission to launch and support its implementation.\n","70":"Artificial intelligence, robotics and \u2018autonomous\u2019 systems can bring prosperity, contribute to well-being and help to achieve European moral ideals and socio-economic goals if designed and deployed wisely. Thus to safeguard and steer their development in the right direction, a range of increasingly urgent and complex moral questions have emerged as\u00a0summarized here. \u00a0European Group on Ethics in Science and New Technologies (EGE) on their part released a statement calling for the launch of a process that would pave the way towards a common, internationally recognised ethical and legal framework in answering those moral questions and to guide future design, production, use and governance of artificial intelligence, robotics, and \u2018autonomous\u2019 systems.\nAs a first step, statement proposes a set of fundamental ethical principles and democratic prerequisites, based on the values laid down in the EU Treaties and the EU Charter of Fundamental Rights, which may serve as a basis for the establishment of global standards, legislative action, and ethical guidelines for AI and autonomous systems. The proposed principles are\u00a0summarized as below-\nHuman dignity: The principle of human dignity, understood as the recognition of the inherent human state of being worthy of respect, must not be violated by \u2018autonomous\u2019 technologies. This means, for instance, that there are limits to determinations and classifications concerning persons, made on the basis of algorithms and \u2018autonomous\u2019 systems, especially when those affected by them are not informed about them. It also requires that we as humans be aware of whether and when we are interacting with a machine or another human being, and that we reserve the right to vest certain tasks to the human or the machine.\n\t\u00a0\nAutonomy: The principle of autonomy implies the freedom of the human being. All \u2018autonomous\u2019 technologies must, hence, honour the human ability to choose whether, when and how to delegate decisions and actions to them.\n\t\u00a0\nResponsibility: The principle of responsibility must be fundamental to AI research and application. \u2018Autonomous\u2019 systems should only be developed and used in ways that serve the global social and environmental good, as determined by outcomes of deliberative democratic processes. As the potential misuse of \u2018autonomous\u2019 technologies poses a major challenge, risk awareness and a precautionary approach are crucial.\n\t\u00a0\nJustice, equity, and solidarity: AI should contribute to global justice and equal access to the benefits and advantages that its related technologies bring. Discriminatory biases in data sets used to train and run AI systems should be prevented or detected, reported and neutralised at the earliest stage possible.\n\t\u00a0\nDemocracy: Key decisions on the regulation of AI development and application should be the result of democratic debate and public engagement. A spirit of global cooperation and public dialogue on the issue will ensure that they are taken in an inclusive, informed, and farsighted manner. The right to receive education or access information on new technologies and their ethical implications will facilitate that everyone understands risks and opportunities and is empowered to participate in decisional processes that crucially shape our future.\n\t\u00a0\nRule of law and accountability: The whole range of legal challenges arising in the field of AI and autonomous systems should be addressed with timely investment in the development of robust solutions that provide a fair and clear allocation of responsibilities and efficient mechanisms of binding law. In this regard, governments and international organisations ought to increase their efforts in clarifying with whom liabilities lie for damages caused by undesired behaviour of \u2018autonomous\u2019 systems. Moreover, effective harm mitigation systems should be in place.\n\t\u00a0\nSecurity, safety, bodily and mental integrity: Safety and security of \u2018autonomous\u2019 systems materialises in three forms: (1) external safety for their environment and users, (2) reliability and internal robustness, e.g. against hacking, and (3) emotional safety with respect to human-machine interaction. All dimensions of safety must be taken into account by AI developers and strictly tested before release. Special attention should also be paid to potential dual use and weaponisation of AI, e.g. in cybersecurity, finance, infrastructure and armed conflict.\n\t\u00a0\nData protection and privacy: In an age of ubiquitous and massive collection of data through digital communication technologies, the right to protection of personal information and the right to respect for privacy are crucially challenged. Both physical AI robots as part of the Internet of Things, as well as AI softbots that operate via the World Wide Web must comply with data protection regulations and not collect and spread data or be run on sets of data for whose use and dissemination no informed consent has been given.\n\t\u00a0\nSustainability: AI technology must be in line with the human responsibility to ensure the basic preconditions for life on our planet, continued prospering for mankind and preservation of a good environment for future generations. Strategies to prevent future technologies from detrimentally affecting human life and nature are to be based on policies that ensure the priority of environmental protection and sustainability.\nThe above ethical considerations can be used to shape the world of future AI technologies and should be construed as stimulus and opportunities for innovation, and not impediments and barriers.\n","71":"Advances in AI, robotics and so-called autonomous technologies warrants special reflection as they can be oriented divergent from common good and pose ethical, societal and legal challenges. European Group on Ethics in Science and New Technologies (EGE) released a statement calling for the launch of a process that would pave the way towards a common, internationally recognised ethical and legal framework for the design, production, use and governance of artificial intelligence, robotics, and \u2018autonomous\u2019 systems.\nThe EGE statement also investigates that the current ethical frameworks governing autonomous systems are very narrow which implies an often overly simplistic metrics in human affairs, suggesting a need for wider ethical framework, citing example from 3 applications.\nIn 2016, moral controversy stirred up when the first person was killed in a car crash while driving in \u2018autonomous\u2019 mode. Moral debates are now often limited to discussion of exceptional use cases concerning so-called \u2018Trolley Problem\u2019 thought experiments. These cases are concerned with dilemmas of unavoidable accidents in which the only available choice is between options associated with the loss of human lives. Central questions in that framing mainly seem to concern how \u2018autonomous\u2019 systems should be programmed so that their deployment leads to morally acceptable outcomes in terms of lives lost respectively lives saved. This neglects broader questions such as \u2018which design decisions were taken in the past that have led up to this moral predicament\u2019, \u2018which values should inform design\u2019, \u2018how should values in design be weighed in case of conflict, and by whom\u2019.\n\t\u00a0\nA large debate on autonomous weapon system takes place at the Conference on Certain Conventional Weapons in Geneva concerning the moral acceptability of \u2018autonomous\u2019 weapons and legal and moral responsibility for the deployment of these systems. However, attention also needs to be widened to questions such as - the nature and meaning of \u2018meaningful human control\u2019 over these systems and how to institute morally desirable forms of control.\n\t\u00a0\nWithout human intervention and control from outside, smart systems today conduct dialogues with customers in online call-centres; speech recognition interfaces and recommender systems of online platforms, e.g. Siri, Alexa and Cortana, make suggestions to users. Beyond the straightforward questions of data protection and privacy, a wider ethical framework is necessary that may ask whether people have a right to know whether they are dealing with a human being or with an AI artefact. Moreover, the question arises whether there should be limits to what AI systems can suggest to a person, based on a construction of the person's own conception of their identity.\nWhile there is growing awareness of the need to address such questions, AI and robotics are currently advancing more rapidly than the process of finding answers to these thorny ethical, legal and societal questions. Current efforts represent a patchwork of disparate initiatives. There is a clear need for a collective, wide-ranging and inclusive process that would pave the way towards a common, internationally recognised ethical framework for the design, production, use and governance of AI, robots and \u2018autonomous\u2019 systems as recognized in the statement by EGE.\n","72":"Advances in AI, robotics and so-called autonomous technologies warrants special reflection as they can be oriented divergent from common good and pose ethical, societal and legal challenges. \u00a0European Group on Ethics in Science and New Technologies (EGE) thus released a statement calling for the launch of a process that would pave the way towards a common, internationally recognised ethical and legal framework for the design, production, use and governance of artificial intelligence, robotics, and \u2018autonomous\u2019 systems.\nSelf-driving cars and drones, robots in deep sea and space exploration, weapon systems, software agents, such as bots in financial trade, and deep learning in medical diagnosis, are among the most prominent examples of Autonomous Systems. Artificial intelligence (AI), especially in the form of machine learning, and the increasing availability of large datasets from various domains of life are important drivers of these systems. The confluence of these digital technologies is rapidly making them more powerful, they are applied in an increasing number of new products, and can have both military and civilian application. The advent of these high-tech systems and software that can function increasingly independently of humans and can execute tasks that would require intelligence when carried out by humans, warrants special reflection. These systems give rise to a range of important and hard moral questions as recognized by the EGE statement-\nQuestions about safety, security, the prevention of harm and the mitigation of risks. How can we make a world with interconnected AI and \u2018autonomous\u2019 devices safe and secure and how can we gauge the risks?\n\t\u00a0\nQuestions about Human moral responsibility. Where is the morally relevant agency located in dynamic and complex socio-technical systems with advanced AI and robotic components? How should moral responsibility be attributed and apportioned and who is responsible for untoward outcomes? Does it make sense to speak about \u2018shared control\u2019 and \u2018shared responsibility\u2019 between humans and smart machines?\n\t\u00a0\nQuestions about governance, regulation, design, development, inspection, monitoring, testing and certification. How should our institutions and laws be redesigned to ensure AI and autonomous systems serve the welfare of individuals and society, and to make society safe for this technology.\n\t\u00a0\nQuestions regarding democratic decision making. Investigations are carried out across the globe to establish the extent to which citizens are taken advantage of by the use of advanced nudging techniques based on the combination of machine learning, big data and behavioural science, which make possible the subtle profiling, micro-targeting, tailoring and manipulation of choice architectures in accordance with commercial or political purposes.\n\t\u00a0\nQuestions about the explainability and transparency of AI and autonomous systems. Which values do these systems effectively and demonstrably serve? And which values are we letting to be undermined \u2013 openly or silently \u2013 in the technological progress and utility trade-offs? AI driven \u2018optimisation\u2019 of social processes based on social scoring systems with which some countries experiment, violate the basic idea of equality and freedom in the same way caste systems do, because they construct \u2018different kinds of people\u2019 where there are in reality only \u2018different properties\u2019 of people. How can the attack on democratic systems and the utilisation of scoring systems, as a basis for dominance by those who have access to these powerful technologies, be prevented?\nThe statement also describes following considerations from an ethical perspective in searching for the answers to above questions.\nAutonomy in the ethically relevant sense of the word can only be attributed to human beings. The terminology of \u2018autonomous\u2019 systems has however widely gained currency in the scientific literature and public debate to refer to the highest degree of automation and the highest degree of independence from human beings in terms of operational and decisional \u2018autonomy\u2019. Human beings ought to be able to determine which values are served by technology, what is morally relevant and which final goals and conceptions of the good are worthy to be pursued. This cannot be left to machines, no matter how powerful they are.\n\t\u00a0\nMoral responsibility, in whatever sense, cannot be allocated or shifted to \u2018autonomous\u2019 technology. In recent debates about Lethal Autonomous Weapons Systems (LAWS) and Autonomous Vehicles there seems to exist a broad consensus that Meaningful Human Control is essential for moral responsibility. The principle of Meaningful Human Control (MHC) was first suggested for constraining the development and utilisation of future weapon systems. This means that humans - and not computers and their algorithms - should ultimately remain in control, and thus be morally responsible.\nWhile there is growing awareness of the need to address such questions, AI and robotics are currently advancing more rapidly than the process of finding answers to these thorny ethical, legal and societal questions. Current efforts represent a patchwork of disparate initiatives. EGE, as expressed in its statement, is of the opinion that Europe should play an active and prominent role in defining a collective and inclusive process to propose a set of fundamental ethical principles and democratic prerequisites that could also guide light on binding laws to check any violation by autonomous systems and AI.\n\u00a0\n","73":"There\u2019s a lot of fear surrounding artificial intelligence these days, and it\u2019s hard to know what's warranted and what isn\u2019t.\nSome people believe that AI is far more dangerous than nukes and the humanity would be in danger because of the next world war in which the consequent destruction would not be down to nuclear weapons, but AI.\nHowever, a recent article published in Entrepreneur magazine argues against this myth. It stated that for all AI to overthrow humanity, four things would have to occur:\n1.\u00a0\u00a0\u00a0 An AI would have to develop a sense of self distinct from others and have the intellectual capacity to step outside the intended purpose of its programmed boundaries\n2.\u00a0\u00a0\u00a0 It would have to develop, out of the billions of possible feelings, a desire for something that it believes is incompatible with human existence\n3.\u00a0\u00a0\u00a0 It would have to choose a plan for dealing with its feelings (out of the billions of possible plans) that involved death, destruction and mayhem\n4.\u00a0\u00a0\u00a0 It would have to have the computing power \/ intelligence \/ resources to enact such a plan\nAn AI achieving any of these is highly unlikely. To achieve all of it? Next to impossible. It is improbable for an AI system to achieve consciousness -- the ability to think about oneself as an object and self-direct action. Machine learning is achieved by training a machine using millions of bits of diagnostic information in order to teach the machine how to do and what to do in a certain situation. The machine can only do what it is programmed for.\nWhat we\u2019re seeing again and again are forward-thinkers applying AI to situations where what we need is speed: identifying specifics based on complex statistical models, understanding and processing enormous amounts of data to solve otherwise-impossible problems. AI isn\u2019t the \u201cdemon\u201d it\u2019s made out to be; inherently it\u2019s useful and will allow us to affect change like we never have before.\nInstead of fearing from the AI, the most pressing need is to brainstorm about the legislative and ethical aspects of AI. What if the training data is incorrect or not comprehensive? What if the training algorithm is bugy. What if the artificially intelligent machine make harm to anybody? Who will be prosecuted? Machine? the owner? the programmer? the manufacturer?\n","74":"Technologists themselves say the technology needs to align with human values, and that ethical dimensions must be prioritised at every stage of the design, development and deployment of AI systems.\nThe ISOC report on \u201cPaths to Our Digital Future\u201d released in 2017 brought attention to the fact that there could be extensive ethical concerns due\u00a0to AI and automation. The speed at which AI and related technologies are being developed and deployed will require significant investment and effort in the short term to avoid unintended consequences for society and humanity. \u201cWe will need focused research and effective governance structures to make sure AI technologies create opportunities and not harm\u201d.\nThe report also address the concern that AI also raises serious considerations related to privacy, transparency, safety, the nature of work and jobs, and the overall economy. For example, technologies such as facial recognition based on AI can improve user experience over a social media platform. But the same technologies can be used to improve surveillance and compromise anonymity. Or, if AI becomes a permanent feature in social media networks and online platforms, where algorithms are used to curate the online experience, questions about free choice and bias will intensify. Concerns about the transparency and accountability of data collection and decision-making will accelerate calls for ethical principles to guide AI design and deployment.\nGovernments need to have available skills and resources in order to address the larger economic and social impacts of AI. Within governments, AI could bring about a fundamental reshaping of decision-making as policy development is increasingly data driven. By extension, there is a risk that AI could become an unaccountable and non-transparent decision-making tool for future policy choices.\nMany foresee a fierce, competitive battle to dominate the commercial AI space in coming years. While this will likely drive innovation and possibly disrupt current market structures, there are also concerns about competition. Forecasters believe that today\u2019s leading technology firms will control the market for AI platforms for the foreseeable future.\nRead the full report here.\n","75":"It is important to have an ethical framework in place for artificially intelligent and autonomous machines. In the Net Future 2017 debate on Legal, ethical and social issues in a software defined world, there was a disagreement among the participants regarding the ethical considerations of AI. It was advocated by some participants that the ethical framework and legal standards should be designed and built into the system design.\u00a0 However this raises a question that what happens to the learning algorithm and how it can be designed with such ethics in mind?\nThe counter argument is that the application of technology should be the subject of legality and ethics rather than the technology itself. It is argued that the use of technology is to be accountable against legal and ethical questions rather than the technology. Trying to put ethics into technology design might constrain it.\nIt is however still a question to be answered that how ethics can be designed into AI technology and where these ethical and legal questions lie.\nThe question of ethics for autonomous machines is not new and lessons can be learned from the societal impacts of robotics, a well-cited example from 1942 being Isaac Asmiov\u2019s \"Three Laws of Robotics\".\nA robot may not injure a human being or, through inaction, allow a human being to come to harm.\nA robot must obey orders given it by human beings except where such orders would conflict with the First Law.\nA robot must protect its own existence as long as such protection does not conflict with the First or Second Law\nThe concept of robotics as tools is discussed in  EPSRC and AHRC Robotics Retreat held in September 2010, supporting the notion that it is the application that the tool is put to that needs ethical consideration and legislation governing what is permissible.\nThe Hub4NGI D2.1 deliverable recommends that multi-disciplinary research and discussion are undertaken to provide answers to legal and ethical questions surrounding AI and its applications:\u00a0\nHow should legislation be brought to effect on AI systems?\nWhat are the most appropriate regulations?\n\nAre AI systems ever likely to be legal entities?\nHow can an AI system be incentivised to be compliant with the law? It does not understand the notions of penalties for non-compliance.\n\nShould ethics be designed into AI technology, or should ethics apply to the applications\n\tof AI technology?\nHow can commitments be acquired from creators of AI technology to issue patches for\n\tsafety critical flaws over the long term?\n\u00a0\n","76":"In the Hub4NGI D2.1, a significant issue regarding the responsible AI has been raised which is about whether and how can an AI algorithm be accountable for its actions.\nThe issue of Algorithmic Accountability was also raised in Net Futures debate \"Legal, ethical and social issues in a software defined world\" and the participants agreed that there is a responsibility gap for the AI systems.\nTransparency is considered to be a key aspect of algorithmic accountability as depicted in the Net Future 2017 debate session. And it is widely agreed that the algorithms need to be able to explain their decisions.\nFurthermore, the biasness and discrimination might also be a big issue and it is possible that the algorithm may discriminate people because of their gender, race, ethnic or religious associations. For example, there might be the case when an algorithm filters Curriculum Vitae in recruitment situations. So the transparency should enable every concerned citizen understand how their personnel data is being used. Because of the inputs and training data, biasness can be built into AI algorithm. Therefore the training and input process should be transparent in such a way that citizens can trust on the AI system.\nThe Algorithmic Accountability is to trying to find the answers for the following questions:\nHow to trust a black box algorithm?\nHow to opt out of algorithm use?\nTo what extent do algorithms violate privacy?\nIf an algorithm causes harm, who or what is responsible?\nTransparency: how can AI systems explain their decisions?\nHow can bias be eliminated from AI systems?\nResearch and discussion involving multidisciplinary teams from the legal, sociological and technical domains is needed to provide the answers for ethical and legal questions.\n","77":"If something has been dividing people on the tech front for some time now it is artificial intelligence (AI). Not even some of the brightest minds, many of them regular speakers at TED conferences, can agree on whether AI will empower us as human beings or kill us, softly but surely.\nWell-known, forward-thinking luminaries like Elon Musk have been among those calling for caution, warning that AI could ultimately overpower us and even cause an AI apocalypse.\nSo, is AI all doom and gloom or an opportunity to hold on ever more tightly to human values and ethics?\nThese opinion pieces don\u2019t give a definitive answer as to whether AI is ultimately good or bad but they will give you a good idea of the major factors at play and help you form your own opinion. Feel free to post comments below!\nMajor risks at stake\nAt the 2016 TED Summit, Neuroscientist and Philosopher Sam Harris warned, \u201cIf intelligence is just a matter of information processing, and we continue to improve our machines, we will produce some form of super intelligence. And we have no idea how long it will take us to do that safely.\u201d\nHarris added, \u201cThe moment we admit that some appropriate computational system is the basis of what intelligence is, and we admit that we will improve this system continuously, and we admit that the horizon of cognition very likely far exceeds what we currently know, then we have to admit that we are in the process of building some sort of god. Now would be a good time to make sure it\u2019s a god we could live with.\u201d\nHe stressed the importance of keeping super intelligent AI in check. The problem is, if AI goes wrong, even in the first try, apocalyptic consequences may be likely.\n\u201cWhen you\u2019re talking about super-intelligent AI that can make changes to itself, we only have one chance to get the initial conditions right. And even then, we will need to absorb the economic and political consequences of getting them right,\u201d he added.\nCheck out the TED Talk here: Can we build AI without losing control over it? - Sam Harris\nFor technologist and TEDx Brussels 2014 speaker Jeremy Howard, the AI revolution that the super intelligent AI will bring will have a stronger impact than what the Industrial Revolution did to the 19th century society.\nHoward explained that when engines started taking over jobs in the 19th century, there was drastic social disruption which eventually settled down after a while. On the other hand, he continued, \u201cThe machine learning revolution will be different from industrial revolution because it never settles down. The better computers get at intellectual activities, the more they can build better computers with intellectual capabilities, so this will be a change that the world has never seen before.\u201d\nHe says the difference lies in the fact that, through deep learning, AI capability grows exponentially, as opposed to the growth of engine capability before.\n\u201cIt\u2019s already impacting us\u201d, Howard warned. \u201cIn the last 25 years, as capital productivity increased, labour productivity has been flat and even a bit down. So, I want us to start having the discussion now. So, we have to start thinking how are we going to adjust our economic and social structures to be aware of this new reality.\u201d\nThe wonderful and terrifying implications of computers that can learn \u2013 Jeremy Howard\nIs AI Worth It?\nThere\u2019s a reason why despite the many risks associated with AI, scientists are still pursuing its development. Many would argue that AI\u2019s more tangible benefits that are closer to realization than the prophesied doomsday scenario and have far more weight.\nOne of the biggest developments was proposed by inventor and futurist Ray Kurzweil during the TED 2014 conference in Vancouver.\nHe said that nanobots will allow the brain to connect to our human neocortex to a synthetic neocortex in the cloud, thus providing an extension of our brain. \u201cNow today, you have a computer in your phone but if you need 10,000 computers for a few seconds to do a complex search, you can access that for a second or two in the cloud. Our thinking then would be a hybrid of biological and non-biological thinking.\u201d\nCheck out the TED Talk here: Get ready for hybrid thinking \u2013 Ray Kurzweil\n\u201cNon-biological thinking will be subject to the accelerating law of returns \u2013 it will grow exponentially. And remember what happened the last time we expanded our neocortex? That was 2 million years ago when we became humanoids and developed these large foreheads. The frontal cortex is not really qualitatively different \u2013 it\u2019s a quantitative expansion of the neocortex. But that additional quantity of thinking was the enabling factor for us to take a qualitative leap and advance language, art, science and technology.\u201d\nKurzweil explained that no other species has done that. \u201cSo, in the next few decades, we\u2019re going to do it again, we\u2019re going to expand our neocortex, only this time, we won\u2019t be limited by a fixed architecture of enclosure, it will be expanded without limit. That again will be the enabling factor for a qualitative leap in culture and technology.\u201d\nSiri creator and TED2017 speaker Tom Gruber echoed the sentiments of Kurzweil when he said, \u201cI think the purpose of AI is to empower humans with machine intelligence. And as machines get smarter, we get smarter. I call this, humanistic AI - artificial intelligence designed to meet human needs by collaborating and helping people.\u201d\n\u201cWe can choose to make AI automate and compete with us, or we can use AI to augment and collaborate with us - to overcome our cognitive limitations and to help us do what we want to do, only better. And that is why every time a machine gets smarter, we get smarter.\u201d\nFei-Fei Li, who is developing a technology that will allow computers to see and understand images, also agrees with the benefits brought by AI. \u201cWhen machines can see, doctors and nurses will have extra pairs of tireless eyes to help them diagnose and take care of patients. Cars will run smarter and safer on the road. Robots, not just human will help us brave the disaster zones to save the trapped and wounded. We would discover new species, better materials and explore unseen frontiers with the help of machines.\u201d\nShe added, \u201cFirst, we teach them to see. Then, they help us to see better. We will not only use the machines for their intelligence. We will also collaborate with them in ways that we cannot even imagine.\u201d\nSolving the AI fears may lie in ethics\nThe argument is that almost any benefit brought by AI can be turned against humans. This is why many experts believe ethics should be at the centre of discussions on AI. How we think about ethics in the AI context is the key to answering today\u2019s biggest AI fears.\nTechno-sociologist Zeynep Tufekci, during the 2016 TED Summit, cites an example of a predictive AI technology now being used to determine hiring in companies and rate the likelihood of criminal offenders re-offending. However, despite it being meant to be impartial, their algorithms still seem to have been imbued with biases that people have.\nShe said, \u201cArtificial intelligence doesn\u2019t give us a get out of ethics free card. We need to cultivate algorithm suspicion, scrutiny and investigation. We need to make sure we have algorithmic accountability and auditing and meaningful transparency. Bringing math and computation to messy, value-laden human affairs, doesn\u2019t bring objectivity, rather the complexity of human affairs invades the algorithms.\u201d\nTufekci agreed that we should use computation to help us make better decisions. \u201cWe have to own up to our moral responsibility and use algorithms within that framework, and not as a means to abdicate and outsource our responsibilities. Machine intelligence is here. That means we should hold on ever tighter to human values and ethics.\u201d\nCheck out the TED Talk here: Machine intelligence makes human morals more important \u2013 Zeynep Tufekci\nAnother way to solve the fundamental issues of AI was proposed by Nick Bostrom, speaker during the TED2015 conference. He said that the key is to figure out how to create super intelligent AI such that even if, or when it does an unplanned action, it\u2019s still safe because it is fundamentally on our side and because it shares our values.\n\u201cWe would create an AI that uses its intelligence to learn what we value. And its motivation system is constructed in such a way that it is motivated to pursue our values or perform actions that it predicts what we would have approved of,\u201d Bostrom said.\nHe adds, \u201cThe values that the AI has need to match ours not just in the familiar context, like where we can easily check how the AI behaves but also all novel contexts that the AI may encounter in the near future.\u201d\nConclusion\nAs you\u2019ve seen, AI experts are divided between those that see AI as an extension of us and thus, an improvement for humans and those that believe AI will destroy us (or at least be harmful to our society in the long-run). However, there are those that think ethics plays a key role in preventing the latter from happening.\nWhether you\u2019re for, against or undecided about AI, one thing is for sure \u2013 that we as a society will have to think seriously about how we want AI to develop as it embeds itself more and more into our lives.\n","78":"With AI becoming more ubuiquitous, there is a need for means of redress where decisions made by machines are difficult to understand, or unethical or even illegal. A recent article from MIT Technology Review discusses the need for AI systems to explain decisions without revealing secrets or stifling innovation.\nThe article discusses a possible solution from some Harvard researchers which is built upon a definition of explanation as \"...we generally mean the reasons or justifications for that particular outcome, rather than a description of the decision-making process in general\". \n\u00a0\n","79":"Artificial Intelligence: can it really bring socio-economic impacts?\nAI is already being used to address the challenges of an ageing population and detecting breast cancer in the US. Mammograms play a crucial role in detecting breast cancer but they also throw up false positives, such as lesions that appear suspicious. Once operated on, many such lesions turn out to be benign. With so much uncertainty in data,\u00a0machine learning is the tool we need to improve detection and prevent over-treatment. In the US alone, 40,000 women dies from breast cancer every year, but when cancers are found early enough, they can often be cured.\u00a0\nSummary:\nMachine learning is a vital tool to overcome uncertainty in data from diagnostic tools for breast cancer.\u00a0\nImpacts\nSocio-economic: reducing healthcare costs, improving patient outcomes\nOf interest to:\nCitizens, medical professionals, decision-makers in hospital and care facilities, governments.\nRead more in this BBC article (17 October 2017):\u00a0http:\/\/www.bbc.com\/news\/technology-41651839\n","80":"Hi All,\nwe've been investigating\u00a0blockchain from several perspectives, such as identity and privacy, as well as civil society. Here, we look at the future trajectory of blockchain with insights from research and standards. Then we zoom in on work by\u00a0civil society stakeholders.\nInspiration on the research side comes from Cathy Mulligan, Imperial College London, on the promise, and potential pittfalls of blockchain.\u00a0\nBlockchain is among the latest waves of digitisation enabled by the worldwide distribution of computing capacity. There are essentially two types of blockchains: permissioned (private) and permissionless (public, e.g. bitcoin). Permissioned distributed ledgers are a better match for business-oriented use cases that are of interest to industry and governmental institutions.\nA key public aspect of Blockchain is its value as a timestamped and chronologically recorded digital ledger type transaction that allows anyone to download the code and start mining bitcoin or take part in new network ideas built on the Ethereum platform.\nBlockchain promises to redefine trust, transparency and inclusion across the world. Transparency comes from the participation of huge parts of the public while trust is built from the almost impossibility to record malicious entries or change transactions already processed.\nIt is arguable how well blockchain captures that notion of trust, or whether any technology can ever actually replicate what a human being thinks, feels and acts like when they trust and are trusted. These concepts are deeply human, as are the power structures within which digital solutions are built.\nIt may or may not overcome its technical and environmental challenges, but the concept of citizen-led and citizen-owned solutions to global problems has been unleashed.\nBlockchain speaks to a deep human need to be able to trust other people, organisations and companies in an increasingly digital world though more work is needed on exactly how we prove this trust-building process.\nBlockchain can help us organise society differently by enabling new levels of cooperation and new types of partnerships across geographical and sectoral borders. This shows us how important it is to support transparency and inclusion and what they should look like in the digital world.\nBlockchain\u2019s focus on inclusion, trust and multilateralism is expected to continue for many decades but needs the support of governments, civil society, academia and industry.\nBlockchain is cross-border. As such it requires a unified, multilateral approach to regulation. Civil services need to understand how their regulations may be interpreted in code, from multi-stakeholder perspectives and thinking about laws in one country may impact people in another country.\nIt is likely that the key legacy of blockchain will be that when computing power is handed to a large part of the population\u2014rather than solely housed in corporations\u2014completely new solutions to old problems will emerge. In the case of blockchain, it began with a desire to see a new form of banking system, one that was truly native to the digital world we are all starting to inhabit.\nBlockchain is a relatively immature technology, which does not exist in a vacuum. On the negative side, it may potentially create as many problems as it solves. Yet it can yield insights into emerging technologies and how we can face them head on in a rapidly changing world.\nBlockchain is still new and will evolve many times before it can be fully integrated into society. We should not see it as a fully functional solution but as a lens on the possible. Its possibilities merit the attention of everyone. For example, users on the consultation platform have raised the issue of the Blockchain-GDPR Paradox, whereas storing personal data on a blockchain is not an option according to GDPR, since the data \u201cshould be erasable\u201d at any point in time, which wouldn\u2019t be possible if it was in a blockchain transaction.\nCivil Society Lens: Leadership on priority issues \u2013 Champions perspectives\nThe NGI Champions Panel includes experts from civil society, notably the International civil society centre. Here's what they're doing on blockchain.\u00a0\nIt is key to act now on collaborative blockchain and big data projects in organisations like the International Civil Society Centre to make our voices heard right across the globe.\nThese projects are vital for leading the way and zooming in on priority topics like data privacy and security.\nNew projects include:\nData-driven advocacy partnerships for sustainable development goals (SDGs), developing a data collaboration method focused on the evidence-based advocacy for the leave no one behind agenda. The idea is to use the Centre\u2019s Leave No One Behind project as a case study on how to use big data effectively at different project stages.\nBig data for impact measurement, using various big data sets to discover new insights, creating an impact measurement tool to improve decision-making.\nPlan Omega, exploring how to establish a CSO Blockchain to improve efforts to protect and expand the civic space, mapping relevant CSO actors and technology experts to gauge the viability of building the CSO blockchain.\nCryptocurrency and CSO transaction costs, exploring the possibilities of using an existing or setting up a new cryptocurrency for the CSO sector exclusively and verifying whether it can reduce transaction costs.\nThanks for reading and please engage on our consultation platform. Your views and comments are very much appreciated.\u00a0\n","81":"A blockchain is a growing list of records, called blocks, linked together with cryptography. By design, the data from a blockchain cannot be modified. It is an open distributed ledger that can record transactions between two parties in an efficient and secure manner. \nMostly known for cryptocurrencies, blockchains can be used  for digital identity attributes, object tracking, or the verification of service level agreements. \nDistributed ledgers like blockchain can be either permissionless (public) or permissioned (private). \nPermissioned distributed ledgers are better qualified to address the more business-oriented use cases that are of interest to industry and governmental institutions (as opposed to permissionless ledgers like Bitcoin). \nThe creation of a new ETSI Industry Specification Group on blockchain: Permissioned Distributed Ledgers in December 2018 marks an important step towards standards setting. The ISG PDL group will analyse and provide the foundations to operate permissioned distributed ledgers to be deployed across industry and governmental institutions. \nWhile leading EU industry is making an important contribution, it is also important to note that standards are most valuable when they are globally applicable. Hence, Ericsson, Huawei, Intel, Telefonica, Vodafone and others will be working together on the challenges related to the operation of permissioned distributed ledgers, business use cases, functional architecture and solutions for operating the ledgers, including interfaces\/APIs\/protocols and information\/data models.\n","82":"An interesting blogpost on the paradoxical potential impact of GDPR on Blockchain technologies and some possible workarounds to ensure GDPR compliancy.\u00a0https:\/\/medium.com\/wearetheledger\/the-blockchain-gdpr-paradox-fc51e663d047.\nCertainly solutions will need to be developed in the NGI programme.\n","83":"While the TCP\/IP made communication easy since it allowed devices to talk to each other, the blockchain technology could help advance it further by making data interoperable in such a way that having to hard code APIs for accessing databases would be a thing of the past.\nAs someome who deals with data extraction, verification and analysis, I believe that blockchains can help restore trust in the Internet by allowing storing and dealing with data more interoperable, reliable, convenient and efficient. Doing so helps journalists and the public less prone to falling into fake news traps.\nThere are also challenges and risks to blockchains however. I highlighted some of them in a recent article I co-wrote with Nicolas Seidler.\u00a0\nWalid Al-Saqaf, PhD\nSenior Lecturer in Media Technology\nS\u00f6dert\u00f6rn University, Stockholm\nwalid.al-saqaf@sh.se\u00a0\n","84":"You most likely already have seen CE marks. Some toys and other manufactured products have a \"CE\" written somewhere. The CE marking is a key indicator (but not proof) of a product\u2019s compliance with European Union (EU) health, safety and environmental protection directives and regulations. CE marking is necessary to get access to the European market and there are many service providers out there that want to sell their consulting, testing and certification services to help get the CE mark.\nIt applies to the following products (non-exhaustive list): active implantable medical devices, appliances burning gaseous fuels (gas appliances), cableway installations designed to carry persons, energy related products, electronics and active components, equipment and protective systems intended for use in potentially explosive atmospheres (ATEX equipment), explosives for civil uses, hot-water boilers, household refrigerators and freezers, in vitro diagnostic medical devices, lifts, low voltage equipment (electrical material), machinery, measuring instruments, medical devices, outdoor equipment producing noise, non-automatic weighing instruments, personal protective equipment, pressure equipment, pyrotechnics, radio and telecommunications terminal equipment, recreational craft, toys, and simple pressure vessels.\nSo let's take two examples, one simple and one more advanced and see how to the blockchain could help and disrupt\n- Toys Directive. The Directive has requirements on small pieces that can be eaten by children. Manufacturers and importers need to send the necessary documents to notified bodies that carry out some assessments (more on http:\/\/CEmarking.net). They then produce a certificate of conformity. Smart contracts would ensure basic requirements are met before the file gets submitted to the Notified body. Everyone would be able to read the data, ensuring transparency e.g. to stakeholders, while at the same time allowing the company to encrypt data in case the company data is private.\nAnother advantage of blockchain for CEmarking relates to its disintermediation&distributed properties and global value chains. Production and supply chains nowadays are more and more spanning several countries, including non EU countries. Because blockchains are not centralised e.g. in the EU, decentralised elements of the production and supply chain can contribute to the certification process and put in the blockchain their documents certifying compliance. The blockchain provides then a standard mechanism to exchange certification documents across continents and across elements of the value chain or notified bodies.\n\u00a0\nThe above Toys example is a simple one. Because it is a simple case, it probably can be made generic so that many uncomplicated CEmarking processes are met with the same blockchain. A more interesting case relates to the Directive for the registration of chemical substances. Imported and manufactured products must be registered when put on the market just like above.. but there is a twist, there is a specific principle :\n- REACH Directive. This Directive has a principle called One susbtance One registration. For one substance, all related manufacturers and importers need to agree on how to register the susbtance.\u00a0 This means sharing costs such as the testing costs (spectrum analysis) and data.\u00a0 This issue is at the moment a critical issue industry-wise as the number of parties having to agree can amount to thousands. Blockchain would help here because with smart contracts it could ensure that a file is complete and filled by all relevant parties before being submitted. It can enforce a process of agreement.\u00a0 A second point relevant to blockchain is security. Obviously some chemical susbtances are costly to produce and might relate to trade secrets, e.g. you don't want as a business to share all data. The blockchain would help here because it is a strongly secured mechanism.\n\u00a0\nWhat do you think of those crazy ideas? :-)\n","85":"It is not a coincidence that the Bitcoin genesis block came into existence in the midst of the financial crisis. Satoshi referred to the blockchain as an alternative to the failing banking system. The financial crisis was followed by a democratic crisis. People around the world sense that the state or European Union as trusted third party, maybe cannot be trusted after all.\nThe only way blockchain can really change society is, if we use this technology to re-establish our values. If elections can get hacked, blockchain can make them safe again. If people feel unrepresented by politicians, blockchain has the potential to create new forms of groupdecision making. If ownership or personal data is not registered by the state properly, a blockchain can be a safe vault. Blockchain has the possibility to restore norms like the rule of law, liberty and non discrimination. But we need to realise that these norms will not code themselves. They need good blockchain-governance.\nIn order to better understand the full potential of blockchain technologies, the Dutch Government asked us to set up some blockchain pilots. We started at the beginning of may 2016 and so far we have finished 35 pilotprojects within the Dutch Government: www.blockchainpilots.nl.\nWe hope to find more governmental or EU organizations who want to work together on specific usecases. We can share prototypes or start new projects together. \u00a0\n","86":"In 2016, Joshua Cooper Ramo hypothesized the shift from one global Internet to a system of regional Internet blocs, each with distinct characteristics and values, in his book The Seventh Sense (https:\/\/www.amazon.com\/Seventh-Sense-Fortune-Survival-Networks-ebook\/dp\/...)\nIn 2019, we can see that world shaping before our eyes:\nThe American internet.  Laissez-faire, hyper-capitalistic, increasing public authority for private companies, fighting to keep Net Neutrality alive.\nOn the opposite end of the world, we have the censored Chinese internet.  The international proliferation of China's biggest ventures (WePay, Alibaba, Huawei) and Google's collaboration with the Chinese government look to accelerate its development.\nAnd then, we have the European Internet.  Deploying the GDPR to protect its citizens in the digital space.  Holding businesses accountable when they break the rules (http:\/\/fortune.com\/2019\/01\/21\/france-fines-google-57-million-for-gdpr-vi...).  Admittedly, dealing with some serious threats -- see Article 11  (https:\/\/www.eff.org\/deeplinks\/2019\/01\/article-13-and-11-update-even-comp...) and Article 13 (https:\/\/www.eff.org\/deeplinks\/2019\/03\/german-data-privacy-commissioner-s...) -- but on the whole, Europe is funding innovative and human-centric efforts to create an ethical, open, and fair Internet for the next generation.\n[A \u20ac50 million fine for Google doesn't seem like much.  But in the words of Ted Waz (https:\/\/www.linkedin.com\/in\/theodore-waz-a069143\/), the French courts set a precedent which can now be utilized across 27 other EU countries -- so that \u20ac50 million fine can become a  \u20ac1.4 billion fine.]\nAs the strength of a network is based on the number of nodes, Ramo argues that the strength of these (presumably competing) regional Internets will depend on the number of countries they have \"signed on.\"  So MENA and Oceania countries will have a chance to chose between the U.S., E.U., and Chinese Internet.  Consequently, whichever regional Internet creates the most attractive Internet architecture for these nations will have the leading network in the world.\nDo we want to live in a world where our identities, healthcare, and public services are administered by Facebook?  \nWhat about a world where every moment is tracked and our entire perspective is controlled by a digital police state? (https:\/\/www.eff.org\/deeplinks\/2019\/03\/massive-database-leak-gives-us-win...)\nOr, what about a world designed for *us*?\nA world where we control + earn from our personal data. (https:\/\/solid.inrupt.com\/about)\nWhere our access to information is limitless, and as a community, we collaborate to protect the integrity (https:\/\/crowdfact.io\/) of our information landscape.  \nWhere our leaders prioritize people over unsustainable corporate growth (https:\/\/www.youtube.com\/watch?v=LZnDWu1mnMc#t=04m14s), and our governments embrace technological innovation to improve the common good.\nThese divergent digital futures are the context of our work today, illustrating the urgency + responsibility we all face in this moment.  \nAs the Internet dictates more and more of the physical world, the values and characteristics of our Internet will determine the world we experience every day.  \nIn relation to the regional Internet blocs in the U.S. and China, Europe's rising Internet seems truly aligned with the interests of its people.\nThat gives us a rare opportunity to shape our world -- and a responsibility to take advantage of it.  \nNow is the time for us to determine the values and standards of the European Internet.  We need to embrace the task with diligence and care -- exposing our ideas to scrutiny, identifying our blind spots, and compensating for them as best as we can.  As we validate the values and standards of our future Internet, we need to collaboratively build the technology to support it.  And if we want these values to be the standard for people around the world, we need to invite those people and their nations to join us on the journey.\nHow does that inform our actions today?\n1. With initiatives like the NGI, we start reaching out to communities beyond Europe -- MENA, Africa, Oceania, South America, the Balkans, Southeast Asia -- and involving them in the creation of our Next Generation Internet.\n2. When we have those voices at the table, we begin a focused + interdisciplinary dialogue about *specific* values, standards, and visions for the European internet.\nAt the moment, we're catalyzing open innovation in some main topic areas.  This enables creative solutions -- but in the absence of a clear vision, it's ambiguous whether these solutions will be useful down the road, making the effectiveness of those efforts ambiguous as well.\n(Furthermore, we know Facebook + Google have a vision -- e.g. setting up Internet all over Africa, ensuring their digital hegemony -- meaning we have a lot of catching up to do.)\nOf course, as an online community of 15,000 people, we shouldn't just shepherd our vision from the Ivory Tower either.\nBut if we ensure our dialogue is accessible + interdisciplinary, inviting voices from different classes, regions, subject matters, and perspectives to the table, I believe we can avoid reduce the pitfalls of the Ivory Tower, and craft a robust vision for the Next Generation Internet.\nOnce that vision starts to take place, we can begin identifying *specific* needs for the Next Generation Internet -- and start catalyzing open innovation for those *specific* ends.\n(The innovation challenges of Conservation X Labs are a useful reference point -- https:\/\/conservationxlabs.com\/grand-challenges-for-conservation)\nFrom there, the game is on.\n-Sam\nP.S. This proposal obviously came from the Ivory Tower between my own two ears, and the irony of it isn't lost on me.  \nShare your voice in the comments below, and let's get the discussion flowing around these issues.\n","87":"Optimal resource consumption and minimization of carbon emission is a great challenge for the Next Generation Internet. Data centres and networking devices consume significant amount of energy. It is imperative to improve energy efficiency, both locally and at Internet level. Currently there is a significant lack of transparency of environmental cost, which should be urgently resolved given the vast scale of resource usage.\nThere is a need to provide transparency mechanisms on the environmental cost of the Internet. Identification and tagging of most resource consuming elements is also very important and urgent. The research is needed to figure out the alternatives to improving energy efficiency. This will ensure sustainability of the Internet and of the economy relying on it.\n","88":"Supporting safety of EU citizens and their data and ensuring the business and social connectivity is the foremost concern in the NGI initiative. The challenge is to provide efficient accountability and security mechanisms for the operational NGI initiative with tamper-proof technical solutions such as security proofs, risk protection, as well as whistle-blowing options and accountability mechanisms. These solutions should ensure high availability of the NGI, counter issues such as sabotage or surveillance, and provide distributed trust mechanisms to remove single points of failure. Given the inherent vulnerability of any single root of trust, there is a preference for distributing trust mechanisms to remove single points of failure, and finding ways to delegate trust in an auditable and controlled way.\nSecurity solutions should also include mechanisms to encourage automating incident\u00a0and abuse-handling to further enable safe Internet usage during outage. Streamlining and automating how incidents are handled across the highly connected network is an important part of maintaining high availability. This will make the overall system more secure, because it will allow increased responsiveness to changing operational conditions, particularly in time of emergency. The goal should be to improve the trustworthiness and sustainability of the Internet, enabling innovation. This will reduce future cost of security auditing by creating verifiable trustworthiness that cannot be perverted. It will also lower the overall cost of deployment and maintenance while improving responsiveness.\u00a0\nWhile building such solutions, we need to follow the technical baseline for cryptographic functionalities. We need to make sure that the higher level technology aspects are not lost to low level hardware incapabilities, e.g. offer Secure Random Number Generation, Secure Key Storage and Cryptographic Acceleration.\n","89":"\u00a0\u201cI cannot think of a better example where interoperability is more important than the Internet of Things. Without interoperability, lights won\u2019t work with the switches, sensors can\u2019t be read by your smartphone, and devices cannot use the networks around them\u201d. -\u00a0Jari Arkko, former chair, IETF\nThe Internet Society 2017 report- Paths to our Digital Future\u00a0recognizes interoperability as fundamental to the success of IoT. Interoperability, standards and protocols, and security are all intertwined and essential to the success of IoT. Without them, we face a different kind of fragmentation \u2014 where devices and systems simply will not work together. Users will hesitate to adopt IoT if it cannot be integrated with other technologies, it is too complex to easily manage, or if they risk being \u201clocked in\u201d to a particular vendor.\u00a0McKinsey & Company estimates that\u00a0\u201c40 percent of the total value that can be unlocked requires different IoT systems to work together\u201d.\nThe large-scale and widespread innovation prospects of IoT will thrive a race between businesses to be a leader in the space. This pressure to get ahead will bring more and more IoT devices and gateways using proprietary\/non-standard technologies into market. This proliferation of proprietary IoT edge will pose a challenge of interoperability between them and rest of the open end-to-end Internet.\nIoT will make unprecedented demands on communication infrastructure, data storage, security and privacy, requiring significant investment in upgrading networks, internet addressing and energy supply. In some cases, specialized access networks might be built to support sensors, for example in smart cities, and there will increase demand on networks, energy supply and for Internet addressing.\u00a0Even in the midst of these challenges, it is essential to give importance to standardized and interoperable solutions to derive the full potential of IoT.\n","90":"In this future technological \u201crenaissance\u201d, will today\u2019s most widely-used online services and platforms deepen their market position, or face competition and possible displacement by new players, a question raised by The Internet Society 2017 report- Paths to our Digital Future. The private sector is generally optimistic about a more competitive environment. However, if the Internet platforms of today consolidate their power \u2014 becoming dominant across infrastructure, services and applications \u2014 user choice and control over their online experience, as well as the availability and diversity of information and content, could be constrained.\nWithout thriving competition, closed platforms and proprietary ecosystems, or \u201cwalled gardens\u201d, may proliferate. Customers may find it difficult to move from one provider or platform to another.\u00a0 This will result in the loss of choice and constraints on innovation and lead to Internet fragmentation.\n\u201cWalled gardens\u201d could also arise as a reaction to political concerns such as economic isolationism and national security, hindering the development of the global economy. Among our community respondents from Africa and Asia reported a significant trend toward greater use of the global, public internet whereas respondents from Europe and North America reported significant trend toward greater use of closed, access-limited, or private IP networks.\nHow governments should respond, and whether their existing policy tools are adequate, will also be called into question. One Internet Society survey respondent from the Middle East suggested that, \u201c\u2026as governments begin to identify the potential of the Internet, there will be increased regulation for social and economic reasons\u201d.\nScalability is such an important factor in the Internet economy. When current Internet companies like search-engine giants reach such a level of scalability, it will be difficult for others to compete with them. Are you optimistic about the future of Internet economies being open, and conclusive of competition, or do you foresee dominance and \u201cwalled gardens\u201d by existing Industry giants?\n","91":"The Internet Society 2017 report- Paths to our Digital Future advocates open and voluntary standards as being the core of the Internet\u2019s success. The report also argues that they will, however, be challenged in the future by the speed of Internet innovation, the complexity of the emerging infrastructure and services, and the emergence of proprietary systems and walled gardens. Standards development processes are also under increasing threat from companies that can use their powerful market presence to create de facto standards, bypassing open standards processes and risking fragmentation.\nIn the words of a technologist from Asia-Pacific Region, the optimism is that so-called Internet of Things which is propagating a move towards proprietary networks and services will fade in significance, as the existing Internet is evolving and expanding with increasing numbers and varieties of connected devices. Successful manufacturers of these devices will have embraced the Internet ecosystem, in terms of open standards, Internet best practices, and appropriate measures to ensure security and longevity of their devices. To summarize, services based on open standards have long contributed to the success on Internet, and this trend is expected to go on.\nHowever, established approaches to formulating Internet standards must also evolve if they are to remain relevant going forward. Simply put, the challenge for established standards organisations and processes includes engaging the innovators who either do not see the benefits of standardisation, or for whom the process of standardisation is too cumbersome.\n","92":"\u201cThe Internet will change from end-to-end to edge-to-edge.\u201d\nThe Internet Society 2017 report- Paths to our Digital Future recognizes increasing development at the edge impacting the wider Internet ecosystem. Broadly defined, the edge of the Internet includes both the networks and devices within homes and enterprises, as well as the Internet service provider networks that connect those homes and enterprises to the global Internet.\u00a0\nThere\u2019s shift in a sense that home networks are supporting a growing number of services that extend far beyond the traditional edge of the network. For example, an individual\u2019s home appliances can participate as part of the regional electric power management system, health devices in the home can be connected into remote health monitoring systems, entertainment and personal application data can be stored remotely and accessed seamlessly on demand. These emerging services are delivered by finely-tuned infrastructure that includes specialized networks. This evolving edge is rapidly changing how individuals interact with the Internet, and offers the potential of new and exciting interactive applications and services.\nEvolving Edge, however, raises challenges for the current general purpose architecture of the Internet. Growing complexity of specialized networks for purpose built services at edge may create independent islands of connectivity. Businesses to maintain their edge are establishing private networks and private domains to create control for their own business structures. This proliferation of \u201cprivate\u201d IP-based edge networks that don\u2019t use the \u201cpublic Internet\u201d is going to increase by orders of magnitude. This could lead to fragmentation of the open, global Internet.\nSpurred by increasing innovation at network edge,\u00a0if specialized networks dominate the connectivity environment, this will create obstacles for innovation and the deployment of new end-to-end services and technologies.\n","93":"\u201cConnectivity and ubiquitous coverage are the backbone of an inclusive new digital world and a prerequisite for a successful further innovation of services online.\u201d\nFor many end-users, ubiquitous and increasingly robust connectivity has simply become a part of the environment most of the time, and rather the state of being offline has become an exception, as echoed by The Internet Society 2017 report- Paths to our Digital Future. It would not have been possible without the widespread deployment of wireless access networks. Mobile access is already the primary way people connect to the Internet in many parts of the world. Devices and people hop from Wi-Fi to cellular networks, and there are use-cases that put a premium on this continuous ubiquitous connectivity. Emerging technologies such as 5G, and new use-cases such as IoT promises to accelerate this trend.\nThe future of ubiquitous connectivity is not without challenges. Networks have to sustain increasing connectivity and bandwidth demand as result of mushrooming IoT, HD and 4K videos, and on top of that have to encourage yet to be imagined new use-cases. The proliferation of connected systems and wireless devices, will make the network edge more complex, and as a result may lead to specialized and proprietary standards. Therefore, it is also essential to focus on development and deployment of open standards that facilitate interoperability so that people can roam seamlessly across different wireless technologies.\n","94":"It is clear that we need a common understanding of the semantics\u00a0and significance of the terms and concepts we use when discussing the\u00a0NGI. To\u00a0avoid duplications and omissions we should think about and agree upon a\u00a0common framework for defining the elements that make up the NGI. This\u00a0may end\u00a0up being a federation of existing nomenclatures or we may embark on\u00a0creating\u00a0a unified model that we can all agree upon. This is the space where that\u00a0discussion and proposals an be forwarded.\n","95":"A very important point raised in Hub4NGI D2.1 is that legislative speed cannot keep up with technical development, resulting in ineffective and out of date legislation. Legislation and the legislative process are recurring themes in the sources. The key elements for legislation can be seen in following Figure:\n\nLegislation\nIt is usual that citizens and businesses are ahead of governments in understanding the implications of Internet, and overall conclusion is that the legislative process must reform to adapt to the speed that technology evolves at. Changes are rapid, so legislation must adapt. [PSNC-2017]\nIn order to make legislation keep pace with technology, various solutions are proposed. Takahashi-2017, suggests that AI could provide automation to speed up the legislative process, however on the other hand, as suggested by Net-Future-2017, interdisciplinary approaches will be required to determine legislation for new technology, especially when legislating for safety critical and applications with high social impact. It was advocated to consult as many people as possible through the new methods of E-Participation and smart consultation. Such consultation techniques will engage more citizens quickly. Multidisciplinary teams should also work together to determine appropriate legislation for safety critical applications of technology so that both the technical, application, ethical and legal perspectives are considered.\n","96":"Another widespread concern, raised in Hub4NGI D2.1, is the abuse of Internet technologies causing threats or limitations to democracy and liberty.\nIn an online article titled \"Will we still have a single global internet in 2025?\", the Ditchley Foundation also mentioned that the authoritarian governments wish to use the capabilities of the Internet to exert controls over citizens and keep their data at home in order to ensure access.\nGovernments are aiming to regularise the Internet and ensuring prosperity. As depicted in a report of the CSaP Policy Workshop on NGI, States are working to enforce the data localization laws, which require companies to store their customers' and employees' data locally.\nAccording to a recent study and analysis by Lipparini & Romeo (2017), the democracy is seen to be under threat in such a way that electorate can be manipulated via the power of the Internet as a source of big data and as a broadcast medium. The study points out that the governments and tech-companies may collide with each other to spy on citizens and implement social control.\nOn the other hand there is a trade-off between regulations towards social control and privacy protection. Applying the \"hard regulations\" against fake news, may imply the risk of censorship and social control which may violate some of the human values such as social liberty and privacy. This trade-off is highlighted in the Overton's report, and a multidisciplinary approach is highly recommended to balance between the human rights and legislation.\nThe Hub4NGI D2.1 also raised some of the issues and challenges in this context along with some recommendations. It is advocated to enforce regulations on search engines so that they produce more balanced results. However, on the other hand, users may not want this. They may prefer to get results that agree with their opinions and preferences. If more \"objective\" results are returned, the user's perspective may be that their search experience is worse than before. Citizens\u2019 social groups should not be interfered with, unless there are genuine reasons (such as illegal activity). Many citizens want to interact with like-minded people, and clearly in a liberal society, this should not be prevented.\nPromoting inclusiveness (e.g. broadband for all) and diversity (e.g. heterogeneity and multidisciplinary discourse) is a possible partial solution, but citizens cannot be forced into diversity. All citizens must have equal rights in the digital society. As the companies and individuals all are increasingly demand for fast broadband therefore there should be the right infrastructure in place in order to ensure that the citizens and organizations are not discriminated [Lipparini & Romeo 2017]. Multidisciplinary research is needed in order to answer questions relating to the state control and liberty.\n","97":"There is a risk that the Internet becomes an \u201cecho chamber\u201d, where profiling of citizens, \"fake news\" and citizens\u2019 own preferences and social groups distort the information citizens can see to biased opinions or sympathetic views that reinforce entrenched views.\nMultidisciplinary research is needed in order to answer questions relating to the promotion of information diversity and truth in the Internet. Many of these questions relate to the causes of limited or biased information and how the information can be made less biased or more complete. Examples of causes include unbalanced search results from Internet search providers that tune the results to users\u2019 previous searches or preferences; restrictions on Internet search results through interventions by authoritarian governments; the current high-profile of \u201cfake news\u201d (is the news really fake or is someone merely accusing it of being fake?); and social groups that pursue a particular agenda by reinforcing certain arguments, ignoring other opinions.\nThese questions raise other questions of jurisdiction, state control and liberty, and a question overarching them all is: what levels of intervention are acceptable before liberty is compromised?\n","98":"Social networks and online gaming aren't just changing the way we lead out lives day-by-day but may also be altering our self-perception.\nAccording to Professor Sir John Beddington, we could see a rise in social exclusion for some and problems with balancing rights and liberties against privacy and security. There have also been recent reports that smart cities may be excluding certain sections of society like the elderly.\u00a0\n\nDo we accept the changing landscape or take action to shape future hyper-connected sociality that addresses critical issues about trust and governance?\n\n\nHow do we make it more democratic and based on user experiences?\n\n\nWhat principles should form the basis for the next-generation social media platforms as a global social sphere?\n\n\nWhat technologies and mechanisms do we need to make sure it is open and inclusive?\u00a0\n\n\nHow do we improve the role of prosumers, communities and small businesses, mastering technological barriers, introducing innovative and participatory forms of quality journalism? And how do we make sure various types of data are used securely?\n\nThese are just some of the questions that need answering to build a new, EU vision for the next generation internet.\n\u00a0\n","99":"The digital world needs to be accessible to everyone. We can bridge the digital divide and equip all groups of society, including persons with disabilities and specific needs, by taking advantage of ICT, and by enabling capacity building in digital skills.\u00a0\nThe main drivers behind the framework for implementing a Regional Initiative for Europe are based on the following values:\n- Accessibility\n- Affordability\n- Skills Development\n- Digital Inclusion\n- Sustainable Development\nThis regional event for Europe was being jointly organized by the Telecommunication Development Bureau (BDT) of the International Telecommunication Union (ITU) and European Commission (EC), and hosted by United Nations Vienna in December 2018.\nTelecommunications and the Information and Communication Technologies (ICTs) have vital importance for people's empowerment and in promoting accessibility policies. The event highlighted the relevance of joining efforts to remove barriers and enable human development and social inclusion of persons with disabilities and special needs and other groups of people with specific needs, either through cooperation, programme and projects development, generating partnerships, and training.\nWithin the event, the ITU Office for Europe organised its Regional Contest on Innovative Digital Solutions.\nResults of the contest are now announced, celebrating made-in-Europe ICT.\nWinner:\nEVA (@Vision_EVA; http:\/\/www.eva.vision\/): Extended Visual Assistant. EVA is voice controlled eyewear for the visually impaired. EVA's Artificial Intelligence recognises objects, texts, signs and verbally describes what it sees.\nRunners-up:\nPEDIUS (@PediusCall; https:\/\/www.pedius.org\/en\/video\/). Pedius is a communication system helping Deaf and Hard of Hearing people to make phone calls, using voice recognition and speech synthesis technologies.\nFEELIF (@FeelifOriginal; https:\/\/www.feelif.com\/). Feelif is a multimedia tool for blind and visually impaired people which enables them to feel shapes on standard touchscreen.\n\"We are looking forward to addressing in the near future issue of 5G Impact on ICT Accessibility. We hope to have you on board as well as other visionary stakeholders\", Jaroslaw Ponder, Head of Office for Europe, ITU.\n#ICT4SDG #WSIS #Disability #Accessibility\n","100":"Two types of citizens live in the \u201cglobal digital village\u201d: digital natives, those born in the internet age, and digital migrants, those born before the internet became so central to our lives. These digital migrants are the so-called \"silver surfers\".\nDigital migrants and digital natives often share the same house, the same office space and same public places. Yet, digital exclusion is preventing digital migrants from fully taking advantage of digital tools. We need to nurture digital inclusion, digital literacy and digital skills for all the silver surfers living in the digital global village.\nWithout these, digital migrants cannot carry out even the most basic of daily digital tasks. To overcome this barrier, we need to give them access to digital skills. This is the only way to fully benefit from participation and knowledge from all citizens.\nThe EuroDig 2018 session, Don\u2019t forget silver surfers \u2013 Digital inclusion and Literacy was all about making the internet more \u201cinclusive\u201d. Discussions focused on potential models for digital friendly citizenship and helping to build bridges across generations.\nIt also looked at how digital literacy and skills may contribute to the process of lifelong learning for digital migrants. The session is a chance to learn about best practices in a European context, taking into consideration local developments in Georgia and the Caucasus Region.\nEuroDIG18\n","101":"In a hyper connected world, no sector of the economy will be untouched by technology and only those who adapt quickly to technological change will be successful, as analysed by The Internet Society 2017 report- Paths to our Digital Future.\nAs the Internet economy evolves over the next ten years, fuelled by innovations in technology and business models,\u00a0 advances such as the Internet of Things (IoT), Artificial Intelligence (AI), and blockchain could bring about an industrial and technological \u201crenaissance\u201d, and only those who adapt quickly to technological change will be successful. The pace of this technological change will dramatically accelerate as IoT, AI, and blockchain technologies are fully deployed. Governments will need to increase spending on training programs to help workers impacted by technological displacement. The growth of IoT will effectively make all companies technology companies. This shift to greater dependency on technology will be accompanied by new security concerns. As one Internet Society survey respondent in North America noted, \u201cLosing control of your data is catastrophic today. Tomorrow, it could mean the death of your business\u201d.\nThe impact technical advancements can have on traditional economies is a question as old as the age of technical innovation itself. There is a similar widespread concern currently fuelled by the potential disruptions of hyper-connected world and AI. Measures should be taken for general human civilization and economy to adapt to this technical renaissance.\n","102":"Multidisciplinary Design is viewed as important by almost all of the sources surveyed as mentioned in Hub4NGI D2.1, and involves bringing together the right mix of experts from different disciplines who collaborate to address the problem at hand. The key elements of multidisciplinary design are shown in the following Figure.\n\nMultidisciplinary Design Elements\nResults from the FIRE STUDY Next Generation Internet (NGI) Digital Innovation Networks Consultation involving a Delphi Study with an expert panel emphasized the importance of multidisciplinary and end-to-end design. More than 50% of survey participants opined that the multidisciplinary approach should be the main policy recommendation for the NGI experimentation. Realising the all-and-always connected vision of the Next Generation Internet Experimentation System, the multidisciplinary approach will help in facing a number challenges. Bringing together people, data, devices in a variety of deployment scenarios will require end-to-end experimentation to be driven by combining expertise from different technology domains (e.g. wireless networks, optical networks, cloud computing, IoT, data science etc.) in relation to specific vertical sector needs (health care, creative media, smart transport, marine industry etc.) and horizontal disciplines push factors (e.g. psychology, law, sociology, arts, economics)[FIRE Study DIN 2017].\nWith the advancement speed of new technologies, the governance to legislation has become an ongoing process therefore multidisciplinary teams are deemed necessary. Hybrid teams of technical experts and lawyers will help ensure that legislation is relevant and implemented effectively [Takahashi 2017].\nThe Hub4NGI D2.1 emphasis that multidisciplinary teams are particularly suited to supporting end-to-end systems design, due to its heterogeneous nature, from edge computing, through networks to processing and application design. Participatory design patterns such as co-design and co-creation involving user communities and citizens are seen as part of end-to-end systems design. In turn, end-to-end design is supported by interoperability and open standards. Interoperability and open standards are clearly important to enabling end-to-end system design, and therefore should be encouraged and supported. The discussion on the recommended mechanism for support of multidisciplinary design can be seen in the innovation networks discussion channel.\n","103":"Web #accessibility, is a practice that allows people with disabilities to use the web the same way as everyone else.\n\u00a0\n@axschat Twitter Chat Logo and #axschat hashtag\n\u00a0\n","104":"R U - I o T Ready?\nThe catchphrase, R U - I o T Ready? has raised some interesting questions such as, What is IoT? Why should I care? and What does \"Ready\" mean?\nWhat is IoT? I will use this simple definition of IoT from Webopedia\nThe Internet of Things refers to the ever-growing network of physical objects that feature an IP address for Internet connectivity, and the communication that occurs between these objects and other Internet-enabled devices and systems. I will add to this definition \"for Human-Centric Solutions.\"\nMore definitions here https:\/\/en.wikipedia.org\/wiki\/Internet_of_things\nWhy should I care?\u00a0 In this last month's article Change Agents\u00a0Impacting Building & Facility Management - Marc Petock, provides this wisdom,\u00a0 IoT continues as a game changer; it is changing what we are delivering---how, when and where. However, realizing its potential starts with understanding the value and contribution it brings.\u00a0 IoT is as much about behavioral changes and business opportunity, not just technology. We need to operate and manage buildings based on outcomes, not output.\u00a0 IoT is not the objective of this transformation but the platform upon which to connect, collect and analyze data so we can measure and validate these outcomes. Building owners and operators should not \u201cbuy\u201d IoT; they should purchase solutions to specific problems where IoT components are part of a solution.\nWhat does \"Ready\" mean? Being ready is being able to discuss the merits of IoT and applied them to our applications for human-centric solutions.\u00a0\nWhen I originally created the catchphrase, I was thinking the question was focused on our traditional smart automated building industry but now have come to understand it is not just our industry that needs to be IoT ready. Those who are the reason for our human-centric solutions needed to be part of the discussion, education, and solution and made IoT ready. This process of developing inclusive solutions requires us all to think more like app developers creating our human-centric solutions as discussed earlier in this column\nhttp:\/\/www.contractormag.com\/iot\/human-centric-building-automation\nThose who identify themselves as the IoT industry need to get ready by better understanding the slow dynamics and change agents of our smart automated buildings industry. I prepared this timeline of industry evolution last month including Marc comments to improve understanding of our industry's history and its (sometimes) painfully slow evolution.\nIoT folks need to review the last 20 year plus timeline to understand better that this is not a race for IoT to win but more of a fun run where traditional controls and new IoT folks will gather to discover each other's strengths and build on them for the greater good.\nAs as an industry, we need to stop the waste of time in this creation of them and us, we are all in this together it is not a war, it is a love-in \"for Human-Centric Solutions.\"\nOur opportunity is 2B IoT-Ready and uses our combined knowledge to gracefully and purposefully connect humans to our large inventory of existing soulless buildings in North America.\nThis post provides insight to the why you need 2B IoT Ready, Finding Generation IoT: New Talent for a New Era. We are experiencing a worldwide scramble for IoT-capable staff.\nWhy is it mandatory that we be IoT ready?\nIt is mandatory, because the next big thing about to land is what I am calling IoT ready.\nFrom Harbor Research - Machine Intelligence Through Data Transformation\nAggregation, transformation, and management of data from sensors, machines, and equipment is the holy grail of machine learning and the IoT; a fundamental core enabler\nThe fact that a wide range of sensors, machines, and equipment can transmit information about status, performance, and usage, and can interact with people and other devices anywhere in real time points to the increasingly complex role of data in IoT systems. This only compounds when we consider the many billions or more of networked devices that many observers are forecasting will be deployed and the scale of data they will produce. Gathering and analyzing machine data is not a role for human beings. The only way to achieve it is to have the product\u2019s own \u201cmachine intelligence\u201d continually delivered back to its creator. This requires three things: \nMore and more my thoughts are being formed my observations reflected and shared in my daily posting on twitter of what IoT ready might included.\nThis post is scary and validated by wall street.\nhttps:\/\/twitter.com\/Ken_Sinclair\/status\/928926211610361856\nBig Data and analytics is something we have been talking about for a while, and we are either using it, providing it, or selling it. At this stage of the game, it has created a business opportunity that many have embraced. Someone has to connect the data to some form of filtering or to an analytics platform to make the data useful. But what happens when data no longer needs a human interaction?\nCheck out this video, courteous of the Wall Street Journal. If you are like me, it will shock you, scare you, and intrigue you. Whatever you think about the video, you cannot ignore what these business leaders are telling you is happening.\nhttp:\/\/www.wsj.com\/video\/top-executives-how-ai-will-change-all-industries\/501976AE-00D4-412A-92D0-B65988C274E8.html\nExecutives from Baidu, Intel, Samsung and Walmart talk about how artificial intelligence will soon redefine our technological lives. They speak at the WSJ D.Live conference in Laguna Beach, Calif.\nIn this article What's driving the building automation market forward?\nEnergy management, government initiatives, and IoT deployments are three major drivers boosting market growth.\nA report from ABI Research forecasts that global smart building facility services revenue will grow from US$625 million in 2015 to more than $8 billion in 2021. The report cited that large buildings primarily in North America and Western Europe implement cloud-based smart building platforms or integrate existing building management systems to smart building platforms.\n","105":"How can the next generation internet change the nature of education and learning so it empowers the many, not just the few, including the most vulnerable users?\nWith open, trusted and personalised learning solutions that optimise digital learning and allow users to engage and interact with content and with peers.\u00a0\nA digital learning incubator will ensure European citizens have the same digital learning opportunities:\n\u00a0 \u00a0- by extending personalised learning across society, regardless of age, gender and other socio-economic factors.\n\u00a0 \u00a0- by increasing\u00a0the number of distributed learning solutions for children with special educational needs.\n\u00a0 \u00a0- by improving\u00a0opportunities for start-ups and SMEs taking to market new personalised and inclusive learning solutions.\u00a0\nThe European next generation internet initiative will help unleash these opportunities through the Work Programme 2018-2020: ICT-30-2019-2020. It will do this in two ways: through an Innovation Action rolling out a Digital Learning Incubator and a Coordination and Support Action in the area of Digital Learning.\nAmong other things, the Innovation Action will comprise multi-stakeholder alliances that can jointly achieve fast-paced breakthroughs in personalised and inclusive learning online.\nThe Coordination and Support Action will pinpoint emerging research challenges from digital certification of learning outcomes and blockchain technologies and their uptake for a more inclusive and personalised learning experience.\u00a0\n","106":"The NGI Networking Session on NGI Skills and Education at the NGI Forum 2017 asked two key questions about the future of education:\n1. How can education help the next generation internet? What skills will citizens and workers need?\n2. How might NGI change the nature of education in schools and universities?\u00a0\nCurrent education systems give the same education to all children and students but do they\u00a0still need to learn\u00a0handwriting and basic maths?\nThe NGI will be key to customising education globally so each child has their own learning path no matter where they are in the world.\u00a0\nThe NGI can also support crowdsourced research, an environment where students come up with bright new ideas and push them out to the internet for others to take forward and create new communities around the ideas.\nBut what about identity, safety and privacy? Children will need to handle not just their physical identity but also their online identity, and information that could remain online potentially for a long time. Most importantly, they need to understand the terms and conditions of using the internet so it works for them, not against them.\u00a0\nIn this video, John Domingue, Director of the Knowledge Media Institute at the Open University, shares the main takeaways from the Networking Session..\u00a0\n","107":"Complementary to the evolving network edge, the traditional hierarchy of backbone, access and enterprise networks is flattening, as echoed by The Internet Society 2017 report- Paths to our Digital Future. In the past, this hierarchy meant that backbone networks would exchange, or transit, traffic destined for access networks they did not directly connect. However, the increasing use of CDNs and the continuous growth of Internet Exchange Points (IXPs), where traffic is often passed directly to access networks, have reduced the need for transit traffic. Geoff Huston, Chief Scientist at APNIC, referred to this as \u201cthe death of transit\u201d.\nWhile these changes improve experience for end-users by reducing latency and jitter, and lower costs\u00a0 for large-scale service providers, the cost of implementing capabilities such as CDNs and other close-to-the-edge service points puts smaller or emerging service providers at disadvantage. For example, large on-demand video providers can establish caches close to their users to provide better quality service while smaller providers are unable to do so. This trend may lead to consolidation and reduced competition in service offerings.\nThe potential implications therefore include reduced innovation in long haul networks and lack of choice for consumers. Internet infrastructure and economy will be at risk of being dominated by larger players having capability to invest at the edge unlike SMEs and start-ups, preventive of a healthy competitive ecosystem and next generation of permission-less innovation.\n","108":"\u201cIoT compounds every security problem ever seen and multiplies every problem of the Internet. Your toaster could be sending out spam.\u201d -Technologist, North America\nConnected devices add enormous complexity to an already complex security environment. They also raise the stakes, as with high convergence and influence of Internet into our lives, there is increased potential in cyber threats to damage physical assets and harm human life. The Internet Society 2017 report- Paths to our Digital Future identifies the root of the problem being de-prioritization of security over IoT innovation, we are adopting IoT faster than we can secure it.\nThe case of Mirai attack of 2016 is often taken up to prove the extent of damage mere plug-and-play remotely-managed IoT devices can have on the broader Internet. Many of these devices on the market today have very limited built-in security measures, and will not be updated through the devices\u2019 lifetime. Furthermore, explosion in the requirement of such connected devices in transportation, health, smart homes and many other domains alter the entire landscape of cyber threats. An agreement on IoT Security frameworks and best practices is essential to safeguard safety and realize full potential of IoT.\nThe role of government cannot be undermined; more risk there is to critical infrastructure from connected devices, the greater the perceived need for governments to intervene. If the threats arise from something as innocent as an Internet connected light bulb, the government will be tempted to regulate the Internet. But similar to the events in the past, there is a fear that will government responsive respectful of privacy and individual autonomy. All stakeholders, apart from government, from users to manufacturers, will need to be more security aware and work together towards a more comprehensive and resilient security environment. The insurance industry, for example, may exert market influence, for example, by requiring systems or devices to have security certifications in order for their owners to be insurable.\nWe need to address IoT-related security issues before we can realize the full benefits of the Internet economy. A sustainable and effective long-term solution will require ongoing collaboration, and a commitment by manufacturers and service providers to incorporate privacy and security in their design processes, from initial conception to long-term support and updates. \u00a0\n","109":"A small number of major companies may further concentrate their power by absorbing potential threats or new opportunities. The reach and resources of Internet platforms mean that start-ups will be acquired in their infancy, before they can disrupt the bigger players. Will the idea of permissionless innovation and the notion that anyone can start the new \u201cGoogle\u201d still be realistic, are the\u00a0broad questions addressed by The Internet Society 2017 report- Paths to our Digital Future.\nThat said, innovation and new services on the Internet often develop and move faster than anyone can predict. Economic growth and business opportunity will increasingly depend on a dynamic and innovative Internet, which, in turn, will depend on open interoperable standards and permissionless innovation. This demand for continuous innovation by industry, users and even government may mean that even today\u2019s large Internet platforms will face fierce competition from emerging players, including those outside the traditional ICT sector.\nA new generation of entrepreneurs coming online from emerging countries has the opportunity to use technology to solve local problems, reach global markets and drive innovation. As more people benefit from coming online in the next five to ten years, the opportunities and funding for entrepreneurs and start-ups will grow locally and globally. Start-ups will be able to scale more quickly, accelerating past the traditional path of company growth. And as Internet growth shifts from the historically strong digital economies in North America and Europe to emerging markets in Asia, Latin America and Africa, new innovation leaders and technology hubs will emerge. These new entrepreneurs should play a pivotal role in shaping the future of the Internet economy.\nThe question is if smaller entrepreneurs are going to be able to compete, or get caught up in an uncertain environment of investment and competition from big conglomerates?\n","110":"\u201cCountries need to enhance their industrial policies and consumer protection frameworks to prepare for IoT \u2026 National IoT frameworks will also need to incorporate cultural considerations that will impact IoT development.\u201d\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0-Internet Society Member, Africa\nInternet of Things is putting more and more things on the Internet empowered by ubiquitous connectivity, increasing bandwidth and sensor technology. IoT is not just limited to this extended Internet infrastructure, but as well includes applications and services deriving some useful functions from the connected devices, with future promising AI enabled advanced interaction with connected objects through voice and gesture, and virtual and augmented reality experiences through data generated by IoT.\nWith this development, we are approaching a state where Internet will be integrated into every walk of our life. This convergence of the physical and digital worlds, as Internet will be used to control much of our objects and environment, will bring many opportunities but would also profoundly impact all sectors of our society and economy, as addressed by The Internet Society 2017 report- Paths to our Digital Future.\nIt may reduce mundane tasks, freeing workers to focus on creative, non-routine aspects of their jobs. But, as convergence gains momentum, every industry faces disruption that may change or even destroy jobs.\nIoT brings a convergence of ICT and traditional analogue industries such as manufacturing firms, increasing the competition between two, and also evolving the current dynamics of Internet economy.\nCurrent landscape of industry-specific regulatory frameworks is not well suited in a changing world in where connectivity blurs the lines between sectors of the economy. The challenge for policymakers and government will be twofold: one, to avoid falling further behind technological change; and two, to avoid disproportionate and potentially harmful regulations in response to evolving security threats.\nWith IoT, there will be risk of mass surveillance, potentially harmful insights by curating and analysing user data, thus profoundly impacting privacy as a result.\nWhile lives may be improved by smart homes and smart cities, IoT is such a disruptive technology that it can impact many walks of human life. Therefore, its effects should be foreseen, and safeguards put in place to check any profound negative impact on economy, privacy, and society.\n","111":"Although it is commented by some that AI projection is just a marketing hype, however many in industry and governments believed that the role of AI is pervasive in the future Internet economy. AI presents enormous opportunities to create new jobs, new industries and new ways of connecting. At the same time many believed that AI would steal thousands of jobs. The nature of work will drastically change as the AI and automation drive significant structural change across industries. This change will empower workers and minimize the inequalities among people and between countries. Many existing jobs may be displaced as AI moves beyond monetising user data to changing how products and services are delivered. Adapting to the pace of change will be a major global challenge for the immediate future. AI could be a partner in human intelligence, letting us take on and solve much bigger challenges. As one survey respondent explained, \u201cThe distance between people\u2019s brains and the Internet will become ever smaller, and the interface between the two ever more sophisticated\u201d [ISOC report on \u201cPaths to our Digital Future\u201d 2017].\nBecause of the AI, there will be huge gains in scientific research, transportation and delivery of services. With the help of open source development, AI has the potential to diminish the difference between developed and developing worlds. For example, a country that relies on agricultural production could use AI to analyse crop yields and optimise food production. AI applications in healthcare could be a game changer for disease detection in low income areas.\nDoes the global society has made itself ready to absorb the change, and prepared for new economy and new business models? The intelligence and services used to manage and implement manufacturing or services may still reside in developed countries rather than being developed locally. AI might exacerbate the digital divide in significant ways that would have geopolitical implications.\n","112":"The rise of nationalism and populism around the globe could cause governments build national policy barriers that fragment the Internet. If current trends are any indication, more and more governments will restrict and control Internet use and access through censorship, network shutdowns and other means. This is a matter of great concern and is highlighted in the ISOC report on \u201cPaths to our Digital Future\u201d released in 2017. This report raised the questions related to globalization and the domestic pressures that need to be answered before we go ahead with the future Internet:\nWill governments embrace globalisation, or will they respond to domestic pressures to strengthen both physical and cyber borders?\nWill they support and promote multistakeholder approaches to policy, or will they retrench behind the walls of multilateralism?\nGlobalisation could pull Governments to become more attuned to the need for cross-border and cross-sector cooperation on cyber threats like crime and terrorism. The complexity of the challenges should compel governments to work with other stakeholders. However, for such efforts to work and to have legitimacy, they will need to move beyond traditional public-private partnerships and include civil society.\nThe governments need to support multistakeholder approaches particularly when it comes to setting norms and best practices for cyberspace. But because of the slow political process the tension between multilateralism and multistakeholderism will continue for the foreseeable future.\nThe ISOC report throws a question about the use of multi-stakeholder approaches in the future. It also questions whether civil society groups and activists will have a real seat at the table. The answer to this question will have significant implications for the future of online rights and freedoms. The report mentioned the pressing need for new models of Internet governance in this evolving multipolar world. These new diverging models will be able to shape the global Internet and its core principles. If the international system continues to turn inwards, the implications for the global Internet will become ever more profound.\nRead full report here\n","113":"In the ISOC report on \u201cPaths to Our Digital Future\u201d released in 2017, it is believed that the Internet should empower users with certain abilities which must remain at the heart of the Internet experience for everyone and everywhere. The users must be able to connect, speak, innovate, share, choose and trust.\nLike civil society, with the evolution of the digital society and the expansion of the Internet into our economy, governments need to be more active as policymakers. From cybersecurity to societal issues to technologies such as the Internet of Things (IoT) and Artificial Intelligence (AI), governments will face a host of new and complex issues that might challenge all aspects of their decision-making. The pressure of security challenges is therefore growing the future of Internet is highly dependent on how the governments respond to this issue.\nOn the other hand, as there\u2019s a mix of public and private sector services, the roles of responsibilities among governments and private sector is blurred and complicated.\nCould this result in the private sector assuming responsibilities that are traditionally those of governments\u2019?\nIf so, will they be subject to the same accountability and governance mechanisms as governments? In the future Internet economy, the use of IoT and artificial intelligence will increase the need to be vigilant about transparency and accountability in decision-making and governance. With the increase in the more complicated relationships between public and private sectors, transparency and accountability will also be needed to understand and manage.\nTo what extent, do governments need to work with the new business models and technologies?\nLegislation process needs to be accelerated to keep pace with the technological developments. There will be ever increasing pressure on governments to act with the pace of change. Are governments prepared for the drastic changes in the economy, especially in traditional industries most challenged by technology? Government\u2019s tendency to apply legacy regulatory models to new and emerging issues is of particular concern.\nRead full report here\n","114":"Wealth distribution and economies are being increasingly influenced by the digitization and Internet. The Hub4NGI D2.1 pointed out that the Internet has changed the market dynamics. Only the companies doing service innovation might survive. The major elements of economics and wealth distribution are shown in the following Figure:\n\nEconomics and Wealth Distribution\nThe proliferation of AI and automation is becoming a major threat to human employment. As the machines will take over certain tasks in the economy, there is a need to find new ways of distributing wealth. 70% of European citizens agree that robots and artificial intelligence are going to steal peoples' job in near future [Lipparini & Romeo 2017]. Before it would happen, we need to find the answers to these questions:\nHow can human and machines coexist in the economy?\nWhat roles are humans ideally suited for and what roles are machines best at?\nHow can humans' livelihood be sustained?\nHow can machines be paid for?\nHow the autonomous machines be legislated?\nShould robots and AI be legible to pay taxes?\nHow to support SMEs in the new Internet economy?\nWhat alternative business models exist to challenge the dominance of the incumbents?\nCompared to other business types, SMEs are seen to be at a disadvantage and need help to take advantage of NGI. Investment policies and legislations should aim to increase the abilities of SMEs to profit from NGI technologies. Furthermore, new business models are needed to challenge the current dominance of the large incumbents. New collaboration based business models which integrate people and resources from various disciplines might help significantly.\n","115":"NGI Interim Study Report on analysing stakeholder input found\u00a0Safeguarding Openness to new Entrants\u00a0to be an essential feature of future human-centric sustainable Internet. The following 4 aspects of safeguarding openness were identified.\nUnlocking New Verticals:\u00a0 Countermeasures are required in NGI against market dominance and lack of choice and control in application domains critical to the users. One of the ways it can be achieved is through suitable microscale alternatives based on open source, open standards, thus dissolving the dependency on hyperscale giants.\n\t\u00a0\n\u200bPreventing Horizontal Spillover:\u00a0For reducing the dominance and near complete dependency, take-over of strategic markets by dominant players from related fields should be avoided in NGI.\n\t\u00a0\nImproving low-level discovery:\u00a0Unbiased and unmediated search, and direct discoverability of services and content offered should be provided for where possible.\n\t\u00a0\nEnd-user capabilities with open spectrum (specific to 5G):\u00a0Adequate\u00a0end-user controlled radio spectrum should be made available as it allows for grass roots innovation.\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\nOpenness to new entrants in NGI can be\u00a0enabled by making it simpler to create services and by unlocking dominant positions in application domains strategically important to the users, which is hampering development and innovation. Freedom of use is ensured by mechanisms supporting open access, such as stimulating the offering of scalable shared mechanisms to support multi-cultural needs, like multilingual use and local content i.e. availability of ICT in every language \u2013 driven by the needs of the language communities rather than business decisions. The strict enforcement of Net-Neutrality must be the legal requirements which means that no type of internet usage shall be discriminated against by access providers. This openness drives sustainability of the NGI while enabling diverse creativity and innovation.\n","116":"Hub4NGI D2.1 deliverable advocates Innovation Support as the process of helping applied research output that addressed some real-world problems turnaround into a product or service to the needs of some users.\nReferencing Nurse [Nurse 2015] throughout, the deliverable presents the process of innovation as a journey from pure research to applied research and finally to a finished product. Applied research aims at achieving specific outcomes and is directed towards addressing real world problems. The pre-requisite therefore to applied research are understanding of the needs of the target user community together with a sufficiently well-developed knowledge base of the subject area which is strengthened by the pure (or discovery) research. Once the applied research results in proving the utility of a technology for a particular application, thereafter innovation is materialized, as\u00a0results are developed into a marketable product or service and tested in real world conditions. Following figure demonstrates the interpreted innovation lifecycle from Nurse [Nurse 2015].\n\nInnovation Lifecycle\nAs also evident from the above innovation lifecycle, the research process does not have to always follow a liner direction from research to applied research and finally to product. Knowledge can be acquired from applied research and give clues to further discovery research.\nThe deliverable also investigates that there is a gap between applied research outputs and product and service development due to the traditional ways the two activities are funded. Applied research is often funded by public money (e.g. EC or national grants), and product development is often funded by private money (e.g. venture capital for entrepreneurs). This gap is addressed by so called Innovation Agencies. Glennie & Bound describe 4 major types of innovation agencies after surveying and analysing 10 national Innovation Agencies, e.g. Innovate UK, DARPA (USA) and Tekes (Finland): (i) Market and System Fixer (fix failings in the market that mean innovations are not getting through), (ii) Industry Builders (developing and nurturing a particular industry sector), (iii) Mission Drivers (create innovation to solve recognised problems), (iv) System Optimiser (mixing the three above strategy types).\nThe deliverable recommends that innovation support be guided by the approaches taken by national Innovation Agencies,\u00a0as these have proven track record in generating opportunity that has transferred into viable and sustainable businesses, creating strong bodies of expertise and strengthening their respective national economies.\n\u00a0\n[Nurse 2015] Nurse, Paul. \"Ensuring a successful UK research endeavour.\" A Review of the UK Research Councils, Department for Business, Innovation & Skills, UK Government (2015).\n","117":"Hub4NGI D2.1 deliverable, citing DIN Forum 2017, defines evidence platforms as places where researchers can share, store as well as search data and models, where solutions to problems can be archived and possibly made available. Evidence bases thus provide a platform for innovation as through sharing data and models, people and other stakeholders can collaborate, identify new ideas and test existing ones. The deliverable, however, argues that such a single integrated platform providing sum functionality of data and solutions to problem is not available, though individual functions are independently available as briefed next.\nFor evidence platforms to be effective, it is important that the practice of open science or Open Research Data (ORD) is promoted to which both EC and the OECD have investigated mechanisms. EC consultation resulted in the Public Consultation on Science 2.0\u00a0 with the name Science 2.0 now being replaced by open science, which investigated how science needed to change given new technologies and changes in attitudes, so as to reinforce science\u2019s core principles of openness, transparency and reproducibility. The OECD has also determined its policy to clarify and support open science. Asserting that science should be a global public good, accessible by and for the benefit of all humankind,\u00a0it accordingly defines open science as including open access to (i) scientific publications, (ii) research data, (iii) digital applications and source code, (iv) scientists, the public and commercial companies.\nRoyal Society in concurring with the Public Consultation on Science 2.0, highlighted that science has benefited from open practices throughout history and openness should be default for science. In keeping up this practice, making science data open enables the public to more easily engage in the results and process of science, also arguing that data-intensive science is becoming a driver of economic growth and development. The deliverable giving example of Zenodo stems out that scientific community also has clear will to support open research data. Fed4FIRE+ D2.1 deliverable [Taylor 2017] investigates Zerodo from the point of view of an experimentation platform.\nOther than ORD repositories to store and curate results of scientific experiments,\u00a0DIN Forum 2017 advocated that sharing knowledge on problem solving would also have additional benefits to support the innovation community quoting \u201coften the cost of looking for solutions to problems is so great or the search intractable, that we resort to making our own solution instead of finding other peoples\u201d. The deliverable gave example of Stack Overflow as a popular forum for persisting solutions to programming problems, and raised an open question to identify such forums in other important domains as well.\nApart from open data and solutions to problems, PSNC 2017\u00a0identified open public data as also being important specifically for start-ups. The deliverable summarized by realisinig the need to survey and forms a directory of platforms that provide above functions. Additionally, if there is any value in integrating these functions and platforms together\u00a0over the integration Google search\u00a0currently provides.\n[Taylor 2017] Taylor, S. Fed4FIRE+ D2.01 Initial Guidelines on Data Management. In preparation. 2017.\n","118":"Experimentation Platforms are strongly advocated as an important component of NGI innovation. The Fire Study reinforces this, emphasizing that heterogeneous,\u00a0integrated and\u00a0real-world experimentation environments or resources are important, as their inclusion early in the validation and end-to-end testing of new protocols and services incorporates fast feedback. The study goes on to recommend that new experimentation areas should open up to \u201cinclude a pan European blockchain, including robotic devices, and the establishment of mixed experimentation environments with large numbers of heterogeneous devices with IoT programmability, and Large Scale Streams\u201d.\nPSNC workshop on NGI concurs with the above described recommendations of The Fire Study. The workshop adds that since it is expensive many a times to validate end-to-end real-life functioning of a service or product especially for start-ups, easy and affordable access to experimentation infrastructure (hardware, software, clouds) and resources should be provided as a service. This can be particularly true for new and upcoming technologies like blockchain.\nThe Fire Study\u00a0also supports existing pattern of open calls and experimentation funding targeted towards attracting innovative SMEs and start-ups to test new networks\/protocols, and enable prototyping for rapid innovations. Hub4NGI D2.1 deliverable also recommends that in addition to the current open calls, the experimentation funding mechanisms offer flexible funding to accommodate SMEs that need experimentation in short order. This can be achieved through means like Responsive mode funding \u2013 where applications can be made at any time with each being judged on its own merits rather than against other applicants, and fast turnaround of experimentation funding decisions.\nHub4NGI D2.1 deliverable recognizes heterogeneous experimentation platforms as important element for innovation in NGI related themes.\n","119":"Hub4NGI D2.1 deliverable determines Innovation Networks as an important theme for the NGI Initiative, and therein considers the collaboration spaces as an essential network infrastructure to foster innovation in NGI related issues. As a starting point, it defines collaboration spaces as places where stakeholders concerned with the future of Internet can interact and share ideas be it physical places (incubators, etc.) or virtual (Internet forums).\nTo stress on the importance and need for collaboration spaces, the document includes evidence from Large-scale survey of European citizens study which acknowledges that more efforts are needed at European, national, and local levels to create spaces and places where citizens, stakeholders, and policy makers could exchange on the future of NGI related issues.\u00a0Nurse [Nurse 2015]\u00a0\u00a0also highlights the importance of facilitating collaboration in highly interconnected research system space quoting that \u201cmost effective research systems are characterised by freedom of movement and action.\u201d\nFor collaboration spaces to be effective, citing 2017 DIN Forum Report, the document asserts the need for them to be wider than simply places for people to interact, suggesting to incorporate other infrastructure types such as social networks, evidence platforms and experimentation platforms potentially bringing in open scientific data to the space.\u00a0If all these platforms\u00a0are brought together, there will be spaces for collaboration of people and resources from different disciplines, so that they may create and apply new and existing technologies to real world problems.\n\u00a0\n[Nurse 2015] Nurse, Paul. \"Ensuring a successful UK research endeavour.\" A Review of the UK Research Councils, Department for Business, Innovation & Skills, UK Government (2015).\n"},"title":{"0":"In a world of crowdsourced moderation, how do you fact-check the fact checks?","1":"Webinar on Strengthening Internet Trustworthiness: Q&A, ideas & comments about the NGI ICT-24-2019 call","2":"Genuine Global Identities for Open e-Democracy","3":"Better search for trustworthy content and objects discovery: NGI Forum 2018","4":"Online Identities and Trust","5":"Initiating trustworthiness","6":"Finding the appropriate partners for responding to R&I on discovery and identification technologies","7":"Webinar on Service and Data Portability: Q&A, Ideas & comments about the NGI ICT-24-2019 Call","8":"Service and data portability - ICT24 ii-b) topic","9":"Service portability and data decoupling","10":"Internet Society Global Internet Report 2019","11":"RINA (Recursive InterNetwork Architecture): a strong foundation for the NGI","12":"Cyber Security and Resilience","13":"Resilient Internet Services","14":"Optimisable, extensible, reusable and reliable open hardware","15":"Architecture renovation","16":"Smarter Asset Distribution for a resilient  Internet","17":"Highly Available, Resillient and Robust Internet Infrastructure Components","18":"Improving Maintainability and Deployability","19":"Internet Threat Catalogue critical to NGI","20":"Need for a new Internet Architecture","21":"Application Areas for NGI Technologies","22":"Emerging NGI Technologies","23":"An inclusive, multilingual internet","24":"User control and privacy in the global App market","25":"Human-centric approach to smart buildings","26":"Beyond the Internet: Enabling Businesses & Multi-stakeholder Dialogue","27":"Next Generation Internet: Beyond the Internet - Funding opportunities","28":"NGI national and EU initiatives","29":"NGI Frontrunners from Austrian national projects","30":"NGI Values: ambassadors and innovator frontrunners","31":"Blockchain disruptions and emerging business models","32":"SME Opportunities at NGI: Beyond the Internet Session","33":"Data Mining: How Companies Now Know Everything About You","34":"Privacy in real-time data marketplaces","35":"Workshop on Privacy and Trust at the NGI Forum 2018","36":"Privacy is everywhere - Take-aways from EuroDIG18","37":"End-user friendly transparency mechanisms","38":"User empowerment through freedom of choice","39":"Securing end-user rights, protection and reputation","40":"Cooperative Security needed in Future Internet","41":"Confidentiality","42":"Inadequacy of Responses and the Impact on Trust","43":"Impact of AI on Internet security and network intelligence","44":"Ensure continuing confidence in system","45":"How Technologies impact Privacy.","46":"Implications of giving away personal Data","47":"Lack of control over Data","48":"GDPR and NGI","49":"Audio-visual manipulation: what the Acosta affair teaches us","50":"Tackling Online Disinformation:  A European Approach","51":"Concepts for Search and Discovery based on the Slovenian Interoperability Framework","52":"SME Perspectives for Trustworthy Search and Content Discovery","53":"Semantic Data Organization","54":"Unbiased and privacy-respectful discovery of content and services","55":"Market uptake of eIDAS compliant eID infrastructure","56":"Extant research","57":"The unbalance of data relationships in the digital market","58":"Priorities for a decentralised Internet","59":"Blockchain alone won't make the internet decentralised and other challenges","60":"Internet and Data Sovereignty","61":"percloud: Personal clouds that real people WILL actually use","62":"Fixing asymmetry in data governance and Adam Smith's invisible hand","63":"Addressing ICT-24 with Web technology \u2013 Looking for collaborators","64":"Dencentralisation of Control","65":"How to balance between citizen-centric NGI and business models based on the data economy","66":"Advancing decentralised data governance","67":"Industry Lens: the 3 AI Challenges for future networks","68":"New EU Funding and Coordinated Plan for AI","69":"Towards a shared Ethical Framework for Artificial Intelligence","70":"Ethical principles and democratic prerequisites to form a Responsible AI.","71":"Beyond a narrow ethical framework governing autonomous systems","72":"Moral questions to check and safeguard development of AI technologies.","73":"Is AI really scary?","74":"Governance and Ethics in a World of AI","75":"Ethical Frameworks for Autonomous Machines","76":"Algorithmic Accountability","77":"Will AI Kill Us Or Empower Us? TED Talk Experts Weigh In","78":"Legal Accountability of AI","79":"Socio-economic impacts of artificial intelligence","80":"Blockchain through the lens of a researcher & Civil Society","81":"Standards setting for blockchain: permissioned distributed ledgers","82":"Impact of GDPR on Blockchain technologies","83":"Bringing interoperability to the data layer","84":"Blockchain for CE marking-based Directives","85":"Blockchain NL","86":"Game of Nodes: The Rise of the Regional Internet Blocs (Help us start the conversation)","87":"Greening the Internet","88":"Verification, accountability and automation mechanisms for the NGI","89":"IoT, Interoperability and the Future of Internet","90":"Market Consolidation, Walled Gardens and Policy Responses","91":"Safeguarding Standardization and Innovation","92":"Evolution of the Edge and Issue of Fragmentation","93":"Inter-operable Solutions for Ubiquitous Connectivity","94":"Common Definitions Common Understandings","95":"Technology Evolution vs Legislation","96":"Limitations to Democracy and Liberty","97":"Echo Chambers & Fake News","98":"How do we shape future hyper-connected sociality?","99":"ACCESSIBLE EUROPE: Bridging the Digital Divide","100":"Don\u2019t forget silver surfers \u2013 Digital inclusion and literacy focused on seniors","101":"The Impact of New Technologies on Industry and the Economy","102":"Multidisciplinary and End-to-End Design","103":"How to create a web inclusive for elderly, children and people with disabilities?","104":"R U - I o T Ready?","105":"Digital learning opportunities","106":"Insights from NGI Forum 2017","107":"Decline of Transit","108":"The Pressing Need for IoT Security","109":"The Future of Innovation and Entrepreneurship","110":"Socioeconomic Implications of Converging Digital and Physical Worlds","111":"Impact of AI on the Internet economy","112":"Multistakeholderism and Multilateralism and the setting of global norms","113":"Policy Making in the Digital Age","114":"Wealth Distribution and New Business Models","115":"Safeguarding Openness to new Entrants","116":"Innovation Support","117":"Evidence Platforms","118":"Experimentation Platforms","119":"Collaboration Spaces"},"url":{"0":"https:\/\/consultation.ngi.eu\/channels\/h2020-2019-call-topic-n1-strengthening-internet-trustworthiness\/world-crowdsourced","1":"https:\/\/consultation.ngi.eu\/channels\/h2020-2019-call-topic-1-strengthening-internet-trustworthiness\/webinar-strengthening","2":"https:\/\/consultation.ngi.eu\/channels\/h2020-2019-call-topic-1-strengthening-internet-trustworthiness\/genuine-global-identities","3":"https:\/\/consultation.ngi.eu\/channels\/h2020-2019-call-topic-1-strengthening-internet-trustworthiness\/better-search-trustworthy","4":"https:\/\/consultation.ngi.eu\/channels\/h2020-2019-call-topic-1-strengthening-internet-trustworthiness\/online-identities-and-trust","5":"https:\/\/consultation.ngi.eu\/channels\/strengthening-internet-trustworthiness-electronic-identities\/initiating-trustworthiness","6":"https:\/\/consultation.ngi.eu\/channels\/strengthening-internet-trustworthiness-electronic-identities\/finding-appropriate-partners-responding-ri","7":"https:\/\/consultation.ngi.eu\/channels\/h2020-2019-call-topic-n2-service-and-data-portability\/webinar-service-and-data-portability","8":"https:\/\/consultation.ngi.eu\/channels\/h2020-2019-call-topic-n2-service-and-data-portability\/service-and-data-portability-ict24-ii","9":"https:\/\/consultation.ngi.eu\/channels\/service-and-data-portability\/service-portability-and-data-decoupling","10":"https:\/\/consultation.ngi.eu\/channels\/h2020-2019-call-topic-n3-open-internet-architecture-renovation\/internet-society-global","11":"https:\/\/consultation.ngi.eu\/channels\/open-internet-architecture-renovation\/rina-recursive-internetwork-architecture-strong","12":"https:\/\/consultation.ngi.eu\/channels\/open-internet-architecture-renovation\/cyber-security-and-resilience","13":"https:\/\/consultation.ngi.eu\/channels\/open-internet-architecture-renovation\/resilient-internet-services","14":"https:\/\/consultation.ngi.eu\/channels\/open-internet-architecture-renovation\/optimisable-extensible-reusable-and-reliable-open","15":"https:\/\/consultation.ngi.eu\/channels\/open-internet-architecture-renovation\/architecture-renovation","16":"https:\/\/consultation.ngi.eu\/channels\/open-internet-architecture-renovation\/smarter-asset-distribution-resilient-internet","17":"https:\/\/consultation.ngi.eu\/channels\/open-internet-architecture-renovation\/highly-available-resillient-and-robust-internet","18":"https:\/\/consultation.ngi.eu\/channels\/open-internet-architecture-renovation\/improving-maintainability-and-deployability","19":"https:\/\/consultation.ngi.eu\/channels\/open-internet-architecture-renovation\/internet-threat-catalogue-critical-ngi","20":"https:\/\/consultation.ngi.eu\/channels\/open-internet-architecture-renovation\/need-new-internet-architecture","21":"https:\/\/consultation.ngi.eu\/channels\/open-internet-architecture-renovation\/application-areas-ngi-technologies","22":"https:\/\/consultation.ngi.eu\/channels\/open-internet-architecture-renovation\/emerging-ngi-technologies","23":"https:\/\/consultation.ngi.eu\/channels\/open-internet-architecture-renovation\/inclusive-multilingual-internet","24":"https:\/\/consultation.ngi.eu\/channels\/ngi-ict2018\/user-control-and-privacy-global-app-market","25":"https:\/\/consultation.ngi.eu\/channels\/ngi-ict2018\/human-centric-approach-smart-buildings","26":"https:\/\/consultation.ngi.eu\/channels\/ngi-ict2018\/beyond-internet-enabling-businesses-multi-stakeholder-dialogue","27":"https:\/\/consultation.ngi.eu\/channels\/ngi-ict2018\/next-generation-internet-beyond-internet-funding-opportunities","28":"https:\/\/consultation.ngi.eu\/channels\/ngi-ict2018\/ngi-national-and-eu-initiatives","29":"https:\/\/consultation.ngi.eu\/channels\/ngi-ict2018\/ngi-frontrunners-austrian-national-projects","30":"https:\/\/consultation.ngi.eu\/channels\/ngi-ict2018\/ngi-values-ambassadors-and-innovator-frontrunners","31":"https:\/\/consultation.ngi.eu\/channels\/ngi-ict2018\/blockchain-disruptions-and-emerging-business-models","32":"https:\/\/consultation.ngi.eu\/channels\/ngi-ict2018\/sme-opportunities-ngi-beyond-internet-session","33":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/data-mining-how-companies-now-know-everything","34":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/privacy-real-time-data-marketplaces","35":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/workshop-privacy-and-trust-ngi-forum-2018","36":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/privacy-everywhere-take-aways-eurodig18","37":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/end-user-friendly-transparency-mechanisms","38":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/user-empowerment-through-freedom-choice","39":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/securing-end-user-rights-protection-and-reputation","40":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/cooperative-security-needed-future-internet","41":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/confidentiality","42":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/inadequacy-responses-and-impact-trust","43":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/impact-ai-internet-security-and-network","44":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/ensure-continuing-confidence-system","45":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/how-technologies-impact-privacy","46":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/implications-giving-away-personal-data","47":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/lack-control-over-data","48":"https:\/\/consultation.ngi.eu\/channels\/privacy-and-trust-enhancing-technologies\/gdpr-and-ngi","49":"https:\/\/consultation.ngi.eu\/channels\/discovery-and-identification-technologies\/audio-visual-manipulation-what-acosta-affair","50":"https:\/\/consultation.ngi.eu\/channels\/discovery-and-identification-technologies\/tackling-online-disinformation-european-approach","51":"https:\/\/consultation.ngi.eu\/channels\/discovery-and-identification-technologies\/concepts-search-and-discovery-based-slovenian","52":"https:\/\/consultation.ngi.eu\/channels\/discovery-and-identification-technologies\/sme-perspectives-trustworthy-search-and-content","53":"https:\/\/consultation.ngi.eu\/channels\/discovery-and-identification-technologies\/semantic-data-organization","54":"https:\/\/consultation.ngi.eu\/channels\/discovery-and-identification-technologies\/unbiased-and-privacy-respectful-discovery-content","55":"https:\/\/consultation.ngi.eu\/channels\/discovery-and-identification-technologies\/market-uptake-eidas-compliant-eid-infrastructure","56":"https:\/\/consultation.ngi.eu\/channels\/discovery-and-identification-technologies\/extant-research","57":"https:\/\/consultation.ngi.eu\/channels\/decentralised-data-governance\/unbalance-data-relationships-digital-market","58":"https:\/\/consultation.ngi.eu\/channels\/decentralised-data-governance\/priorities-decentralised-internet","59":"https:\/\/consultation.ngi.eu\/channels\/decentralised-data-governance\/blockchain-alone-wont-make-internet-decentralised-and-other","60":"https:\/\/consultation.ngi.eu\/channels\/decentralised-data-governance\/internet-and-data-sovereignty","61":"https:\/\/consultation.ngi.eu\/channels\/decentralised-data-governance\/percloud-personal-clouds-real-people-will-actually-use","62":"https:\/\/consultation.ngi.eu\/channels\/decentralised-data-governance\/fixing-asymmetry-data-governance-and-adam-smiths-invisible","63":"https:\/\/consultation.ngi.eu\/channels\/decentralised-data-governance\/addressing-ict-24-web-technology-%E2%80%93-looking-collaborators","64":"https:\/\/consultation.ngi.eu\/channels\/decentralised-data-governance\/dencentralisation-control","65":"https:\/\/consultation.ngi.eu\/channels\/decentralised-data-governance\/how-balance-between-citizen-centric-ngi-and-business-models","66":"https:\/\/consultation.ngi.eu\/channels\/decentralised-data-governance\/advancing-decentralised-data-governance","67":"https:\/\/consultation.ngi.eu\/channels\/responsible-ai\/industry-lens-3-ai-challenges-future-networks","68":"https:\/\/consultation.ngi.eu\/channels\/responsible-ai\/new-eu-funding-and-coordinated-plan-ai","69":"https:\/\/consultation.ngi.eu\/channels\/responsible-ai\/towards-shared-ethical-framework-artificial-intelligence","70":"https:\/\/consultation.ngi.eu\/channels\/responsible-ai\/ethical-principles-and-democratic-prerequisites-form-responsible-ai","71":"https:\/\/consultation.ngi.eu\/channels\/responsible-ai\/beyond-narrow-ethical-framework-governing-autonomous-systems","72":"https:\/\/consultation.ngi.eu\/channels\/responsible-ai\/moral-questions-check-and-safeguard-development-ai-technologies","73":"https:\/\/consultation.ngi.eu\/channels\/responsible-ai\/ai-really-scary","74":"https:\/\/consultation.ngi.eu\/channels\/responsible-ai\/governance-and-ethics-world-ai","75":"https:\/\/consultation.ngi.eu\/channels\/responsible-ai\/ethical-frameworks-autonomous-machines","76":"https:\/\/consultation.ngi.eu\/channels\/responsible-ai\/algorithmic-accountability","77":"https:\/\/consultation.ngi.eu\/channels\/responsible-ai\/will-ai-kill-us-or-empower-us-ted-talk-experts-weigh","78":"https:\/\/consultation.ngi.eu\/channels\/responsible-ai\/legal-accountability-ai","79":"https:\/\/consultation.ngi.eu\/channels\/responsible-ai\/socio-economic-impacts-artificial-intelligence","80":"https:\/\/consultation.ngi.eu\/channels\/blockchain-enabler-ngi\/blockchain-through-lens-researcher-civil-society","81":"https:\/\/consultation.ngi.eu\/channels\/blockchain-enabler-ngi\/standards-setting-blockchain-permissioned-distributed-ledgers","82":"https:\/\/consultation.ngi.eu\/channels\/blockchain-enabler-ngi\/impact-gdpr-blockchain-technologies","83":"https:\/\/consultation.ngi.eu\/channels\/blockchain-enabler-ngi\/bringing-interoperability-data-layer","84":"https:\/\/consultation.ngi.eu\/channels\/blockchain-enabler-ngi\/blockchain-ce-marking-based-directives","85":"https:\/\/consultation.ngi.eu\/channels\/blockchain-enabler-ngi\/blockchain-nl","86":"https:\/\/consultation.ngi.eu\/channels\/open-internet-initiative\/game-nodes-rise-regional-internet-blocs-help-us-start-conversation","87":"https:\/\/consultation.ngi.eu\/channels\/open-internet-initiative\/greening-internet","88":"https:\/\/consultation.ngi.eu\/channels\/open-internet-initiative\/verification-accountability-and-automation-mechanisms-ngi","89":"https:\/\/consultation.ngi.eu\/channels\/open-internet-initiative\/iot-interoperability-and-future-internet","90":"https:\/\/consultation.ngi.eu\/channels\/open-internet-initiative\/market-consolidation-walled-gardens-and-policy-responses","91":"https:\/\/consultation.ngi.eu\/channels\/open-internet-initiative\/safeguarding-standardization-and-innovation","92":"https:\/\/consultation.ngi.eu\/channels\/open-internet-initiative\/evolution-edge-and-issue-fragmentation","93":"https:\/\/consultation.ngi.eu\/channels\/open-internet-initiative\/inter-operable-solutions-ubiquitous-connectivity","94":"https:\/\/consultation.ngi.eu\/channels\/open-internet-initiative\/common-definitions-common-understandings","95":"https:\/\/consultation.ngi.eu\/channels\/hyper-connected-sociality\/technology-evolution-vs-legislation","96":"https:\/\/consultation.ngi.eu\/channels\/hyper-connected-sociality\/limitations-democracy-and-liberty","97":"https:\/\/consultation.ngi.eu\/channels\/hyper-connected-sociality\/echo-chambers-fake-news","98":"https:\/\/consultation.ngi.eu\/channels\/hyper-connected-sociality\/how-do-we-shape-future-hyper-connected-sociality","99":"https:\/\/consultation.ngi.eu\/channels\/next-generation-internet-diversity-inclusion-and-skills\/accessible-europe-bridging-digital","100":"https:\/\/consultation.ngi.eu\/channels\/next-generation-internet-diversity-inclusion-and-skills\/don%E2%80%99t-forget-silver-surfers-%E2%80%93","101":"https:\/\/consultation.ngi.eu\/channels\/next-generation-internet-and-skills\/impact-new-technologies-industry-and-economy","102":"https:\/\/consultation.ngi.eu\/channels\/next-generation-internet-and-skills\/multidisciplinary-and-end-end-design","103":"https:\/\/consultation.ngi.eu\/channels\/next-generation-internet-and-skills\/how-create-web-inclusive-elderly-children-and-people-disabilities","104":"https:\/\/consultation.ngi.eu\/channels\/next-generation-internet-and-skills\/r-u-i-o-t-ready","105":"https:\/\/consultation.ngi.eu\/channels\/next-generation-internet-diversity-inclusion-and-skills\/digital-learning-opportunities","106":"https:\/\/consultation.ngi.eu\/channels\/next-generation-internet-and-skills\/insights-ngi-forum-2017","107":"https:\/\/consultation.ngi.eu\/channels\/socio-economic-and-legal-considerations-ngi\/decline-transit","108":"https:\/\/consultation.ngi.eu\/channels\/socio-economic-and-legal-considerations-ngi\/pressing-need-iot-security","109":"https:\/\/consultation.ngi.eu\/channels\/socio-economic-and-legal-considerations-ngi\/future-innovation-and-entrepreneurship","110":"https:\/\/consultation.ngi.eu\/channels\/socio-economic-and-legal-considerations-ngi\/socioeconomic-implications-converging-digital","111":"https:\/\/consultation.ngi.eu\/channels\/socio-economic-legal-considerations-ngi\/impact-ai-internet-economy","112":"https:\/\/consultation.ngi.eu\/channels\/socio-economic-legal-considerations-ngi\/multistakeholderism-and-multilateralism-and-setting","113":"https:\/\/consultation.ngi.eu\/channels\/socio-economic-legal-considerations-ngi\/policy-making-digital-age","114":"https:\/\/consultation.ngi.eu\/channels\/socio-economic-and-legal-considerations-ngi\/wealth-distribution-and-new-business-models","115":"https:\/\/consultation.ngi.eu\/channels\/innovation-networks\/safeguarding-openness-new-entrants%C2%A0","116":"https:\/\/consultation.ngi.eu\/channels\/innovation-networks\/innovation-support","117":"https:\/\/consultation.ngi.eu\/channels\/innovation-networks\/evidence-platforms","118":"https:\/\/consultation.ngi.eu\/channels\/innovation-networks\/experimentation-platforms","119":"https:\/\/consultation.ngi.eu\/channels\/innovation-networks\/collaboration-spaces"},"url_username":{"0":"https:\/\/consultation.ngi.eu\/users\/sam","1":"https:\/\/consultation.ngi.eu\/users\/Sara Pittonet","2":"https:\/\/consultation.ngi.eu\/users\/Ehud Shapiro","3":"https:\/\/consultation.ngi.eu\/users\/Stephanie Helen Parker","4":"https:\/\/consultation.ngi.eu\/users\/pablo","5":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","6":"https:\/\/consultation.ngi.eu\/users\/sandoche","7":"https:\/\/consultation.ngi.eu\/users\/paul.malone","8":"https:\/\/consultation.ngi.eu\/users\/ales_cernivec","9":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","10":"https:\/\/consultation.ngi.eu\/users\/cdelarrinaga","11":"https:\/\/consultation.ngi.eu\/users\/Eduard Grasa","12":"https:\/\/consultation.ngi.eu\/users\/pablo","13":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","14":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","15":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","16":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","17":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","18":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","19":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","20":"https:\/\/consultation.ngi.eu\/users\/eelahi","21":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","22":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","23":"https:\/\/consultation.ngi.eu\/users\/l.difiore","24":"https:\/\/consultation.ngi.eu\/users\/HelenParker","25":"https:\/\/consultation.ngi.eu\/users\/HelenParker","26":"https:\/\/consultation.ngi.eu\/users\/HelenParker","27":"https:\/\/consultation.ngi.eu\/users\/HelenParker","28":"https:\/\/consultation.ngi.eu\/users\/HelenParker","29":"https:\/\/consultation.ngi.eu\/users\/HelenParker","30":"https:\/\/consultation.ngi.eu\/users\/HelenParker","31":"https:\/\/consultation.ngi.eu\/users\/HelenParker","32":"https:\/\/consultation.ngi.eu\/users\/Silvana Muscella","33":"https:\/\/consultation.ngi.eu\/users\/eelahi","34":"https:\/\/consultation.ngi.eu\/users\/apasic","35":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","36":"https:\/\/consultation.ngi.eu\/users\/Stephanie Helen Parker","37":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","38":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","39":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","40":"https:\/\/consultation.ngi.eu\/users\/raimoakantola","41":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","42":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","43":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","44":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","45":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","46":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","47":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","48":"https:\/\/consultation.ngi.eu\/users\/","49":"https:\/\/consultation.ngi.eu\/users\/Sara Pittonet","50":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","51":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","52":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","53":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","54":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","55":"https:\/\/consultation.ngi.eu\/users\/apasic","56":"https:\/\/consultation.ngi.eu\/users\/KevinDoolin","57":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","58":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","59":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","60":"https:\/\/consultation.ngi.eu\/users\/pablo","61":"https:\/\/consultation.ngi.eu\/users\/mfioretti","62":"https:\/\/consultation.ngi.eu\/users\/Pekka Nikander","63":"https:\/\/consultation.ngi.eu\/users\/Ruben Verborgh","64":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","65":"https:\/\/consultation.ngi.eu\/users\/jclarke@tssg.org","66":"https:\/\/consultation.ngi.eu\/users\/a.petrocelli","67":"https:\/\/consultation.ngi.eu\/users\/Stephanie Helen Parker","68":"https:\/\/consultation.ngi.eu\/users\/Stephanie Helen Parker","69":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","70":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","71":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","72":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","73":"https:\/\/consultation.ngi.eu\/users\/eelahi","74":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","75":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","76":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","77":"https:\/\/consultation.ngi.eu\/users\/r.carrillo","78":"https:\/\/consultation.ngi.eu\/users\/paul.malone","79":"https:\/\/consultation.ngi.eu\/users\/l.difiore","80":"https:\/\/consultation.ngi.eu\/users\/Stephanie Helen Parker","81":"https:\/\/consultation.ngi.eu\/users\/HelenParker","82":"https:\/\/consultation.ngi.eu\/users\/jclarke@tssg.org","83":"https:\/\/consultation.ngi.eu\/users\/wsaqaf","84":"https:\/\/consultation.ngi.eu\/users\/rodwouters","85":"https:\/\/consultation.ngi.eu\/users\/Marloes","86":"https:\/\/consultation.ngi.eu\/users\/sam","87":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","88":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","89":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","90":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","91":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","92":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","93":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","94":"https:\/\/consultation.ngi.eu\/users\/Richard","95":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","96":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","97":"https:\/\/consultation.ngi.eu\/users\/Sjt","98":"https:\/\/consultation.ngi.eu\/users\/l.difiore","99":"https:\/\/consultation.ngi.eu\/users\/Stephanie Helen Parker","100":"https:\/\/consultation.ngi.eu\/users\/Stephanie Helen Parker","101":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","102":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","103":"https:\/\/consultation.ngi.eu\/users\/akwyz","104":"https:\/\/consultation.ngi.eu\/users\/AutoKen","105":"https:\/\/consultation.ngi.eu\/users\/l.difiore","106":"https:\/\/consultation.ngi.eu\/users\/speakuser","107":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","108":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","109":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","110":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","111":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","112":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","113":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","114":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","115":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","116":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","117":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","118":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser","119":"https:\/\/consultation.ngi.eu\/users\/ngi-report-analyser"},"username":{"0":"sam","1":"Sara Pittonet","2":"Ehud Shapiro","3":"Stephanie Helen Parker","4":"pablo","5":"ngi-report-analyser","6":"sandoche","7":"paul.malone","8":"ales_cernivec","9":"ngi-report-analyser","10":"cdelarrinaga","11":"Eduard Grasa","12":"pablo","13":"ngi-report-analyser","14":"ngi-report-analyser","15":"ngi-report-analyser","16":"ngi-report-analyser","17":"ngi-report-analyser","18":"ngi-report-analyser","19":"ngi-report-analyser","20":"eelahi","21":"ngi-report-analyser","22":"ngi-report-analyser","23":"l.difiore","24":"HelenParker","25":"HelenParker","26":"HelenParker","27":"HelenParker","28":"HelenParker","29":"HelenParker","30":"HelenParker","31":"HelenParker","32":"Silvana Muscella","33":"eelahi","34":"apasic","35":"ngi-report-analyser","36":"Stephanie Helen Parker","37":"ngi-report-analyser","38":"ngi-report-analyser","39":"ngi-report-analyser","40":"raimoakantola","41":"ngi-report-analyser","42":"ngi-report-analyser","43":"ngi-report-analyser","44":"ngi-report-analyser","45":"ngi-report-analyser","46":"ngi-report-analyser","47":"ngi-report-analyser","48":"","49":"Sara Pittonet","50":"ngi-report-analyser","51":"ngi-report-analyser","52":"ngi-report-analyser","53":"ngi-report-analyser","54":"ngi-report-analyser","55":"apasic","56":"KevinDoolin","57":"ngi-report-analyser","58":"ngi-report-analyser","59":"ngi-report-analyser","60":"pablo","61":"mfioretti","62":"Pekka Nikander","63":"Ruben Verborgh","64":"ngi-report-analyser","65":"jclarke@tssg.org","66":"a.petrocelli","67":"Stephanie Helen Parker","68":"Stephanie Helen Parker","69":"ngi-report-analyser","70":"ngi-report-analyser","71":"ngi-report-analyser","72":"ngi-report-analyser","73":"eelahi","74":"ngi-report-analyser","75":"ngi-report-analyser","76":"ngi-report-analyser","77":"r.carrillo","78":"paul.malone","79":"l.difiore","80":"Stephanie Helen Parker","81":"HelenParker","82":"jclarke@tssg.org","83":"wsaqaf","84":"rodwouters","85":"Marloes","86":"sam","87":"ngi-report-analyser","88":"ngi-report-analyser","89":"ngi-report-analyser","90":"ngi-report-analyser","91":"ngi-report-analyser","92":"ngi-report-analyser","93":"ngi-report-analyser","94":"Richard","95":"ngi-report-analyser","96":"ngi-report-analyser","97":"Sjt","98":"l.difiore","99":"Stephanie Helen Parker","100":"Stephanie Helen Parker","101":"ngi-report-analyser","102":"ngi-report-analyser","103":"akwyz","104":"AutoKen","105":"l.difiore","106":"speakuser","107":"ngi-report-analyser","108":"ngi-report-analyser","109":"ngi-report-analyser","110":"ngi-report-analyser","111":"ngi-report-analyser","112":"ngi-report-analyser","113":"ngi-report-analyser","114":"ngi-report-analyser","115":"ngi-report-analyser","116":"ngi-report-analyser","117":"ngi-report-analyser","118":"ngi-report-analyser","119":"ngi-report-analyser"}}